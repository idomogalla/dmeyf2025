{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "150c43ca",
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Cargando paquete requerido: data.table\n",
      "\n",
      "Cargando paquete requerido: parallel\n",
      "\n",
      "Cargando paquete requerido: R.utils\n",
      "\n",
      "Cargando paquete requerido: R.oo\n",
      "\n",
      "Cargando paquete requerido: R.methodsS3\n",
      "\n",
      "R.methodsS3 v1.8.2 (2022-06-13 22:00:14 UTC) successfully loaded. See ?R.methodsS3 for help.\n",
      "\n",
      "R.oo v1.27.1 (2025-05-02 21:00:05 UTC) successfully loaded. See ?R.oo for help.\n",
      "\n",
      "\n",
      "Adjuntando el paquete: 'R.oo'\n",
      "\n",
      "\n",
      "The following object is masked from 'package:R.methodsS3':\n",
      "\n",
      "    throw\n",
      "\n",
      "\n",
      "The following objects are masked from 'package:methods':\n",
      "\n",
      "    getClasses, getMethods\n",
      "\n",
      "\n",
      "The following objects are masked from 'package:base':\n",
      "\n",
      "    attach, detach, load, save\n",
      "\n",
      "\n",
      "R.utils v2.13.0 (2025-02-24 21:20:02 UTC) successfully loaded. See ?R.utils for help.\n",
      "\n",
      "\n",
      "Adjuntando el paquete: 'R.utils'\n",
      "\n",
      "\n",
      "The following object is masked from 'package:utils':\n",
      "\n",
      "    timestamp\n",
      "\n",
      "\n",
      "The following objects are masked from 'package:base':\n",
      "\n",
      "    cat, commandArgs, getOption, isOpen, nullfile, parse, use, warnings\n",
      "\n",
      "\n",
      "Cargando paquete requerido: primes\n",
      "\n",
      "Cargando paquete requerido: rlist\n",
      "\n",
      "Cargando paquete requerido: yaml\n",
      "\n",
      "Cargando paquete requerido: lightgbm\n",
      "\n",
      "Cargando paquete requerido: DiceKriging\n",
      "\n",
      "Cargando paquete requerido: mlrMBO\n",
      "\n",
      "Cargando paquete requerido: mlr\n",
      "\n",
      "Cargando paquete requerido: ParamHelpers\n",
      "\n",
      "\n",
      "Adjuntando el paquete: 'ParamHelpers'\n",
      "\n",
      "\n",
      "The following object is masked from 'package:R.utils':\n",
      "\n",
      "    isVector\n",
      "\n",
      "\n",
      "\n",
      "Adjuntando el paquete: 'mlr'\n",
      "\n",
      "\n",
      "The following objects are masked from 'package:R.utils':\n",
      "\n",
      "    resample, setThreshold\n",
      "\n",
      "\n",
      "Cargando paquete requerido: smoof\n",
      "\n",
      "Cargando paquete requerido: checkmate\n",
      "\n",
      "\n",
      "Adjuntando el paquete: 'checkmate'\n",
      "\n",
      "\n",
      "The following object is masked from 'package:DiceKriging':\n",
      "\n",
      "    checkNames\n",
      "\n",
      "\n",
      "The following object is masked from 'package:R.utils':\n",
      "\n",
      "    asInt\n",
      "\n",
      "\n",
      "\n",
      "Adjuntando el paquete: 'smoof'\n",
      "\n",
      "\n",
      "The following objects are masked from 'package:R.oo':\n",
      "\n",
      "    getDescription, getName\n",
      "\n",
      "\n",
      "Cargando paquete requerido: ggplot2\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# cargo las librerias que necesito\n",
    "if(!require(\"data.table\")) install.packages(\"data.table\")\n",
    "require(\"data.table\")\n",
    "\n",
    "if(!require(\"parallel\")) install.packages(\"parallel\")\n",
    "require(\"parallel\")\n",
    "\n",
    "if(!require(\"R.utils\")) install.packages(\"R.utils\")\n",
    "require(\"R.utils\")\n",
    "\n",
    "if( !require(\"primes\") ) install.packages(\"primes\")\n",
    "require(\"primes\")\n",
    "\n",
    "if( !require(\"utils\") ) install.packages(\"utils\")\n",
    "require(\"utils\")\n",
    "\n",
    "if( !require(\"rlist\") ) install.packages(\"rlist\")\n",
    "require(\"rlist\")\n",
    "\n",
    "if( !require(\"yaml\")) install.packages(\"yaml\")\n",
    "require(\"yaml\")\n",
    "\n",
    "if( !require(\"lightgbm\") ) install.packages(\"lightgbm\")\n",
    "require(\"lightgbm\")\n",
    "\n",
    "if( !require(\"DiceKriging\") ) install.packages(\"DiceKriging\")\n",
    "require(\"DiceKriging\")\n",
    "\n",
    "if( !require(\"mlrMBO\") ) install.packages(\"mlrMBO\")\n",
    "require(\"mlrMBO\")\n",
    "\n",
    "if( !require(\"ggplot2\") ) install.packages(\"ggplot2\")\n",
    "require(\"ggplot2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "54cddfce",
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"dataframe\">\n",
       "<caption>A matrix: 2 × 6 of type dbl</caption>\n",
       "<thead>\n",
       "\t<tr><th></th><th scope=col>used</th><th scope=col>(Mb)</th><th scope=col>gc trigger</th><th scope=col>(Mb)</th><th scope=col>max used</th><th scope=col>(Mb)</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "\t<tr><th scope=row>Ncells</th><td>2336750</td><td>124.8</td><td>4765421</td><td>254.6</td><td>2934765</td><td>156.8</td></tr>\n",
       "\t<tr><th scope=row>Vcells</th><td>4043417</td><td> 30.9</td><td>8388608</td><td> 64.0</td><td>5870691</td><td> 44.8</td></tr>\n",
       "</tbody>\n",
       "</table>\n"
      ],
      "text/latex": [
       "A matrix: 2 × 6 of type dbl\n",
       "\\begin{tabular}{r|llllll}\n",
       "  & used & (Mb) & gc trigger & (Mb) & max used & (Mb)\\\\\n",
       "\\hline\n",
       "\tNcells & 2336750 & 124.8 & 4765421 & 254.6 & 2934765 & 156.8\\\\\n",
       "\tVcells & 4043417 &  30.9 & 8388608 &  64.0 & 5870691 &  44.8\\\\\n",
       "\\end{tabular}\n"
      ],
      "text/markdown": [
       "\n",
       "A matrix: 2 × 6 of type dbl\n",
       "\n",
       "| <!--/--> | used | (Mb) | gc trigger | (Mb) | max used | (Mb) |\n",
       "|---|---|---|---|---|---|---|\n",
       "| Ncells | 2336750 | 124.8 | 4765421 | 254.6 | 2934765 | 156.8 |\n",
       "| Vcells | 4043417 |  30.9 | 8388608 |  64.0 | 5870691 |  44.8 |\n",
       "\n"
      ],
      "text/plain": [
       "       used    (Mb)  gc trigger (Mb)  max used (Mb) \n",
       "Ncells 2336750 124.8 4765421    254.6 2934765  156.8\n",
       "Vcells 4043417  30.9 8388608     64.0 5870691   44.8"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# limpio la memoria\n",
    "rm(list=ls(all.names=TRUE)) # remove all objects\n",
    "gc(full=TRUE, verbose=FALSE) # garbage collection"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc7b50e8",
   "metadata": {},
   "source": [
    "# Parámetros"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "209462b4",
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "# Parámetros\n",
    "PARAM <- list()\n",
    "PARAM$experimento <- \"expC01_Prueba01_A\"\n",
    "PARAM$semilla_primigenia <- 200003\n",
    "\n",
    "# training y future\n",
    "PARAM$train <- c(202101, 202102)\n",
    "PARAM$train_final <- c(202101, 202102)\n",
    "PARAM$future <- c(202104)\n",
    "PARAM$train_final_kaggle <- c(202101, 202102, 202103, 202104)\n",
    "PARAM$entrega_kaggle <- c(202106)\n",
    "PARAM$semilla_kaggle <- 314159 #Semilla para el modelo final que va a Kaggle, primeros números de pi que sean primos.\n",
    "PARAM$cortes <- seq(0, 20000, by= 100)\n",
    "\n",
    "# un undersampling de 0.1  toma solo el 10% de los CONTINUA\n",
    "# undersampling de 1.0  implica tomar TODOS los datos\n",
    "\n",
    "PARAM$trainingstrategy$undersampling <- 0.5\n",
    "\n",
    "# Parametros LightGBM\n",
    "\n",
    "PARAM$hyperparametertuning$xval_folds <- 5\n",
    "\n",
    "# parametros fijos del LightGBM que se pisaran con la parte variable de la BO\n",
    "PARAM$lgbm$param_fijos <-  list(\n",
    "  boosting= \"gbdt\", # puede ir dart, ni pruebe random_forest\n",
    "  objective= \"binary\", #default regression\n",
    "  metric= \"auc\", # default \"\" \n",
    "  first_metric_only= FALSE, # default FALSE\n",
    "  boost_from_average= TRUE, # default TRUE\n",
    "  feature_pre_filter= FALSE, # default TRUE\n",
    "  force_row_wise= TRUE, # para reducir warnings\n",
    "  verbosity= -100, # default 1\n",
    "\n",
    "  seed= PARAM$semilla_primigenia, # Relacionado con data_random_seed, feature_fraction_seed, entre otros \n",
    "\n",
    "  max_depth= -1L, # -1 significa no limitar,  por ahora lo dejo fijo\n",
    "  min_gain_to_split= 0, # min_gain_to_split >= 0\n",
    "  min_sum_hessian_in_leaf= 0.001, #  min_sum_hessian_in_leaf >= 0.0\n",
    "  lambda_l1= 0.0, # lambda_l1 >= 0.0\n",
    "  lambda_l2= 0.0, # lambda_l2 >= 0.0\n",
    "  max_bin= 31L, # lo debo dejar fijo, no participa de la BO\n",
    "\n",
    "  bagging_fraction= 1.0, # 0.0 < bagging_fraction <= 1.0\n",
    "  pos_bagging_fraction= 1.0, # 0.0 < pos_bagging_fraction <= 1.0\n",
    "  neg_bagging_fraction= 1.0, # 0.0 < neg_bagging_fraction <= 1.0\n",
    "  is_unbalance= FALSE, # Default FALSE\n",
    "  scale_pos_weight= 1.0, # scale_pos_weight > 0.0\n",
    "\n",
    "  drop_rate= 0.1, # 0.0 < neg_bagging_fraction <= 1.0\n",
    "  max_drop= 50, # <=0 means no limit\n",
    "  skip_drop= 0.5, # 0.0 <= skip_drop <= 1.0\n",
    "\n",
    "  extra_trees= FALSE, # default FALSE\n",
    "\n",
    "  num_iterations= 1200, # default 100\n",
    "  learning_rate= 0.02, # default 0.1\n",
    "  feature_fraction= 0.5, # default 1\n",
    "  num_leaves= 750, # default 31\n",
    "  min_data_in_leaf= 5000 # default 20\n",
    ")\n",
    "\n",
    "# Aqui se cargan los bordes de los hiperparametros de la BO\n",
    "PARAM$hypeparametertuning$hs <- makeParamSet(\n",
    "  makeIntegerParam(\"num_iterations\", lower= 50L, upper= 3000L),\n",
    "  makeNumericParam(\"learning_rate\", lower= 0.005, upper= 0.1),\n",
    "  makeNumericParam(\"feature_fraction\", lower= 0.1, upper= 1.0),\n",
    "  makeIntegerParam(\"num_leaves\", lower= 1L, upper= 2048L),\n",
    "  makeIntegerParam(\"min_data_in_leaf\", lower= 1L, upper= 8000L)\n",
    ")\n",
    "\n",
    "PARAM$hyperparametertuning$iteraciones <- 100 # iteraciones bayesianas"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dfb8db72",
   "metadata": {},
   "source": [
    "# Funciones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e0ab6486",
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "# particionar agrega una columna llamada fold a un dataset\n",
    "#   que consiste en una particion estratificada segun agrupa\n",
    "# particionar( data=dataset, division=c(70,30),\n",
    "#  agrupa=clase_ternaria, seed=semilla)   crea una particion 70, 30\n",
    "\n",
    "particionar <- function(data, division, agrupa= \"\", campo= \"fold\", start= 1, seed= NA) {\n",
    "  if (!is.na(seed)) set.seed(seed, \"L'Ecuyer-CMRG\")\n",
    "\n",
    "  bloque <- unlist(mapply(\n",
    "    function(x, y) {rep(y, x)},division, seq(from= start, length.out= length(division))))\n",
    "\n",
    "  data[, (campo) := sample(rep(bloque,ceiling(.N / length(bloque))))[1:.N],by= agrupa]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "506eed41",
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "# iniciliazo el dataset de realidad, para medir ganancia\n",
    "realidad_inicializar <- function( pfuture, pparam) {\n",
    "\n",
    "  # datos para verificar la ganancia\n",
    "  drealidad <- pfuture[, list(numero_de_cliente, foto_mes, clase_ternaria)]\n",
    "\n",
    "  particionar(drealidad,\n",
    "    division= c(3, 7),\n",
    "    agrupa= \"clase_ternaria\",\n",
    "    seed= PARAM$semilla_kaggle\n",
    "  )\n",
    "\n",
    "  return( drealidad )\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0d09def7",
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "# evaluo ganancia en los datos de la realidad\n",
    "\n",
    "realidad_evaluar <- function( prealidad, pprediccion) {\n",
    "\n",
    "  prealidad[ pprediccion,\n",
    "    on= c(\"numero_de_cliente\", \"foto_mes\"),\n",
    "    predicted:= i.Predicted\n",
    "  ]\n",
    "\n",
    "  tbl <- prealidad[, list(\"qty\"=.N), list(fold, predicted, clase_ternaria)]\n",
    "\n",
    "  res <- list()\n",
    "  res$public  <- tbl[fold==1 & predicted==1L, sum(qty*ifelse(clase_ternaria==\"BAJA+2\", 780000, -20000))]/0.3\n",
    "  res$private <- tbl[fold==2 & predicted==1L, sum(qty*ifelse(clase_ternaria==\"BAJA+2\", 780000, -20000))]/0.7\n",
    "  res$total <- tbl[predicted==1L, sum(qty*ifelse(clase_ternaria==\"BAJA+2\", 780000, -20000))]\n",
    "\n",
    "  prealidad[, predicted:=NULL]\n",
    "  return( res )\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7774b9d7",
   "metadata": {},
   "source": [
    "# Configuración del Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b998f5d3",
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "# lectura del dataset\n",
    "dataset <- fread(\"../../competencia_01.csv.gz\", stringsAsFactors= TRUE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "76923d46",
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "# Genero columnas Lags y Delta Lags de orden 1\n",
    "cols_a_excluir <- c(\"numero_de_cliente\", \"foto_mes\", \"clase_ternaria\")\n",
    "cols_con_lag <- setdiff(names(dataset), cols_a_excluir)\n",
    "nombres_nuevas_cols_lag <- paste0(cols_con_lag, \"_lag1\")\n",
    "dataset[, (nombres_nuevas_cols_lag) := shift(.SD, 1, NA, \"lag\"), by = numero_de_cliente, .SDcols = cols_con_lag]\n",
    "nombres_nuevas_cols_delta <- paste0(cols_con_lag, \"_delta1\")\n",
    "dataset[, (nombres_nuevas_cols_delta) := .SD - mget(nombres_nuevas_cols_lag), .SDcols = cols_con_lag]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a3519f78",
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "# Selecciono los datos de training\n",
    "dataset_train <- dataset[foto_mes %in% PARAM$train]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0e9e959b",
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "# paso la clase a binaria que tome valores {0,1}  enteros\n",
    "#  BAJA+1 y BAJA+2  son  1,   CONTINUA es 0\n",
    "#  a partir de ahora ya NO puedo cortar  por prob(BAJA+2) > 1/40\n",
    "\n",
    "dataset_train[,\n",
    "  clase01 := ifelse(clase_ternaria %in% c(\"BAJA+2\",\"BAJA+1\"), 1L, 0L)\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "df466eab",
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "# defino los datos que forma parte del training\n",
    "# aqui se hace el undersampling de los CONTINUA\n",
    "# notar que para esto utilizo la SEGUNDA semilla\n",
    "\n",
    "set.seed(PARAM$semilla_primigenia, kind = \"L'Ecuyer-CMRG\")\n",
    "dataset_train[, azar := runif(nrow(dataset_train))]\n",
    "dataset_train[, training := 0L]\n",
    "\n",
    "dataset_train[\n",
    "  foto_mes %in%  PARAM$train &\n",
    "    (azar <= PARAM$trainingstrategy$undersampling | clase_ternaria %in% c(\"BAJA+1\", \"BAJA+2\")),\n",
    "  training := 1L\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9887427e",
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "# Me quedo con los campos a ser utilizados en el entrenamiento\n",
    "\n",
    "campos_buenos <- setdiff(\n",
    "  colnames(dataset_train),\n",
    "  c(\"clase_ternaria\", \"clase01\", \"azar\", \"training\")\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c944ff93",
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "163737"
      ],
      "text/latex": [
       "163737"
      ],
      "text/markdown": [
       "163737"
      ],
      "text/plain": [
       "[1] 163737"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "458"
      ],
      "text/latex": [
       "458"
      ],
      "text/markdown": [
       "458"
      ],
      "text/plain": [
       "[1] 458"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# dejo los datos en el formato que necesita LightGBM\n",
    "\n",
    "dtrain <- lgb.Dataset(\n",
    "  data= data.matrix(dataset_train[training == 1L, campos_buenos, with= FALSE]),\n",
    "  label= dataset_train[training == 1L, clase01],\n",
    "  free_raw_data= FALSE\n",
    ")\n",
    "\n",
    "nrow(dtrain)\n",
    "ncol(dtrain)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd8ba0ef",
   "metadata": {},
   "source": [
    "# Bayesian Optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c4e963ed",
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "# En el argumento x llegan los parmaetros de la bayesiana\n",
    "#  devuelve la AUC en cross validation del modelo entrenado\n",
    "\n",
    "EstimarGanancia_AUC_lightgbm <- function(x) {\n",
    "\n",
    "  # x pisa (o agrega) a param_fijos\n",
    "  param_completo <- modifyList(PARAM$lgbm$param_fijos, x)\n",
    "\n",
    "  # entreno LightGBM\n",
    "  modelocv <- lgb.cv(\n",
    "    data= dtrain,\n",
    "    nfold= PARAM$hyperparametertuning$xval_folds,\n",
    "    stratified= TRUE,\n",
    "    param= param_completo\n",
    "  )\n",
    "\n",
    "  # obtengo la ganancia\n",
    "  AUC <- modelocv$best_score\n",
    "\n",
    "  # hago espacio en la memoria\n",
    "  rm(modelocv)\n",
    "  gc(full= TRUE, verbose= FALSE)\n",
    "\n",
    "  message(format(Sys.time(), \"%a %b %d %X %Y\"), \" AUC \", AUC)\n",
    "\n",
    "  return(AUC)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "56fa3453",
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "# Aqui comienza la configuracion de la Bayesian Optimization\n",
    "\n",
    "# en este archivo quedan la evolucion binaria de la BO\n",
    "dir.create(\"Archivos Bayesiana\", showWarnings=FALSE)\n",
    "kbayesiana <- paste0(\"./Archivos Bayesiana/bayesiana.RDATA\")\n",
    "\n",
    "funcion_optimizar <- EstimarGanancia_AUC_lightgbm # la funcion que voy a maximizar\n",
    "\n",
    "configureMlr(show.learner.output= FALSE)\n",
    "\n",
    "# configuro la busqueda bayesiana,  los hiperparametros que se van a optimizar\n",
    "# por favor, no desesperarse por lo complejo\n",
    "\n",
    "obj.fun <- makeSingleObjectiveFunction(\n",
    "  fn= funcion_optimizar, # la funcion que voy a maximizar\n",
    "  minimize= FALSE, # estoy Maximizando la ganancia\n",
    "  noisy= TRUE,\n",
    "  par.set= PARAM$hypeparametertuning$hs, # definido al comienzo del programa\n",
    "  has.simple.signature= FALSE # paso los parametros en una lista\n",
    ")\n",
    "\n",
    "# cada 600 segundos guardo el resultado intermedio\n",
    "ctrl <- makeMBOControl(\n",
    "  save.on.disk.at.time= 600, # se graba cada 600 segundos\n",
    "  save.file.path= kbayesiana\n",
    ") # se graba cada 600 segundos\n",
    "\n",
    "# indico la cantidad de iteraciones que va a tener la Bayesian Optimization\n",
    "ctrl <- setMBOControlTermination(\n",
    "  ctrl,\n",
    "  iters= PARAM$hyperparametertuning$iteraciones\n",
    ") # cantidad de iteraciones\n",
    "\n",
    "# defino el método estandar para la creacion de los puntos iniciales,\n",
    "# los \"No Inteligentes\"\n",
    "ctrl <- setMBOControlInfill(ctrl, crit= makeMBOInfillCritEI())\n",
    "\n",
    "# establezco la funcion que busca el maximo\n",
    "surr.km <- makeLearner(\n",
    "  \"regr.km\",\n",
    "  predict.type= \"se\",\n",
    "  covtype= \"matern3_2\",\n",
    "  control= list(trace= TRUE)\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "62d79bf0",
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning message in mboContinue(kbayesiana):\n",
      "\"Tuning ended with term.iter. No need to continue. Simply returning stored result.\"\n"
     ]
    }
   ],
   "source": [
    "# inicio la optimizacion bayesiana, retomando si ya existe\n",
    "# es la celda mas lenta de todo el notebook\n",
    "\n",
    "if (!file.exists(kbayesiana)) {\n",
    "  bayesiana_salida <- mbo(obj.fun, learner= surr.km, control= ctrl)\n",
    "} else {\n",
    "  bayesiana_salida <- mboContinue(kbayesiana) # retomo en caso que ya exista\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "e60c2d38",
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>\n",
       ".list-inline {list-style: none; margin:0; padding: 0}\n",
       ".list-inline>li {display: inline-block}\n",
       ".list-inline>li:not(:last-child)::after {content: \"\\00b7\"; padding: 0 .5ex}\n",
       "</style>\n",
       "<ol class=list-inline><li>'num_iterations'</li><li>'learning_rate'</li><li>'feature_fraction'</li><li>'num_leaves'</li><li>'min_data_in_leaf'</li><li>'y'</li><li>'dob'</li><li>'eol'</li><li>'error.message'</li><li>'exec.time'</li><li>'ei'</li><li>'error.model'</li><li>'train.time'</li><li>'prop.type'</li><li>'propose.time'</li><li>'se'</li><li>'mean'</li></ol>\n"
      ],
      "text/latex": [
       "\\begin{enumerate*}\n",
       "\\item 'num\\_iterations'\n",
       "\\item 'learning\\_rate'\n",
       "\\item 'feature\\_fraction'\n",
       "\\item 'num\\_leaves'\n",
       "\\item 'min\\_data\\_in\\_leaf'\n",
       "\\item 'y'\n",
       "\\item 'dob'\n",
       "\\item 'eol'\n",
       "\\item 'error.message'\n",
       "\\item 'exec.time'\n",
       "\\item 'ei'\n",
       "\\item 'error.model'\n",
       "\\item 'train.time'\n",
       "\\item 'prop.type'\n",
       "\\item 'propose.time'\n",
       "\\item 'se'\n",
       "\\item 'mean'\n",
       "\\end{enumerate*}\n"
      ],
      "text/markdown": [
       "1. 'num_iterations'\n",
       "2. 'learning_rate'\n",
       "3. 'feature_fraction'\n",
       "4. 'num_leaves'\n",
       "5. 'min_data_in_leaf'\n",
       "6. 'y'\n",
       "7. 'dob'\n",
       "8. 'eol'\n",
       "9. 'error.message'\n",
       "10. 'exec.time'\n",
       "11. 'ei'\n",
       "12. 'error.model'\n",
       "13. 'train.time'\n",
       "14. 'prop.type'\n",
       "15. 'propose.time'\n",
       "16. 'se'\n",
       "17. 'mean'\n",
       "\n",
       "\n"
      ],
      "text/plain": [
       " [1] \"num_iterations\"   \"learning_rate\"    \"feature_fraction\" \"num_leaves\"      \n",
       " [5] \"min_data_in_leaf\" \"y\"                \"dob\"              \"eol\"             \n",
       " [9] \"error.message\"    \"exec.time\"        \"ei\"               \"error.model\"     \n",
       "[13] \"train.time\"       \"prop.type\"        \"propose.time\"     \"se\"              \n",
       "[17] \"mean\"            "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "tb_bayesiana <- as.data.table(bayesiana_salida$opt.path)\n",
    "colnames( tb_bayesiana)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "666d5785",
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   num_iterations learning_rate feature_fraction num_leaves min_data_in_leaf\n",
      "            <int>         <num>            <num>      <int>            <int>\n",
      "1:           2687    0.01639236        0.5954814       1405               13\n",
      "[1] 0.9437747\n"
     ]
    }
   ],
   "source": [
    "# almaceno los resultados de la Bayesian Optimization\n",
    "# y capturo los mejores hiperparametros encontrados\n",
    "\n",
    "tb_bayesiana <- as.data.table(bayesiana_salida$opt.path)\n",
    "\n",
    "tb_bayesiana[, iter := .I]\n",
    "\n",
    "# ordeno en forma descendente por AUC = y\n",
    "setorder(tb_bayesiana, -y)\n",
    "\n",
    "# grabo para eventualmente poder utilizarlos en OTRA corrida\n",
    "fwrite( tb_bayesiana,\n",
    "  file= \"./Archivos Bayesiana/BO_log.txt\",\n",
    "  sep= \"\\t\"\n",
    ")\n",
    "\n",
    "# los mejores hiperparámetros son los que quedaron en el registro 1 de la tabla\n",
    "PARAM$out$lgbm$mejores_hiperparametros <- tb_bayesiana[\n",
    "  1, # el primero es el de mejor AUC\n",
    "  setdiff(colnames(tb_bayesiana),\n",
    "    c(\"y\",\"dob\",\"eol\",\"error.message\",\"exec.time\",\"ei\",\"error.model\",\n",
    "      \"train.time\",\"prop.type\",\"propose.time\",\"se\",\"mean\",\"iter\")),\n",
    "  with= FALSE\n",
    "]\n",
    "\n",
    "\n",
    "PARAM$out$lgbm$y <- tb_bayesiana[1, y]\n",
    "\n",
    "write_yaml(PARAM, file=\"./Archivos Bayesiana/PARAM.yml\")\n",
    "\n",
    "print(PARAM$out$lgbm$mejores_hiperparametros)\n",
    "print(PARAM$out$lgbm$y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dec8b80f",
   "metadata": {},
   "source": [
    "# Entrenamiento Mejores hiperparámetros"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "d5b207e6",
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"dataframe\">\n",
       "<caption>A data.table: 3 × 2</caption>\n",
       "<thead>\n",
       "\t<tr><th scope=col>clase_ternaria</th><th scope=col>N</th></tr>\n",
       "\t<tr><th scope=col>&lt;fct&gt;</th><th scope=col>&lt;int&gt;</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "\t<tr><td>CONTINUA</td><td>320372</td></tr>\n",
       "\t<tr><td>BAJA+2  </td><td>  1857</td></tr>\n",
       "\t<tr><td>BAJA+1  </td><td>  1453</td></tr>\n",
       "</tbody>\n",
       "</table>\n"
      ],
      "text/latex": [
       "A data.table: 3 × 2\n",
       "\\begin{tabular}{ll}\n",
       " clase\\_ternaria & N\\\\\n",
       " <fct> & <int>\\\\\n",
       "\\hline\n",
       "\t CONTINUA & 320372\\\\\n",
       "\t BAJA+2   &   1857\\\\\n",
       "\t BAJA+1   &   1453\\\\\n",
       "\\end{tabular}\n"
      ],
      "text/markdown": [
       "\n",
       "A data.table: 3 × 2\n",
       "\n",
       "| clase_ternaria &lt;fct&gt; | N &lt;int&gt; |\n",
       "|---|---|\n",
       "| CONTINUA | 320372 |\n",
       "| BAJA+2   |   1857 |\n",
       "| BAJA+1   |   1453 |\n",
       "\n"
      ],
      "text/plain": [
       "  clase_ternaria N     \n",
       "1 CONTINUA       320372\n",
       "2 BAJA+2           1857\n",
       "3 BAJA+1           1453"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<dl>\n",
       "\t<dt>$boosting</dt>\n",
       "\t\t<dd>'gbdt'</dd>\n",
       "\t<dt>$objective</dt>\n",
       "\t\t<dd>'binary'</dd>\n",
       "\t<dt>$metric</dt>\n",
       "\t\t<dd>'auc'</dd>\n",
       "\t<dt>$first_metric_only</dt>\n",
       "\t\t<dd>FALSE</dd>\n",
       "\t<dt>$boost_from_average</dt>\n",
       "\t\t<dd>TRUE</dd>\n",
       "\t<dt>$feature_pre_filter</dt>\n",
       "\t\t<dd>FALSE</dd>\n",
       "\t<dt>$force_row_wise</dt>\n",
       "\t\t<dd>TRUE</dd>\n",
       "\t<dt>$verbosity</dt>\n",
       "\t\t<dd>-100</dd>\n",
       "\t<dt>$seed</dt>\n",
       "\t\t<dd>200003</dd>\n",
       "\t<dt>$max_depth</dt>\n",
       "\t\t<dd>-1</dd>\n",
       "\t<dt>$min_gain_to_split</dt>\n",
       "\t\t<dd>0</dd>\n",
       "\t<dt>$min_sum_hessian_in_leaf</dt>\n",
       "\t\t<dd>0.001</dd>\n",
       "\t<dt>$lambda_l1</dt>\n",
       "\t\t<dd>0</dd>\n",
       "\t<dt>$lambda_l2</dt>\n",
       "\t\t<dd>0</dd>\n",
       "\t<dt>$max_bin</dt>\n",
       "\t\t<dd>31</dd>\n",
       "\t<dt>$bagging_fraction</dt>\n",
       "\t\t<dd>1</dd>\n",
       "\t<dt>$pos_bagging_fraction</dt>\n",
       "\t\t<dd>1</dd>\n",
       "\t<dt>$neg_bagging_fraction</dt>\n",
       "\t\t<dd>1</dd>\n",
       "\t<dt>$is_unbalance</dt>\n",
       "\t\t<dd>FALSE</dd>\n",
       "\t<dt>$scale_pos_weight</dt>\n",
       "\t\t<dd>1</dd>\n",
       "\t<dt>$drop_rate</dt>\n",
       "\t\t<dd>0.1</dd>\n",
       "\t<dt>$max_drop</dt>\n",
       "\t\t<dd>50</dd>\n",
       "\t<dt>$skip_drop</dt>\n",
       "\t\t<dd>0.5</dd>\n",
       "\t<dt>$extra_trees</dt>\n",
       "\t\t<dd>FALSE</dd>\n",
       "\t<dt>$num_iterations</dt>\n",
       "\t\t<dd>2687</dd>\n",
       "\t<dt>$learning_rate</dt>\n",
       "\t\t<dd>0.016392356370738</dd>\n",
       "\t<dt>$feature_fraction</dt>\n",
       "\t\t<dd>0.595481376865482</dd>\n",
       "\t<dt>$num_leaves</dt>\n",
       "\t\t<dd>1405</dd>\n",
       "\t<dt>$min_data_in_leaf</dt>\n",
       "\t\t<dd>13</dd>\n",
       "</dl>\n"
      ],
      "text/latex": [
       "\\begin{description}\n",
       "\\item[\\$boosting] 'gbdt'\n",
       "\\item[\\$objective] 'binary'\n",
       "\\item[\\$metric] 'auc'\n",
       "\\item[\\$first\\_metric\\_only] FALSE\n",
       "\\item[\\$boost\\_from\\_average] TRUE\n",
       "\\item[\\$feature\\_pre\\_filter] FALSE\n",
       "\\item[\\$force\\_row\\_wise] TRUE\n",
       "\\item[\\$verbosity] -100\n",
       "\\item[\\$seed] 200003\n",
       "\\item[\\$max\\_depth] -1\n",
       "\\item[\\$min\\_gain\\_to\\_split] 0\n",
       "\\item[\\$min\\_sum\\_hessian\\_in\\_leaf] 0.001\n",
       "\\item[\\$lambda\\_l1] 0\n",
       "\\item[\\$lambda\\_l2] 0\n",
       "\\item[\\$max\\_bin] 31\n",
       "\\item[\\$bagging\\_fraction] 1\n",
       "\\item[\\$pos\\_bagging\\_fraction] 1\n",
       "\\item[\\$neg\\_bagging\\_fraction] 1\n",
       "\\item[\\$is\\_unbalance] FALSE\n",
       "\\item[\\$scale\\_pos\\_weight] 1\n",
       "\\item[\\$drop\\_rate] 0.1\n",
       "\\item[\\$max\\_drop] 50\n",
       "\\item[\\$skip\\_drop] 0.5\n",
       "\\item[\\$extra\\_trees] FALSE\n",
       "\\item[\\$num\\_iterations] 2687\n",
       "\\item[\\$learning\\_rate] 0.016392356370738\n",
       "\\item[\\$feature\\_fraction] 0.595481376865482\n",
       "\\item[\\$num\\_leaves] 1405\n",
       "\\item[\\$min\\_data\\_in\\_leaf] 13\n",
       "\\end{description}\n"
      ],
      "text/markdown": [
       "$boosting\n",
       ":   'gbdt'\n",
       "$objective\n",
       ":   'binary'\n",
       "$metric\n",
       ":   'auc'\n",
       "$first_metric_only\n",
       ":   FALSE\n",
       "$boost_from_average\n",
       ":   TRUE\n",
       "$feature_pre_filter\n",
       ":   FALSE\n",
       "$force_row_wise\n",
       ":   TRUE\n",
       "$verbosity\n",
       ":   -100\n",
       "$seed\n",
       ":   200003\n",
       "$max_depth\n",
       ":   -1\n",
       "$min_gain_to_split\n",
       ":   0\n",
       "$min_sum_hessian_in_leaf\n",
       ":   0.001\n",
       "$lambda_l1\n",
       ":   0\n",
       "$lambda_l2\n",
       ":   0\n",
       "$max_bin\n",
       ":   31\n",
       "$bagging_fraction\n",
       ":   1\n",
       "$pos_bagging_fraction\n",
       ":   1\n",
       "$neg_bagging_fraction\n",
       ":   1\n",
       "$is_unbalance\n",
       ":   FALSE\n",
       "$scale_pos_weight\n",
       ":   1\n",
       "$drop_rate\n",
       ":   0.1\n",
       "$max_drop\n",
       ":   50\n",
       "$skip_drop\n",
       ":   0.5\n",
       "$extra_trees\n",
       ":   FALSE\n",
       "$num_iterations\n",
       ":   2687\n",
       "$learning_rate\n",
       ":   0.016392356370738\n",
       "$feature_fraction\n",
       ":   0.595481376865482\n",
       "$num_leaves\n",
       ":   1405\n",
       "$min_data_in_leaf\n",
       ":   13\n",
       "\n",
       "\n"
      ],
      "text/plain": [
       "$boosting\n",
       "[1] \"gbdt\"\n",
       "\n",
       "$objective\n",
       "[1] \"binary\"\n",
       "\n",
       "$metric\n",
       "[1] \"auc\"\n",
       "\n",
       "$first_metric_only\n",
       "[1] FALSE\n",
       "\n",
       "$boost_from_average\n",
       "[1] TRUE\n",
       "\n",
       "$feature_pre_filter\n",
       "[1] FALSE\n",
       "\n",
       "$force_row_wise\n",
       "[1] TRUE\n",
       "\n",
       "$verbosity\n",
       "[1] -100\n",
       "\n",
       "$seed\n",
       "[1] 200003\n",
       "\n",
       "$max_depth\n",
       "[1] -1\n",
       "\n",
       "$min_gain_to_split\n",
       "[1] 0\n",
       "\n",
       "$min_sum_hessian_in_leaf\n",
       "[1] 0.001\n",
       "\n",
       "$lambda_l1\n",
       "[1] 0\n",
       "\n",
       "$lambda_l2\n",
       "[1] 0\n",
       "\n",
       "$max_bin\n",
       "[1] 31\n",
       "\n",
       "$bagging_fraction\n",
       "[1] 1\n",
       "\n",
       "$pos_bagging_fraction\n",
       "[1] 1\n",
       "\n",
       "$neg_bagging_fraction\n",
       "[1] 1\n",
       "\n",
       "$is_unbalance\n",
       "[1] FALSE\n",
       "\n",
       "$scale_pos_weight\n",
       "[1] 1\n",
       "\n",
       "$drop_rate\n",
       "[1] 0.1\n",
       "\n",
       "$max_drop\n",
       "[1] 50\n",
       "\n",
       "$skip_drop\n",
       "[1] 0.5\n",
       "\n",
       "$extra_trees\n",
       "[1] FALSE\n",
       "\n",
       "$num_iterations\n",
       "[1] 2687\n",
       "\n",
       "$learning_rate\n",
       "[1] 0.01639236\n",
       "\n",
       "$feature_fraction\n",
       "[1] 0.5954814\n",
       "\n",
       "$num_leaves\n",
       "[1] 1405\n",
       "\n",
       "$min_data_in_leaf\n",
       "[1] 13\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# clase01\n",
    "dataset[, clase01 := ifelse(clase_ternaria %in% c(\"BAJA+1\", \"BAJA+2\"), 1L, 0L)]\n",
    "\n",
    "dataset_train <- dataset[foto_mes %in% PARAM$train_final]\n",
    "dataset_train[,.N,clase_ternaria]\n",
    "\n",
    "# dejo los datos en el formato que necesita LightGBM\n",
    "dtrain_final <- lgb.Dataset(\n",
    "  data= data.matrix(dataset_train[, campos_buenos, with= FALSE]),\n",
    "  label= dataset_train[, clase01]\n",
    ")\n",
    "\n",
    "# Entrenamiento final\n",
    "param_final <- modifyList(PARAM$lgbm$param_fijos,\n",
    "  PARAM$out$lgbm$mejores_hiperparametros)\n",
    "\n",
    "param_final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "8b27f6e6",
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "# este punto es muy SUTIL  y será revisado en la Clase 05\n",
    "\n",
    "param_normalizado <- copy(param_final)\n",
    "param_normalizado$min_data_in_leaf <-  round(param_final$min_data_in_leaf / PARAM$trainingstrategy$undersampling)\n",
    "\n",
    "# entreno LightGBM\n",
    "\n",
    "modelo_final <- lgb.train(\n",
    "  data= dtrain_final,\n",
    "  param= param_normalizado\n",
    ")\n",
    "\n",
    "# ahora imprimo la importancia de variables\n",
    "tb_importancia <- as.data.table(lgb.importance(modelo_final))\n",
    "archivo_importancia <- \"./Archivos Bayesiana/impo.txt\"\n",
    "\n",
    "fwrite(tb_importancia,\n",
    "  file= archivo_importancia,\n",
    "  sep= \"\\t\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "38d9a4f8",
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "# grabo a disco el modelo en un formato para seres humanos ... ponele ...\n",
    "lgb.save(modelo_final, \"./Archivos Bayesiana/modelo.txt\" )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3f26857",
   "metadata": {},
   "source": [
    "# Validación Final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "235126c5",
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "# aplico el modelo a los datos sin clase\n",
    "dfuture <- dataset[foto_mes %in% PARAM$future]\n",
    "\n",
    "# aplico el modelo a los datos nuevos\n",
    "prediccion <- predict(\n",
    "  modelo_final,\n",
    "  data.matrix(dfuture[, campos_buenos, with= FALSE])\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "e491d386",
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "# inicilizo el dataset  drealidad\n",
    "drealidad <- realidad_inicializar( dfuture, PARAM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "3d6f37c6",
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "# tabla de prediccion\n",
    "\n",
    "tb_prediccion <- dfuture[, list(numero_de_cliente, foto_mes)]\n",
    "tb_prediccion[, prob := prediccion ]\n",
    "\n",
    "# grabo las probabilidad del modelo\n",
    "fwrite(tb_prediccion,\n",
    "  file= \"./Archivos Bayesiana/prediccion.txt\",\n",
    "  sep= \"\\t\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "e6d860d0",
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Envios=0\t TOTAL=-20000  Public=-66666.67 Private=0\n",
      "Envios=100\t TOTAL=13200000  Public=11400000 Private=13971429\n",
      "Envios=200\t TOTAL=37600000  Public=20600000 Private=44885714\n",
      "Envios=300\t TOTAL=50800000  Public=37400000 Private=56542857\n",
      "Envios=400\t TOTAL=67200000  Public=38333333 Private=79571429\n",
      "Envios=500\t TOTAL=86000000  Public=49800000 Private=101514286\n",
      "Envios=600\t TOTAL=96800000  Public=60933333 Private=112171429\n",
      "Envios=700\t TOTAL=110000000  Public=69466667 Private=127371429\n",
      "Envios=800\t TOTAL=122400000  Public=83000000 Private=139285714\n",
      "Envios=900\t TOTAL=127600000  Public=85933333 Private=145457143\n",
      "Envios=1000\t TOTAL=140000000  Public=94000000 Private=159714286\n",
      "Envios=1100\t TOTAL=150800000  Public=105533333 Private=170200000\n",
      "Envios=1200\t TOTAL=159200000  Public=108733333 Private=180828571\n",
      "Envios=1300\t TOTAL=167600000  Public=112133333 Private=191371429\n",
      "Envios=1400\t TOTAL=177600000  Public=120866667 Private=201914286\n",
      "Envios=1500\t TOTAL=183600000  Public=121600000 Private=210171429\n",
      "Envios=1600\t TOTAL=188000000  Public=124866667 Private=215057143\n",
      "Envios=1700\t TOTAL=194800000  Public=136400000 Private=219828571\n",
      "Envios=1800\t TOTAL=198400000  Public=142333333 Private=222428571\n",
      "Envios=1900\t TOTAL=202800000  Public=151266667 Private=224885714\n",
      "Envios=2000\t TOTAL=206400000  Public=154933333 Private=228457143\n",
      "Envios=2100\t TOTAL=214800000  Public=153666667 Private=241000000\n",
      "Envios=2200\t TOTAL=221600000  Public=159333333 Private=248285714\n",
      "Envios=2300\t TOTAL=222800000  Public=162333333 Private=248714286\n",
      "Envios=2400\t TOTAL=226400000  Public=173533333 Private=249057143\n",
      "Envios=2500\t TOTAL=230000000  Public=176533333 Private=252914286\n",
      "Envios=2600\t TOTAL=234400000  Public=179600000 Private=257885714\n",
      "Envios=2700\t TOTAL=237200000  Public=180333333 Private=261571429\n",
      "Envios=2800\t TOTAL=240000000  Public=183733333 Private=264114286\n",
      "Envios=2900\t TOTAL=244400000  Public=189733333 Private=267828571\n",
      "Envios=3000\t TOTAL=246400000  Public=195133333 Private=268371429\n",
      "Envios=3100\t TOTAL=249200000  Public=196000000 Private=272000000\n",
      "Envios=3200\t TOTAL=252000000  Public=196866667 Private=275628571\n",
      "Envios=3300\t TOTAL=254000000  Public=200266667 Private=277028571\n",
      "Envios=3400\t TOTAL=256000000  Public=200733333 Private=279685714\n",
      "Envios=3500\t TOTAL=262000000  Public=212066667 Private=283400000\n",
      "Envios=3600\t TOTAL=265600000  Public=215266667 Private=287171429\n",
      "Envios=3700\t TOTAL=268400000  Public=216066667 Private=290828571\n",
      "Envios=3800\t TOTAL=272000000  Public=219733333 Private=294400000\n",
      "Envios=3900\t TOTAL=275600000  Public=222733333 Private=298257143\n",
      "Envios=4000\t TOTAL=280800000  Public=228266667 Private=303314286\n",
      "Envios=4100\t TOTAL=282800000  Public=234133333 Private=303657143\n",
      "Envios=4200\t TOTAL=285600000  Public=237600000 Private=306171429\n",
      "Envios=4300\t TOTAL=288400000  Public=243600000 Private=307600000\n",
      "Envios=4400\t TOTAL=289600000  Public=241466667 Private=310228571\n",
      "Envios=4500\t TOTAL=291600000  Public=242333333 Private=312714286\n",
      "Envios=4600\t TOTAL=297600000  Public=256333333 Private=315285714\n",
      "Envios=4700\t TOTAL=300400000  Public=257466667 Private=318800000\n",
      "Envios=4800\t TOTAL=304800000  Public=260600000 Private=323742857\n",
      "Envios=4900\t TOTAL=306800000  Public=263933333 Private=325171429\n",
      "Envios=5000\t TOTAL=310400000  Public=272600000 Private=326600000\n",
      "Envios=5100\t TOTAL=311600000  Public=270733333 Private=329114286\n",
      "Envios=5200\t TOTAL=311200000  Public=268600000 Private=329457143\n",
      "Envios=5300\t TOTAL=316400000  Public=271666667 Private=335571429\n",
      "Envios=5400\t TOTAL=320000000  Public=274800000 Private=339371429\n",
      "Envios=5500\t TOTAL=321200000  Public=278066667 Private=339685714\n",
      "Envios=5600\t TOTAL=320800000  Public=275933333 Private=340028571\n",
      "Envios=5700\t TOTAL=322000000  Public=274466667 Private=342371429\n",
      "Envios=5800\t TOTAL=324800000  Public=280733333 Private=343685714\n",
      "Envios=5900\t TOTAL=324400000  Public=278666667 Private=344000000\n",
      "Envios=6000\t TOTAL=325600000  Public=282000000 Private=344285714\n",
      "Envios=6100\t TOTAL=325200000  Public=282666667 Private=343428571\n",
      "Envios=6200\t TOTAL=326400000  Public=283133333 Private=344942857\n",
      "Envios=6300\t TOTAL=328400000  Public=280466667 Private=348942857\n",
      "Envios=6400\t TOTAL=328800000  Public=283466667 Private=348228571\n",
      "Envios=6500\t TOTAL=330800000  Public=286866667 Private=349628571\n",
      "Envios=6600\t TOTAL=331200000  Public=287466667 Private=349942857\n",
      "Envios=6700\t TOTAL=332400000  Public=288066667 Private=351400000\n",
      "Envios=6800\t TOTAL=335200000  Public=294133333 Private=352800000\n",
      "Envios=6900\t TOTAL=335600000  Public=297466667 Private=351942857\n",
      "Envios=7000\t TOTAL=335200000  Public=298066667 Private=351114286\n",
      "Envios=7100\t TOTAL=334800000  Public=295933333 Private=351457143\n",
      "Envios=7200\t TOTAL=335200000  Public=296733333 Private=351685714\n",
      "Envios=7300\t TOTAL=338000000  Public=300600000 Private=354028571\n",
      "Envios=7400\t TOTAL=340000000  Public=303866667 Private=355485714\n",
      "Envios=7500\t TOTAL=338800000  Public=302200000 Private=354485714\n",
      "Envios=7600\t TOTAL=340800000  Public=308600000 Private=354600000\n",
      "Envios=7700\t TOTAL=340400000  Public=309400000 Private=353685714\n",
      "Envios=7800\t TOTAL=342400000  Public=307800000 Private=357228571\n",
      "Envios=7900\t TOTAL=342000000  Public=308266667 Private=356457143\n",
      "Envios=8000\t TOTAL=341600000  Public=306333333 Private=356714286\n",
      "Envios=8100\t TOTAL=343600000  Public=304866667 Private=360200000\n",
      "Envios=8200\t TOTAL=344000000  Public=304866667 Private=360771429\n",
      "Envios=8300\t TOTAL=344400000  Public=303000000 Private=362142857\n",
      "Envios=8400\t TOTAL=344000000  Public=303800000 Private=361228571\n",
      "Envios=8500\t TOTAL=342800000  Public=303933333 Private=359457143\n",
      "Envios=8600\t TOTAL=341600000  Public=302333333 Private=358428571\n",
      "Envios=8700\t TOTAL=342000000  Public=304733333 Private=357971429\n",
      "Envios=8800\t TOTAL=340000000  Public=302533333 Private=356057143\n",
      "Envios=8900\t TOTAL=340400000  Public=305866667 Private=355200000\n",
      "Envios=9000\t TOTAL=339200000  Public=303866667 Private=354342857\n",
      "Envios=9100\t TOTAL=339600000  Public=301933333 Private=355742857\n",
      "Envios=9200\t TOTAL=339200000  Public=300333333 Private=355857143\n",
      "Envios=9300\t TOTAL=339600000  Public=303933333 Private=354885714\n",
      "Envios=9400\t TOTAL=342400000  Public=310400000 Private=356114286\n",
      "Envios=9500\t TOTAL=342000000  Public=308266667 Private=356457143\n",
      "Envios=9600\t TOTAL=344000000  Public=317000000 Private=355571429\n",
      "Envios=9700\t TOTAL=344400000  Public=315000000 Private=357000000\n",
      "Envios=9800\t TOTAL=344800000  Public=315466667 Private=357371429\n",
      "Envios=9900\t TOTAL=343600000  Public=313466667 Private=356514286\n",
      "Envios=10000\t TOTAL=344000000  Public=317066667 Private=355542857\n",
      "Envios=10100\t TOTAL=342800000  Public=315066667 Private=354685714\n",
      "Envios=10200\t TOTAL=342400000  Public=312666667 Private=355142857\n",
      "Envios=10300\t TOTAL=343600000  Public=316200000 Private=355342857\n",
      "Envios=10400\t TOTAL=344000000  Public=314200000 Private=356771429\n",
      "Envios=10500\t TOTAL=344400000  Public=317733333 Private=355828571\n",
      "Envios=10600\t TOTAL=342400000  Public=315200000 Private=354057143\n",
      "Envios=10700\t TOTAL=343600000  Public=316066667 Private=355400000\n",
      "Envios=10800\t TOTAL=342400000  Public=314000000 Private=354571429\n",
      "Envios=10900\t TOTAL=340400000  Public=312533333 Private=352342857\n",
      "Envios=11000\t TOTAL=340000000  Public=313133333 Private=351514286\n",
      "Envios=11100\t TOTAL=340400000  Public=311333333 Private=352857143\n",
      "Envios=11200\t TOTAL=340000000  Public=312000000 Private=352000000\n",
      "Envios=11300\t TOTAL=340400000  Public=312600000 Private=352314286\n",
      "Envios=11400\t TOTAL=339200000  Public=310533333 Private=351485714\n",
      "Envios=11500\t TOTAL=338000000  Public=310600000 Private=349742857\n",
      "Envios=11600\t TOTAL=336800000  Public=308733333 Private=348828571\n",
      "Envios=11700\t TOTAL=336400000  Public=306333333 Private=349285714\n",
      "Envios=11800\t TOTAL=336000000  Public=306800000 Private=348514286\n",
      "Envios=11900\t TOTAL=334000000  Public=305000000 Private=346428571\n",
      "Envios=12000\t TOTAL=333600000  Public=302866667 Private=346771429\n",
      "Envios=12100\t TOTAL=332400000  Public=303666667 Private=344714286\n",
      "Envios=12200\t TOTAL=332000000  Public=304333333 Private=343857143\n",
      "Envios=12300\t TOTAL=332400000  Public=305333333 Private=344000000\n",
      "Envios=12400\t TOTAL=332000000  Public=306200000 Private=343057143\n",
      "Envios=12500\t TOTAL=331600000  Public=304266667 Private=343314286\n",
      "Envios=12600\t TOTAL=332000000  Public=301866667 Private=344914286\n",
      "Envios=12700\t TOTAL=334000000  Public=305000000 Private=346428571\n",
      "Envios=12800\t TOTAL=333600000  Public=308000000 Private=344571429\n",
      "Envios=12900\t TOTAL=334000000  Public=308533333 Private=344914286\n",
      "Envios=13000\t TOTAL=332000000  Public=305800000 Private=343228571\n",
      "Envios=13100\t TOTAL=332400000  Public=309133333 Private=342371429\n",
      "Envios=13200\t TOTAL=332000000  Public=307533333 Private=342485714\n",
      "Envios=13300\t TOTAL=331600000  Public=308066667 Private=341685714\n",
      "Envios=13400\t TOTAL=331200000  Public=306066667 Private=341971429\n",
      "Envios=13500\t TOTAL=330000000  Public=306600000 Private=340028571\n",
      "Envios=13600\t TOTAL=330400000  Public=306933333 Private=340457143\n",
      "Envios=13700\t TOTAL=329200000  Public=307333333 Private=338571429\n",
      "Envios=13800\t TOTAL=329600000  Public=313533333 Private=336485714\n",
      "Envios=13900\t TOTAL=330000000  Public=314200000 Private=336771429\n",
      "Envios=14000\t TOTAL=329600000  Public=312533333 Private=336914286\n",
      "Envios=14100\t TOTAL=328400000  Public=310666667 Private=336000000\n",
      "Envios=14200\t TOTAL=328800000  Public=313866667 Private=335200000\n",
      "Envios=14300\t TOTAL=327600000  Public=314400000 Private=333257143\n",
      "Envios=14400\t TOTAL=327200000  Public=314933333 Private=332457143\n",
      "Envios=14500\t TOTAL=326000000  Public=313066667 Private=331542857\n",
      "Envios=14600\t TOTAL=324800000  Public=310800000 Private=330800000\n",
      "Envios=14700\t TOTAL=322800000  Public=309200000 Private=328628571\n",
      "Envios=14800\t TOTAL=321600000  Public=307000000 Private=327857143\n",
      "Envios=14900\t TOTAL=319600000  Public=305133333 Private=325800000\n",
      "Envios=15000\t TOTAL=318400000  Public=305733333 Private=323828571\n",
      "Envios=15100\t TOTAL=318800000  Public=308600000 Private=323171429\n",
      "Envios=15200\t TOTAL=317600000  Public=309000000 Private=321285714\n",
      "Envios=15300\t TOTAL=317200000  Public=307333333 Private=321428571\n",
      "Envios=15400\t TOTAL=316800000  Public=307733333 Private=320685714\n",
      "Envios=15500\t TOTAL=316400000  Public=305800000 Private=320942857\n",
      "Envios=15600\t TOTAL=315200000  Public=306666667 Private=318857143\n",
      "Envios=15700\t TOTAL=314000000  Public=305066667 Private=317828571\n",
      "Envios=15800\t TOTAL=315200000  Public=303666667 Private=320142857\n",
      "Envios=15900\t TOTAL=314000000  Public=301533333 Private=319342857\n",
      "Envios=16000\t TOTAL=315200000  Public=304466667 Private=319800000\n",
      "Envios=16100\t TOTAL=314000000  Public=302266667 Private=319028571\n",
      "Envios=16200\t TOTAL=316000000  Public=302933333 Private=321600000\n",
      "Envios=16300\t TOTAL=314800000  Public=300800000 Private=320800000\n",
      "Envios=16400\t TOTAL=313600000  Public=298866667 Private=319914286\n",
      "Envios=16500\t TOTAL=312400000  Public=297133333 Private=318942857\n",
      "Envios=16600\t TOTAL=312800000  Public=295200000 Private=320342857\n",
      "Envios=16700\t TOTAL=312400000  Public=293066667 Private=320685714\n",
      "Envios=16800\t TOTAL=310400000  Public=291000000 Private=318714286\n",
      "Envios=16900\t TOTAL=310000000  Public=289133333 Private=318942857\n",
      "Envios=17000\t TOTAL=308800000  Public=286733333 Private=318257143\n",
      "Envios=17100\t TOTAL=306800000  Public=284600000 Private=316314286\n",
      "Envios=17200\t TOTAL=305600000  Public=285266667 Private=314314286\n",
      "Envios=17300\t TOTAL=306000000  Public=285933333 Private=314600000\n",
      "Envios=17400\t TOTAL=304800000  Public=283600000 Private=313885714\n",
      "Envios=17500\t TOTAL=302800000  Public=281533333 Private=311914286\n",
      "Envios=17600\t TOTAL=303200000  Public=279133333 Private=313514286\n",
      "Envios=17700\t TOTAL=303600000  Public=282600000 Private=312600000\n",
      "Envios=17800\t TOTAL=304000000  Public=282933333 Private=313028571\n",
      "Envios=17900\t TOTAL=305200000  Public=281000000 Private=315571429\n",
      "Envios=18000\t TOTAL=304800000  Public=282066667 Private=314542857\n",
      "Envios=18100\t TOTAL=303600000  Public=280733333 Private=313400000\n",
      "Envios=18200\t TOTAL=303200000  Public=284466667 Private=311228571\n",
      "Envios=18300\t TOTAL=302000000  Public=285400000 Private=309114286\n",
      "Envios=18400\t TOTAL=300800000  Public=286000000 Private=307142857\n",
      "Envios=18500\t TOTAL=298800000  Public=284133333 Private=305085714\n",
      "Envios=18600\t TOTAL=298400000  Public=282133333 Private=305371429\n",
      "Envios=18700\t TOTAL=297200000  Public=279933333 Private=304600000\n",
      "Envios=18800\t TOTAL=295200000  Public=277866667 Private=302628571\n",
      "Envios=18900\t TOTAL=294800000  Public=275466667 Private=303085714\n",
      "Envios=19000\t TOTAL=296000000  Public=279000000 Private=303285714\n",
      "Envios=19100\t TOTAL=294000000  Public=277000000 Private=301285714\n",
      "Envios=19200\t TOTAL=292800000  Public=277400000 Private=299400000\n",
      "Envios=19300\t TOTAL=290800000  Public=275266667 Private=297457143\n",
      "Envios=19400\t TOTAL=288800000  Public=272933333 Private=295600000\n",
      "Envios=19500\t TOTAL=289200000  Public=270866667 Private=297057143\n",
      "Envios=19600\t TOTAL=288000000  Public=271200000 Private=295200000\n",
      "Envios=19700\t TOTAL=286800000  Public=269400000 Private=294257143\n",
      "Envios=19800\t TOTAL=285600000  Public=269400000 Private=292542857\n",
      "Envios=19900\t TOTAL=284400000  Public=267266667 Private=291742857\n",
      "Envios=20000\t TOTAL=283200000  Public=265866667 Private=290628571\n"
     ]
    }
   ],
   "source": [
    "# genero archivos con los  \"envios\" mejores\n",
    "# suba TODOS los archivos a Kaggle\n",
    "\n",
    "# ordeno por probabilidad descendente\n",
    "setorder(tb_prediccion, -prob)\n",
    "\n",
    "dir.create(\"kaggle\", showWarnings=FALSE)\n",
    "resultados <- data.table()\n",
    "\n",
    "for (envios in PARAM$cortes) {\n",
    "\n",
    "  tb_prediccion[, Predicted := 0L] # seteo inicial a 0\n",
    "  tb_prediccion[1:envios, Predicted := 1L] # marco los primeros\n",
    "\n",
    "  archivo_kaggle <- paste0(\"./kaggle/\", PARAM$experimento, \"_\", envios, \".csv\")\n",
    "\n",
    "  # grabo el archivo\n",
    "  fwrite(tb_prediccion[, list(numero_de_cliente, Predicted)],\n",
    "    file= archivo_kaggle,\n",
    "    sep= \",\"\n",
    "  )\n",
    "\n",
    "  res <- realidad_evaluar( drealidad, tb_prediccion)\n",
    "  resultados <- rbind(\n",
    "    resultados,\n",
    "    data.table(\n",
    "      clientes = envios,\n",
    "      ganancia_total = res$total,\n",
    "      ganancia_public = res$public,\n",
    "      ganancia_private = res$private\n",
    "    )\n",
    "  )\n",
    "  \n",
    "\n",
    "  options(scipen = 999)\n",
    "  cat( \"Envios=\", envios, \"\\t\",\n",
    "    \" TOTAL=\", res$total,\n",
    "    \"  Public=\", res$public,\n",
    "    \" Private=\", res$private,\n",
    "    \"\\n\",\n",
    "    sep= \"\"\n",
    "  )\n",
    "\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "486c114c",
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "plot without title"
      ]
     },
     "metadata": {
      "image/png": {
       "height": 420,
       "width": 420
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# pasamos a formato largo\n",
    "resultados_long <- melt(\n",
    "  resultados,\n",
    "  id.vars = \"clientes\",\n",
    "  measure.vars = c(\"ganancia_total\", \"ganancia_public\", \"ganancia_private\"),\n",
    "  variable.name = \"tipo\",\n",
    "  value.name = \"ganancia\"\n",
    ")\n",
    "\n",
    "# calcular máximos por tipo\n",
    "maximos <- resultados_long[, .SD[which.max(ganancia)], by = tipo]\n",
    "\n",
    "# crear etiquetas personalizadas para la leyenda\n",
    "etiquetas <- paste0(\n",
    "  maximos$tipo,\n",
    "  \" (envíos = \", maximos$clientes, \", máx = \", format(maximos$ganancia, big.mark = \",\"), \")\"\n",
    ")\n",
    "names(etiquetas) <- maximos$tipo\n",
    "\n",
    "# gráfico\n",
    "ggplot(resultados_long, aes(x = clientes, y = ganancia, color = tipo)) +\n",
    "  geom_line(linewidth = 1) +\n",
    "  # agregar puntos en los máximos\n",
    "  geom_point(data = maximos, aes(x = clientes, y = ganancia, color = tipo), size = 3) +\n",
    "  labs(\n",
    "    title = \"Curvas de Ganancia\",\n",
    "    x = \"Clientes\",\n",
    "    y = \"Ganancia\",\n",
    "    color = \"Máximos\"\n",
    "  ) +\n",
    "  scale_color_manual(values = c(\"ganancia_total\" = \"steelblue\",\n",
    "                                \"ganancia_public\" = \"forestgreen\",\n",
    "                                \"ganancia_private\" = \"firebrick\"),\n",
    "                     labels = etiquetas) +\n",
    "  theme_minimal() +\n",
    "  theme(\n",
    "    plot.margin = margin(10, 10, 10, 10),  # top, right, bottom, left\n",
    "    legend.position = \"bottom\")+\n",
    "  guides(color = guide_legend(nrow = 3, byrow = TRUE))\n",
    "  #+ ggsave(\"curvas.png\", width = 10, height = 6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70050a36",
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "'mar oct 07 14:37:22 2025'"
      ],
      "text/latex": [
       "'mar oct 07 14:37:22 2025'"
      ],
      "text/markdown": [
       "'mar oct 07 14:37:22 2025'"
      ],
      "text/plain": [
       "[1] \"mar oct 07 14:37:22 2025\""
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "format(Sys.time(), \"%a %b %d %X %Y\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2244557",
   "metadata": {},
   "source": [
    "# Ensemble"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a2be6b1",
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iniciando entrenamiento del ensamble con 5 semillas...\n"
     ]
    }
   ],
   "source": [
    "# Definir las 5 semillas fijas para el ensemble\n",
    "semillas <- c(200003,300007,400009,500009,600011)\n",
    "\n",
    "# Lista vacía para ir guardando la predicción de cada modelo\n",
    "lista_predicciones <- list()\n",
    "\n",
    "# clase01\n",
    "dataset[, clase01 := ifelse(clase_ternaria %in% c(\"BAJA+1\", \"BAJA+2\"), 1L, 0L)]\n",
    "\n",
    "dataset_train <- dataset[foto_mes %in% PARAM$train_final]\n",
    "\n",
    "# dejo los datos en el formato que necesita LightGBM\n",
    "dtrain_final <- lgb.Dataset(\n",
    "  data = data.matrix(dataset_train[, campos_buenos, with = FALSE]),\n",
    "  label = dataset_train[, clase01]\n",
    ")\n",
    "\n",
    "# Entrenamiento final\n",
    "param_final <- modifyList(PARAM$lgbm$param_fijos,\n",
    "                          PARAM$out$lgbm$mejores_hiperparametros)\n",
    "\n",
    "# este punto es muy SUTIL  y será revisado en la Clase 05\n",
    "param_normalizado <- copy(param_final)\n",
    "param_normalizado$min_data_in_leaf <- round(param_final$min_data_in_leaf / PARAM$trainingstrategy$undersampling)\n",
    "\n",
    "# Dataset de predicción (lo definimos una sola vez fuera del bucle)\n",
    "dfuture <- dataset[foto_mes %in% PARAM$future]\n",
    "\n",
    "cat(\"Iniciando entrenamiento del ensamble con\", length(semillas), \"semillas...\\n\")\n",
    "\n",
    "### Bucle para entrenar un modelo por cada semilla\n",
    "for (semilla_actual in semillas) {\n",
    "  print(paste0(\"\\nEntrenando modelo con semilla: \", semilla_actual, \"\\n\"))\n",
    "\n",
    "  param_normalizado$seed <- semilla_actual\n",
    "  \n",
    "  # entreno LightGBM\n",
    "  modelo_final <- lgb.train(\n",
    "    data = dtrain_final,\n",
    "    param = param_normalizado\n",
    "  )\n",
    "  \n",
    "  # aplico el modelo a los datos nuevos\n",
    "  prediccion_individual <- predict(\n",
    "    modelo_final,\n",
    "    data.matrix(dfuture[, campos_buenos, with = FALSE])\n",
    "  )\n",
    "  \n",
    "  # Creamos una tabla con la predicción de esta semilla\n",
    "  tb_prediccion_individual <- dfuture[, list(numero_de_cliente, foto_mes)] \n",
    "  tb_prediccion_individual[, prob := prediccion_individual]\n",
    "  \n",
    "  ### Guardamos la predicción en nuestra lista\n",
    "  lista_predicciones[[as.character(semilla_actual)]] <- tb_prediccion_individual\n",
    "  \n",
    "} # Fin del bucle de semillas\n",
    "\n",
    "cat(\"\\nTodas las semillas procesadas. Creando el ensamble final...\\n\")\n",
    "\n",
    "# Juntamos todas las tablas de la lista en una sola\n",
    "predicciones_todas <- rbindlist(lista_predicciones)\n",
    "\n",
    "# Agrupamos por cliente y calculamos la probabilidad promedio\n",
    "tb_prediccion <- predicciones_todas[, .(prob = mean(prob)), by = .(numero_de_cliente, foto_mes)]\n",
    "\n",
    "cat(\"Ensamble creado con éxito. Probabilidades promediadas.\\n\\n\")\n",
    "\n",
    "# inicilizo el dataset  drealidad\n",
    "drealidad <- realidad_inicializar(dfuture, PARAM)\n",
    "\n",
    "# ordeno por probabilidad descendente\n",
    "setorder(tb_prediccion, -prob)\n",
    "\n",
    "dir.create(\"kaggle_promedidado\")\n",
    "resultados <- data.table()\n",
    "\n",
    "for (envios in PARAM$cortes) {\n",
    "  \n",
    "  tb_prediccion[, Predicted := 0L] # seteo inicial a 0\n",
    "  tb_prediccion[1:envios, Predicted := 1L] # marco los primeros\n",
    "  \n",
    "  archivo_kaggle <- paste0(\"./kaggle_promedidado/\", PARAM$experimento, \"_\", envios, \".csv\")\n",
    "  \n",
    "  # grabo el archivo\n",
    "  fwrite(tb_prediccion[, list(numero_de_cliente, Predicted)],\n",
    "         file = archivo_kaggle,\n",
    "         sep = \",\"\n",
    "  )\n",
    "  \n",
    "  res <- realidad_evaluar(drealidad, tb_prediccion)\n",
    "  resultados <- rbind(\n",
    "    resultados,\n",
    "    data.table(\n",
    "      clientes = envios,\n",
    "      ganancia_total = res$total,\n",
    "      ganancia_public = res$public,\n",
    "      ganancia_private = res$private\n",
    "    )\n",
    "  )\n",
    "  \n",
    "  options(scipen = 999)\n",
    "  cat(\"Envios=\", envios, \"\\t\",\n",
    "      \" TOTAL=\", res$total,\n",
    "      \"  Public=\", res$public,\n",
    "      \"  Private=\", res$private,\n",
    "      \"\\n\",\n",
    "      sep = \"\"\n",
    "  )\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99f4aa88",
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "# pasamos a formato largo\n",
    "resultados_long <- melt(\n",
    "  resultados,\n",
    "  id.vars = \"clientes\",\n",
    "  measure.vars = c(\"ganancia_total\", \"ganancia_public\", \"ganancia_private\"),\n",
    "  variable.name = \"tipo\",\n",
    "  value.name = \"ganancia\"\n",
    ")\n",
    "\n",
    "# calcular máximos por tipo\n",
    "maximos <- resultados_long[, .SD[which.max(ganancia)], by = tipo]\n",
    "\n",
    "# crear etiquetas personalizadas para la leyenda\n",
    "etiquetas <- paste0(\n",
    "  maximos$tipo,\n",
    "  \" (envíos = \", maximos$clientes, \", máx = \", format(maximos$ganancia, big.mark = \",\"), \")\"\n",
    ")\n",
    "names(etiquetas) <- maximos$tipo\n",
    "\n",
    "# gráfico\n",
    "ggplot(resultados_long, aes(x = clientes, y = ganancia, color = tipo)) +\n",
    "  geom_line(linewidth  = 1) +\n",
    "  # agregar puntos en los máximos\n",
    "  geom_point(data = maximos, aes(x = clientes, y = ganancia, color = tipo), size  = 3) +\n",
    "  labs(\n",
    "    title = \"Curvas de Ganancia\",\n",
    "    x = \"Clientes\",\n",
    "    y = \"Ganancia\",\n",
    "    color = \"Máximos\"\n",
    "  ) +\n",
    "  scale_color_manual(values = c(\"ganancia_total\" = \"steelblue\",\n",
    "                                \"ganancia_public\" = \"forestgreen\",\n",
    "                                \"ganancia_private\" = \"firebrick\"),\n",
    "                     labels = etiquetas) +\n",
    "  theme_minimal() +\n",
    "  theme(\n",
    "    plot.margin = margin(10, 10, 10, 10),  # top, right, bottom, left\n",
    "    legend.position = \"bottom\")+\n",
    "  guides(color = guide_legend(nrow = 3, byrow = TRUE))\n",
    "  #+ ggsave(\"curvas_ensemble.png\", width = 10, height = 6)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "R",
   "language": "R",
   "name": "ir"
  },
  "language_info": {
   "codemirror_mode": "r",
   "file_extension": ".r",
   "mimetype": "text/x-r-source",
   "name": "R",
   "pygments_lexer": "r",
   "version": "4.4.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
