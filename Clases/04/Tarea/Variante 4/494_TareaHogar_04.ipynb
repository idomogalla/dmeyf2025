{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0cEmzeUKFkPh"
      },
      "source": [
        "# Tarea para el Hogar 04"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DenyKXkiJ5JN"
      },
      "source": [
        "##  1. Big Picture"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l-K2_ZsZGrVD"
      },
      "source": [
        "LightGBM es el algoritmo estado del arte para datasets estructurados.\n",
        "<br> La Bayesian Optimization es el estado del arte para optimización de hiperparámetros\n",
        "<br> Las soluciones a las tres competencias de la asignatura contendrán LightGBMs y Bayesian Optimizations\n",
        "<br> LightGBM ha aumentado en forma no darwiniana sus hiperparámetros en los últimos ocho años; no todos los existentes son útiles.\n",
        "<br> Es necesario lograr entender cuales son los hiperparámetros relevantes de LightGBM"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K9GkTOk5J9t3"
      },
      "source": [
        "## 2. Hiperparámetros del LightGBM"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VmEFy0ukKL5T"
      },
      "source": [
        "Los objetivos de esta tarea son:\n",
        "\n",
        "\n",
        "*   Aumentar la rentabilidad de la campaña de marketing de retención proactiva de clientes.\n",
        "*   Generar un mejor modelo optimizando sus hiperparámetros\n",
        "*   Conceptual : investigar los mas relevantes hiperparámetros de LightGBM\n",
        "*   Familiarizarse con la Bayesian Optimization, sus largos tiempos de corrida y opciones para reducirlos\n",
        "*   Familiarizarse con el uso de máquinas virtuales de Google Colab\n",
        "*   Ver un pipeline completo de optimización de hiperparámetros y puesta en producción"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5yvlS6JQLRMd"
      },
      "source": [
        "LightGBM cuenta con mas de 60 hiperparámetros, siendo posible utilizar 40 al mismo tiempo, aunque no razonable.\n",
        "<br> La documentación oficial de los hiperparámetros de LightGBM es  https://lightgbm.readthedocs.io/en/latest/Parameters.html#core-parameters\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eydI4YNAsFaf"
      },
      "source": [
        "Se lo alerta sobre que una Optimizacion Bayesiana lleva varias horas de corrida, y usted deberá correr VARIAS optimizaciones para descubrir cuales parámetros conviene optimizar.\n",
        "<br> A pesar que la próxima clase es recien en viernes 01 de agosto, inicie la tarea con tiempo, aprenda a planificar estratégicamente sus corridas como un@ científ@  de datos."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RzU4S0SeMcpp"
      },
      "source": [
        "Es necesario investigar cuales son los hiperparámetros de LightGBM que vale la pena optimizar en una Bayesian Optimization, ya que los realmente utiles son apenas un reducido subconjunto.\n",
        "<br>Usted deberá investigar cuales son los hiperparámetros mas relevantes de LightGBM, su primer alternativa es preguntándole a su amigo con capacidades especiales ChatGPT o sus endogámicos familiares Claude, DeepSeek, Gemini, Grok, etc\n",
        "<br> La segunda alternativa es la propia documentación de LightGBM  https://lightgbm.readthedocs.io/en/latest/Parameters-Tuning.html\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LNptUgI_NWWG"
      },
      "source": [
        "Adicionalmente podra buscar información como la que proveen esta diminuta muestra aleatoria de artículos ligeros:\n",
        "*  https://medium.com/@sarahzouinina/a-deep-dive-into-lightgbm-how-to-choose-and-tune-parameters-7c584945842e\n",
        "*  https://www.kaggle.com/code/somang1418/tuning-hyperparameters-under-10-minutes-lgbm\n",
        "*  https://towardsdatascience.com/beginners-guide-to-the-must-know-lightgbm-hyperparameters-a0005a812702/\n",
        "\n",
        "\n",
        "<br>  La muestra anterior se brinda a modo de ejemplo, usted deberá buscar muuuuchas  fuentes adicionales de información\n",
        "<br> Tenga presente que LightGBM es el estado del arte en modelado predictivo para datasets estructurado, que son el 90% del trabajo del 95% de los Data Scientists en Argentina."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WpUThBojODyK"
      },
      "source": [
        "El desafío de esta tarea es:\n",
        "* Qué hiperparparámetros conviene optimizar?  Las recomendaciones de los artículos ligeros es siempre sensata?  Sus autores realmente hicieron experimentos o son siemplemente escritores de entretenimiento carente de base científica?\n",
        "* Elegidos los hiperparámetros, cual es el  <desde, hasta> que se debe utilizar en la Bayesian Optimization ?\n",
        "* Realmente vale la pena optimizar 10 o 16 hiperparámetros al mismo tiempo ?  No resulta contraproducente una búsqueda en un espacio de tal alta dimensionalidad ?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PX0qg_c0yqob"
      },
      "source": [
        "#### 2.1  Seteo del ambiente en Google Colab"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NGY7H9xza7Zr"
      },
      "source": [
        "Esta parte se debe correr con el runtime en Python3\n",
        "<br>Ir al menu, Runtime -> Change Runtime Type -> Runtime type ->  **Python 3**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7PupIBNba7Zr"
      },
      "source": [
        "Conectar la virtual machine donde esta corriendo Google Colab con el  Google Drive, para poder tener persistencia de archivos"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9LpZCst5a7Zs",
        "vscode": {
          "languageId": "r"
        }
      },
      "outputs": [],
      "source": [
        "# primero establecer el Runtime de Python 3\n",
        "from google.colab import drive\n",
        "drive.mount('/content/.drive')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JYC_F-wla7Zs"
      },
      "source": [
        "Para correr la siguiente celda es fundamental en Arranque en Frio haber copiado el archivo kaggle.json al Google Drive, en la carpeta indicada en el instructivo\n",
        "\n",
        "<br>los siguientes comando estan en shell script de Linux\n",
        "*   Crear las carpetas en el Google Drive\n",
        "*   \"instalar\" el archivo kaggle.json desde el Google Drive a la virtual machine para que pueda ser utilizado por la libreria  kaggle de Python\n",
        "*   Bajar el  **dataset_pequeno**  al  Google Drive  y tambien al disco local de la virtual machine que esta corriendo Google Colab\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XWLelftXa7Zt",
        "vscode": {
          "languageId": "r"
        }
      },
      "outputs": [],
      "source": [
        "%%shell\n",
        "\n",
        "mkdir -p \"/content/.drive/My Drive/dmeyf\"\n",
        "mkdir -p \"/content/buckets\"\n",
        "ln -s \"/content/.drive/My Drive/dmeyf\" /content/buckets/b1\n",
        "\n",
        "\n",
        "mkdir -p /content/buckets/b1/exp\n",
        "mkdir -p /content/buckets/b1/datasets\n",
        "mkdir -p /content/datasets\n",
        "\n",
        "\n",
        "\n",
        "archivo_origen=\"https://storage.googleapis.com/open-courses/dmeyf2025-e4a2/competencia_01_crudo.csv\"\n",
        "archivo_destino=\"/content/datasets/competencia_01_crudo.csv\"\n",
        "archivo_destino_bucket=\"/content/buckets/b1/datasets/competencia_01_crudo.csv\"\n",
        "\n",
        "if ! test -f $archivo_destino_bucket; then\n",
        "  wget  $archivo_origen  -O $archivo_destino_bucket\n",
        "fi\n",
        "\n",
        "\n",
        "if ! test -f $archivo_destino; then\n",
        "  cp  $archivo_destino_bucket  $archivo_destino\n",
        "fi\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dseB4qb9RqUb"
      },
      "source": [
        "### Generacion de la clase_ternaria"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LCEnE_02RuIQ"
      },
      "source": [
        "Esta parte se debe correr con el runtime en lenguaje **R** Ir al menu, Runtime -> Change Runtime Tipe -> Runtime type -> R"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "P863YZB9R1Ua",
        "vscode": {
          "languageId": "r"
        }
      },
      "outputs": [],
      "source": [
        "require( \"data.table\" )\n",
        "\n",
        "# leo el dataset\n",
        "dataset <- fread(\"../../Competencia 01/competencia_01_crudo.csv\" )\n",
        "\n",
        "# calculo el periodo0 consecutivo\n",
        "dsimple <- dataset[, list(\n",
        "    \"pos\" = .I,\n",
        "    numero_de_cliente,\n",
        "    periodo0 = as.integer(foto_mes/100)*12 +  foto_mes%%100 ) ]\n",
        "\n",
        "\n",
        "# ordeno\n",
        "setorder( dsimple, numero_de_cliente, periodo0 )\n",
        "\n",
        "# calculo topes\n",
        "periodo_ultimo <- dsimple[, max(periodo0) ]\n",
        "periodo_anteultimo <- periodo_ultimo - 1\n",
        "\n",
        "\n",
        "# calculo los leads de orden 1 y 2\n",
        "dsimple[, c(\"periodo1\", \"periodo2\") :=\n",
        "    shift(periodo0, n=1:2, fill=NA, type=\"lead\"),  numero_de_cliente ]\n",
        "\n",
        "# assign most common class values = \"CONTINUA\"\n",
        "dsimple[ periodo0 < periodo_anteultimo, clase_ternaria := \"CONTINUA\" ]\n",
        "\n",
        "# calculo BAJA+1\n",
        "dsimple[ periodo0 < periodo_ultimo &\n",
        "    ( is.na(periodo1) | periodo0 + 1 < periodo1 ),\n",
        "    clase_ternaria := \"BAJA+1\" ]\n",
        "\n",
        "# calculo BAJA+2\n",
        "dsimple[ periodo0 < periodo_anteultimo & (periodo0+1 == periodo1 )\n",
        "    & ( is.na(periodo2) | periodo0 + 2 < periodo2 ),\n",
        "    clase_ternaria := \"BAJA+2\" ]\n",
        "\n",
        "\n",
        "# pego el resultado en el dataset original y grabo\n",
        "setorder( dsimple, pos )\n",
        "dataset[, clase_ternaria := dsimple$clase_ternaria ]\n",
        "\n",
        "fwrite( dataset,\n",
        "    file =  \"./competencia_01.csv.gz\",\n",
        "    sep = \",\"\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "S3hL7tv8W4rn",
        "vscode": {
          "languageId": "r"
        }
      },
      "outputs": [],
      "source": [
        "setorder( dataset, foto_mes, clase_ternaria, numero_de_cliente)\n",
        "dataset[, .N, list(foto_mes, clase_ternaria)]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oSKhZRToy2F7"
      },
      "source": [
        "### 2.2 Optimizacion Hiperparámetros"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2kwPpHAtSmix"
      },
      "source": [
        "Esta parte se debe correr con el runtime en lenguaje R Ir al menu, Runtime -> Change Runtime Type -> Runtime type -> R"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xp4-Bj3aYI8d"
      },
      "source": [
        "### 2.2.1 Inicio"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zy8YTZfESxeJ"
      },
      "source": [
        "limpio el ambiente de R"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "gBq__iAdQliq",
        "vscode": {
          "languageId": "r"
        }
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "'mar sept 30 23:56:46 2025'"
            ],
            "text/latex": [
              "'mar sept 30 23:56:46 2025'"
            ],
            "text/markdown": [
              "'mar sept 30 23:56:46 2025'"
            ],
            "text/plain": [
              "[1] \"mar sept 30 23:56:46 2025\""
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "format(Sys.time(), \"%a %b %d %X %Y\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "7rdVrBojS1IV",
        "vscode": {
          "languageId": "r"
        }
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<table class=\"dataframe\">\n",
              "<caption>A matrix: 2 × 6 of type dbl</caption>\n",
              "<thead>\n",
              "\t<tr><th></th><th scope=col>used</th><th scope=col>(Mb)</th><th scope=col>gc trigger</th><th scope=col>(Mb)</th><th scope=col>max used</th><th scope=col>(Mb)</th></tr>\n",
              "</thead>\n",
              "<tbody>\n",
              "\t<tr><th scope=row>Ncells</th><td> 658050</td><td>35.2</td><td>1431192</td><td>76.5</td><td>1431192</td><td>76.5</td></tr>\n",
              "\t<tr><th scope=row>Vcells</th><td>1220461</td><td> 9.4</td><td>8388608</td><td>64.0</td><td>1907896</td><td>14.6</td></tr>\n",
              "</tbody>\n",
              "</table>\n"
            ],
            "text/latex": [
              "A matrix: 2 × 6 of type dbl\n",
              "\\begin{tabular}{r|llllll}\n",
              "  & used & (Mb) & gc trigger & (Mb) & max used & (Mb)\\\\\n",
              "\\hline\n",
              "\tNcells &  658050 & 35.2 & 1431192 & 76.5 & 1431192 & 76.5\\\\\n",
              "\tVcells & 1220461 &  9.4 & 8388608 & 64.0 & 1907896 & 14.6\\\\\n",
              "\\end{tabular}\n"
            ],
            "text/markdown": [
              "\n",
              "A matrix: 2 × 6 of type dbl\n",
              "\n",
              "| <!--/--> | used | (Mb) | gc trigger | (Mb) | max used | (Mb) |\n",
              "|---|---|---|---|---|---|---|\n",
              "| Ncells |  658050 | 35.2 | 1431192 | 76.5 | 1431192 | 76.5 |\n",
              "| Vcells | 1220461 |  9.4 | 8388608 | 64.0 | 1907896 | 14.6 |\n",
              "\n"
            ],
            "text/plain": [
              "       used    (Mb) gc trigger (Mb) max used (Mb)\n",
              "Ncells  658050 35.2 1431192    76.5 1431192  76.5\n",
              "Vcells 1220461  9.4 8388608    64.0 1907896  14.6"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# limpio la memoria\n",
        "rm(list=ls(all.names=TRUE)) # remove all objects\n",
        "gc(full=TRUE, verbose=FALSE) # garbage collection"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kuPfQ7ksjwW3"
      },
      "source": [
        "### 2.2.2 Carga de Librerias"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B8BaSFlGfvma"
      },
      "source": [
        "Esta parte lleva varios minutos la primera vez en Google Colab"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "lVyxLaJ1j1J_",
        "vscode": {
          "languageId": "r"
        }
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Cargando paquete requerido: data.table\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Cargando paquete requerido: parallel\n",
            "\n",
            "Cargando paquete requerido: R.utils\n",
            "\n",
            "Cargando paquete requerido: R.oo\n",
            "\n",
            "Cargando paquete requerido: R.methodsS3\n",
            "\n",
            "R.methodsS3 v1.8.2 (2022-06-13 22:00:14 UTC) successfully loaded. See ?R.methodsS3 for help.\n",
            "\n",
            "R.oo v1.27.1 (2025-05-02 21:00:05 UTC) successfully loaded. See ?R.oo for help.\n",
            "\n",
            "\n",
            "Adjuntando el paquete: 'R.oo'\n",
            "\n",
            "\n",
            "The following object is masked from 'package:R.methodsS3':\n",
            "\n",
            "    throw\n",
            "\n",
            "\n",
            "The following objects are masked from 'package:methods':\n",
            "\n",
            "    getClasses, getMethods\n",
            "\n",
            "\n",
            "The following objects are masked from 'package:base':\n",
            "\n",
            "    attach, detach, load, save\n",
            "\n",
            "\n",
            "R.utils v2.13.0 (2025-02-24 21:20:02 UTC) successfully loaded. See ?R.utils for help.\n",
            "\n",
            "\n",
            "Adjuntando el paquete: 'R.utils'\n",
            "\n",
            "\n",
            "The following object is masked from 'package:utils':\n",
            "\n",
            "    timestamp\n",
            "\n",
            "\n",
            "The following objects are masked from 'package:base':\n",
            "\n",
            "    cat, commandArgs, getOption, isOpen, nullfile, parse, use, warnings\n",
            "\n",
            "\n",
            "Cargando paquete requerido: primes\n",
            "\n",
            "Cargando paquete requerido: rlist\n",
            "\n",
            "Cargando paquete requerido: yaml\n",
            "\n",
            "Cargando paquete requerido: lightgbm\n",
            "\n",
            "Cargando paquete requerido: DiceKriging\n",
            "\n",
            "Cargando paquete requerido: mlrMBO\n",
            "\n",
            "Cargando paquete requerido: mlr\n",
            "\n",
            "Cargando paquete requerido: ParamHelpers\n",
            "\n",
            "\n",
            "Adjuntando el paquete: 'ParamHelpers'\n",
            "\n",
            "\n",
            "The following object is masked from 'package:R.utils':\n",
            "\n",
            "    isVector\n",
            "\n",
            "\n",
            "\n",
            "Adjuntando el paquete: 'mlr'\n",
            "\n",
            "\n",
            "The following objects are masked from 'package:R.utils':\n",
            "\n",
            "    resample, setThreshold\n",
            "\n",
            "\n",
            "Cargando paquete requerido: smoof\n",
            "\n",
            "Cargando paquete requerido: checkmate\n",
            "\n",
            "\n",
            "Adjuntando el paquete: 'checkmate'\n",
            "\n",
            "\n",
            "The following object is masked from 'package:DiceKriging':\n",
            "\n",
            "    checkNames\n",
            "\n",
            "\n",
            "The following object is masked from 'package:R.utils':\n",
            "\n",
            "    asInt\n",
            "\n",
            "\n",
            "\n",
            "Adjuntando el paquete: 'smoof'\n",
            "\n",
            "\n",
            "The following objects are masked from 'package:R.oo':\n",
            "\n",
            "    getDescription, getName\n",
            "\n",
            "\n",
            "Cargando paquete requerido: ggplot2\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# cargo las librerias que necesito\n",
        "if(!require(\"data.table\")) install.packages(\"data.table\")\n",
        "require(\"data.table\")\n",
        "\n",
        "if(!require(\"parallel\")) install.packages(\"parallel\")\n",
        "require(\"parallel\")\n",
        "\n",
        "if(!require(\"R.utils\")) install.packages(\"R.utils\")\n",
        "require(\"R.utils\")\n",
        "\n",
        "if( !require(\"primes\") ) install.packages(\"primes\")\n",
        "require(\"primes\")\n",
        "\n",
        "if( !require(\"utils\") ) install.packages(\"utils\")\n",
        "require(\"utils\")\n",
        "\n",
        "if( !require(\"rlist\") ) install.packages(\"rlist\")\n",
        "require(\"rlist\")\n",
        "\n",
        "if( !require(\"yaml\")) install.packages(\"yaml\")\n",
        "require(\"yaml\")\n",
        "\n",
        "if( !require(\"lightgbm\") ) install.packages(\"lightgbm\")\n",
        "require(\"lightgbm\")\n",
        "\n",
        "if( !require(\"DiceKriging\") ) install.packages(\"DiceKriging\")\n",
        "require(\"DiceKriging\")\n",
        "\n",
        "if( !require(\"mlrMBO\") ) install.packages(\"mlrMBO\")\n",
        "require(\"mlrMBO\")\n",
        "\n",
        "if( !require(\"ggplot2\") ) install.packages(\"ggplot2\")\n",
        "require(\"ggplot2\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Iz-6Qt6BUaA3"
      },
      "source": [
        "### 2.2.3 Definicion de Parametros"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cOdlKd7lUm2I"
      },
      "source": [
        "aqui debe cargar SU semilla primigenia\n",
        "<br>recuerde cambiar el numero de experimento en cada corrida nueva"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "ASYkebOu2mF6",
        "vscode": {
          "languageId": "r"
        }
      },
      "outputs": [],
      "source": [
        "PARAM <- list()\n",
        "PARAM$experimento <- \"4940_V4\"\n",
        "PARAM$semilla_primigenia <- 200003"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "ezOhQdbA293o",
        "vscode": {
          "languageId": "r"
        }
      },
      "outputs": [],
      "source": [
        "# training y future\n",
        "PARAM$train <- c(202101,202102)\n",
        "PARAM$train_final <- c(202101,202102)\n",
        "PARAM$future <- c(202104)\n",
        "PARAM$semilla_kaggle <- 314159 #Semilla para el modelo final que va a Kaggle, primeros números de pi que sean primos.\n",
        "PARAM$cortes <- seq(0, 19000, by= 100)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "jtB0Lub42rHO",
        "vscode": {
          "languageId": "r"
        }
      },
      "outputs": [],
      "source": [
        "# un undersampling de 0.1  toma solo el 10% de los CONTINUA\n",
        "# undersampling de 1.0  implica tomar TODOS los datos\n",
        "\n",
        "PARAM$trainingstrategy$undersampling <- 0.5"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "OFxm-xiNUOJX",
        "vscode": {
          "languageId": "r"
        }
      },
      "outputs": [],
      "source": [
        "# Parametros LightGBM\n",
        "\n",
        "PARAM$hyperparametertuning$xval_folds <- 5\n",
        "\n",
        "# parametros fijos del LightGBM que se pisaran con la parte variable de la BO\n",
        "PARAM$lgbm$param_fijos <-  list(\n",
        "  boosting= \"gbdt\", # puede ir dart, ni pruebe random_forest\n",
        "  objective= \"binary\", #default regression\n",
        "  metric= \"auc\", # default \"\" \n",
        "  first_metric_only= FALSE, # default FALSE\n",
        "  boost_from_average= TRUE, # default TRUE\n",
        "  feature_pre_filter= FALSE, # default TRUE\n",
        "  force_row_wise= TRUE, # para reducir warnings\n",
        "  verbosity= -100,\n",
        "\n",
        "  seed= PARAM$semilla_primigenia,\n",
        "\n",
        "  max_depth= -1L, # -1 significa no limitar,  por ahora lo dejo fijo\n",
        "  min_gain_to_split= 0, # min_gain_to_split >= 0\n",
        "  min_sum_hessian_in_leaf= 0.001, #  min_sum_hessian_in_leaf >= 0.0\n",
        "  lambda_l1= 0.0, # lambda_l1 >= 0.0\n",
        "  lambda_l2= 0.0, # lambda_l2 >= 0.0\n",
        "  max_bin= 31L, # lo debo dejar fijo, no participa de la BO\n",
        "\n",
        "  bagging_fraction= 1.0, # 0.0 < bagging_fraction <= 1.0\n",
        "  pos_bagging_fraction= 1.0, # 0.0 < pos_bagging_fraction <= 1.0\n",
        "  neg_bagging_fraction= 1.0, # 0.0 < neg_bagging_fraction <= 1.0\n",
        "  is_unbalance= TRUE, # Default FALSE\n",
        "  scale_pos_weight= 1.0, # scale_pos_weight > 0.0\n",
        "\n",
        "  drop_rate= 0.1, # 0.0 < neg_bagging_fraction <= 1.0\n",
        "  max_drop= 50, # <=0 means no limit\n",
        "  skip_drop= 0.5, # 0.0 <= skip_drop <= 1.0\n",
        "\n",
        "  extra_trees= FALSE, # default FALSE\n",
        "\n",
        "  num_iterations= 1200, # default 100\n",
        "  learning_rate= 0.02, # default 0.1\n",
        "  feature_fraction= 0.5, # default 1\n",
        "  num_leaves= 750, # default 31\n",
        "  min_data_in_leaf= 5000 # default 20\n",
        ")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D5Yj-JV4yvOt"
      },
      "source": [
        "Aqui se definen los hiperparámetros de LightGBM que participan de la Bayesian Optimization\n",
        "- si es un numero entero debe ir makeIntegerParam\n",
        "- si es un numero real (con decimales) debe ir makeNumericParam\n",
        "\n",
        "Es muy importante leer cuales son un lower y upper permitidos y además razonables"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "jENpR26ZyuS8",
        "vscode": {
          "languageId": "r"
        }
      },
      "outputs": [],
      "source": [
        "# Aqui se cargan los bordes de los hiperparametros de la BO\n",
        "PARAM$hypeparametertuning$hs <- makeParamSet(\n",
        "  makeNumericParam(\"min_sum_hessian_in_leaf\", lower= 0.001, upper= 0.1),\n",
        "  makeNumericParam(\"learning_rate\", lower= 0.005, upper= 0.1),\n",
        "  makeNumericParam(\"feature_fraction\", lower= 0.1, upper= 1.0),\n",
        "  makeNumericParam(\"bagging_fraction\", lower= 0.0, upper= 1.0),\n",
        "  makeNumericParam(\"lambda_l1\", lower= 0.0, upper= 10.0),\n",
        "  makeNumericParam(\"lambda_l2\", lower= 0.0, upper= 10.0),\n",
        "  makeNumericParam(\"min_gain_to_split\", lower= 0.0, upper= 15.0),\n",
        "  makeIntegerParam(\"bagging_freq\", lower= 1L, upper= 10L),\n",
        "  makeIntegerParam(\"num_iterations\", lower= 50L, upper= 3000L),\n",
        "  makeIntegerParam(\"max_depth\", lower= -1L, upper= 15L),\n",
        "  makeIntegerParam(\"num_leaves\", lower= 1L, upper= 2048L),\n",
        "  makeIntegerParam(\"min_data_in_leaf\", lower= 1L, upper= 8000L)\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-_RPFUb3zMoW"
      },
      "source": [
        "A mayor cantidad de hiperparámetros, se debe aumentar las iteraciones de la Bayesian Optimization: 30 es un valor muy tacaño, pero corre rápido deberia partir de 50, alcanzando los 100 si se dispone de tiempo."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "q5Rd3pnbzSiG",
        "vscode": {
          "languageId": "r"
        }
      },
      "outputs": [],
      "source": [
        "PARAM$hyperparametertuning$iteraciones <- 100 # iteraciones bayesianas"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "or53-q3bmE5d",
        "vscode": {
          "languageId": "r"
        }
      },
      "outputs": [],
      "source": [
        "# particionar agrega una columna llamada fold a un dataset\n",
        "#   que consiste en una particion estratificada segun agrupa\n",
        "# particionar( data=dataset, division=c(70,30),\n",
        "#  agrupa=clase_ternaria, seed=semilla)   crea una particion 70, 30\n",
        "\n",
        "particionar <- function(data, division, agrupa= \"\", campo= \"fold\", start= 1, seed= NA) {\n",
        "  if (!is.na(seed)) set.seed(seed, \"L'Ecuyer-CMRG\")\n",
        "\n",
        "  bloque <- unlist(mapply(\n",
        "    function(x, y) {rep(y, x)},division, seq(from= start, length.out= length(division))))\n",
        "\n",
        "  data[, (campo) := sample(rep(bloque,ceiling(.N / length(bloque))))[1:.N],by= agrupa]\n",
        "}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "CGKOZ9aMmKxi",
        "vscode": {
          "languageId": "r"
        }
      },
      "outputs": [],
      "source": [
        "# iniciliazo el dataset de realidad, para medir ganancia\n",
        "realidad_inicializar <- function( pfuture, pparam) {\n",
        "\n",
        "  # datos para verificar la ganancia\n",
        "  drealidad <- pfuture[, list(numero_de_cliente, foto_mes, clase_ternaria)]\n",
        "\n",
        "  particionar(drealidad,\n",
        "    division= c(3, 7),\n",
        "    agrupa= \"clase_ternaria\",\n",
        "    seed= PARAM$semilla_kaggle\n",
        "  )\n",
        "\n",
        "  return( drealidad )\n",
        "}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "6aVLFlEbmM3s",
        "vscode": {
          "languageId": "r"
        }
      },
      "outputs": [],
      "source": [
        "# evaluo ganancia en los datos de la realidad\n",
        "\n",
        "realidad_evaluar <- function( prealidad, pprediccion) {\n",
        "\n",
        "  prealidad[ pprediccion,\n",
        "    on= c(\"numero_de_cliente\", \"foto_mes\"),\n",
        "    predicted:= i.Predicted\n",
        "  ]\n",
        "\n",
        "  tbl <- prealidad[, list(\"qty\"=.N), list(fold, predicted, clase_ternaria)]\n",
        "\n",
        "  res <- list()\n",
        "  res$public  <- tbl[fold==1 & predicted==1L, sum(qty*ifelse(clase_ternaria==\"BAJA+2\", 780000, -20000))]/0.3\n",
        "  res$private <- tbl[fold==2 & predicted==1L, sum(qty*ifelse(clase_ternaria==\"BAJA+2\", 780000, -20000))]/0.7\n",
        "  res$total <- tbl[predicted==1L, sum(qty*ifelse(clase_ternaria==\"BAJA+2\", 780000, -20000))]\n",
        "\n",
        "  prealidad[, predicted:=NULL]\n",
        "  return( res )\n",
        "}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4RWZXL1VZjMI"
      },
      "source": [
        "### 2.2.4  Preprocesamiento"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "FM3lxKoLZ643",
        "vscode": {
          "languageId": "r"
        }
      },
      "outputs": [],
      "source": [
        "# lectura del dataset\n",
        "dataset <- fread(\"./competencia_01.csv.gz\", stringsAsFactors= TRUE)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "OsJ-91UeZ-I_",
        "vscode": {
          "languageId": "r"
        }
      },
      "outputs": [],
      "source": [
        "dataset_train <- dataset[foto_mes %in% PARAM$train]\n",
        "# Eliminar las filas (observaciones) donde clase_ternaria es \"BAJA+1\"\n",
        "dataset_train <- dataset_train[clase_ternaria != \"BAJA+1\"]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "vrWE7BE0aB2J",
        "vscode": {
          "languageId": "r"
        }
      },
      "outputs": [],
      "source": [
        "# paso la clase a binaria que tome valores {0,1}  enteros\n",
        "#  BAJA+2  es 1, CONTINUA es 0\n",
        "\n",
        "dataset_train[,\n",
        "  clase01 := ifelse(clase_ternaria %in% c(\"BAJA+2\"), 1L, 0L)\n",
        "]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "jP7YlQBnaW6W",
        "vscode": {
          "languageId": "r"
        }
      },
      "outputs": [],
      "source": [
        "# defino los datos que forma parte del training\n",
        "# aqui se hace el undersampling de los CONTINUA\n",
        "# notar que para esto utilizo la SEGUNDA semilla\n",
        "\n",
        "set.seed(PARAM$semilla_primigenia, kind = \"L'Ecuyer-CMRG\")\n",
        "dataset_train[, azar := runif(nrow(dataset_train))]\n",
        "dataset_train[, training := 0L]\n",
        "\n",
        "dataset_train[\n",
        "  foto_mes %in%  PARAM$train &\n",
        "    (azar <= PARAM$trainingstrategy$undersampling | clase_ternaria %in% c(\"BAJA+2\")),\n",
        "  training := 1L\n",
        "]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "xElu4s5W4rX7",
        "vscode": {
          "languageId": "r"
        }
      },
      "outputs": [],
      "source": [
        "# los campos que se van a utilizar\n",
        "\n",
        "campos_buenos <- setdiff(\n",
        "  colnames(dataset_train),\n",
        "  c(\"clase_ternaria\", \"clase01\", \"azar\", \"training\")\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "PppMHcGYaaol",
        "vscode": {
          "languageId": "r"
        }
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "162289"
            ],
            "text/latex": [
              "162289"
            ],
            "text/markdown": [
              "162289"
            ],
            "text/plain": [
              "[1] 162289"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "154"
            ],
            "text/latex": [
              "154"
            ],
            "text/markdown": [
              "154"
            ],
            "text/plain": [
              "[1] 154"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# dejo los datos en el formato que necesita LightGBM\n",
        "\n",
        "dtrain <- lgb.Dataset(\n",
        "  data= data.matrix(dataset_train[training == 1L, campos_buenos, with= FALSE]),\n",
        "  label= dataset_train[training == 1L, clase01],\n",
        "  free_raw_data= FALSE\n",
        ")\n",
        "\n",
        "nrow(dtrain)\n",
        "ncol(dtrain)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ta-EkOu3cphF"
      },
      "source": [
        "2.2.5 Configuracion Bayesian Optimization"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "cjgfurjdfiXb",
        "vscode": {
          "languageId": "r"
        }
      },
      "outputs": [],
      "source": [
        "# En el argumento x llegan los parmaetros de la bayesiana\n",
        "#  devuelve la AUC en cross validation del modelo entrenado\n",
        "\n",
        "EstimarGanancia_AUC_lightgbm <- function(x) {\n",
        "\n",
        "  # x pisa (o agrega) a param_fijos\n",
        "  param_completo <- modifyList(PARAM$lgbm$param_fijos, x)\n",
        "\n",
        "  # entreno LightGBM\n",
        "  modelocv <- lgb.cv(\n",
        "    data= dtrain,\n",
        "    nfold= PARAM$hyperparametertuning$xval_folds,\n",
        "    stratified= TRUE,\n",
        "    param= param_completo\n",
        "  )\n",
        "\n",
        "  # obtengo la ganancia\n",
        "  AUC <- modelocv$best_score\n",
        "\n",
        "  # hago espacio en la memoria\n",
        "  rm(modelocv)\n",
        "  gc(full= TRUE, verbose= FALSE)\n",
        "\n",
        "  message(format(Sys.time(), \"%a %b %d %X %Y\"), \" AUC \", AUC)\n",
        "\n",
        "  return(AUC)\n",
        "}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "WLi_o1hocvN-",
        "vscode": {
          "languageId": "r"
        }
      },
      "outputs": [],
      "source": [
        "# Aqui comienza la configuracion de la Bayesian Optimization\n",
        "\n",
        "# en este archivo quedan la evolucion binaria de la BO\n",
        "kbayesiana <- \"bayesiana.RDATA\"\n",
        "\n",
        "funcion_optimizar <- EstimarGanancia_AUC_lightgbm # la funcion que voy a maximizar\n",
        "\n",
        "configureMlr(show.learner.output= FALSE)\n",
        "\n",
        "# configuro la busqueda bayesiana,  los hiperparametros que se van a optimizar\n",
        "# por favor, no desesperarse por lo complejo\n",
        "\n",
        "obj.fun <- makeSingleObjectiveFunction(\n",
        "  fn= funcion_optimizar, # la funcion que voy a maximizar\n",
        "  minimize= FALSE, # estoy Maximizando la ganancia\n",
        "  noisy= TRUE,\n",
        "  par.set= PARAM$hypeparametertuning$hs, # definido al comienzo del programa\n",
        "  has.simple.signature= FALSE # paso los parametros en una lista\n",
        ")\n",
        "\n",
        "# cada 600 segundos guardo el resultado intermedio\n",
        "ctrl <- makeMBOControl(\n",
        "  save.on.disk.at.time= 600, # se graba cada 600 segundos\n",
        "  save.file.path= kbayesiana\n",
        ") # se graba cada 600 segundos\n",
        "\n",
        "# indico la cantidad de iteraciones que va a tener la Bayesian Optimization\n",
        "ctrl <- setMBOControlTermination(\n",
        "  ctrl,\n",
        "  iters= PARAM$hyperparametertuning$iteraciones\n",
        ") # cantidad de iteraciones\n",
        "\n",
        "# defino el método estandar para la creacion de los puntos iniciales,\n",
        "# los \"No Inteligentes\"\n",
        "ctrl <- setMBOControlInfill(ctrl, crit= makeMBOInfillCritEI())\n",
        "\n",
        "# establezco la funcion que busca el maximo\n",
        "surr.km <- makeLearner(\n",
        "  \"regr.km\",\n",
        "  predict.type= \"se\",\n",
        "  covtype= \"matern3_2\",\n",
        "  control= list(trace= TRUE)\n",
        ")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_uUeVo5pc4zc"
      },
      "source": [
        "2.2.6 Corrida Bayesian Optimization"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "RcABNaKGciaz",
        "vscode": {
          "languageId": "r"
        }
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Computing y column(s) for design. Not provided.\n",
            "\n",
            "mar sept 30 23:58:11 2025 AUC 0.910174035140234\n",
            "\n",
            "mié oct 01 00:01:26 2025 AUC 0.90884992217168\n",
            "\n",
            "mié oct 01 00:03:57 2025 AUC 0.914247713625076\n",
            "\n",
            "mié oct 01 00:05:57 2025 AUC 0.908858662546172\n",
            "\n",
            "mié oct 01 00:08:20 2025 AUC 0.912871151016607\n",
            "\n",
            "mié oct 01 00:09:28 2025 AUC 0.905901951186261\n",
            "\n",
            "mié oct 01 00:09:48 2025 AUC 0.905117700476006\n",
            "\n",
            "mié oct 01 00:10:21 2025 AUC 0.909294932528272\n",
            "\n",
            "mié oct 01 00:11:30 2025 AUC 0.900686017212763\n",
            "\n",
            "mié oct 01 00:13:04 2025 AUC 0.899190109216937\n",
            "\n",
            "mié oct 01 00:15:38 2025 AUC 0.906173773380995\n",
            "\n",
            "mié oct 01 00:17:31 2025 AUC 0.909123512718725\n",
            "\n",
            "mié oct 01 00:19:43 2025 AUC 0.912132445030658\n",
            "\n",
            "mié oct 01 00:22:53 2025 AUC 0.91268920294379\n",
            "\n",
            "mié oct 01 00:23:44 2025 AUC 0.895649233714079\n",
            "\n",
            "mié oct 01 00:25:15 2025 AUC 0.91302869098782\n",
            "\n",
            "mié oct 01 00:25:56 2025 AUC 0.902995153853927\n",
            "\n",
            "mié oct 01 00:26:11 2025 AUC 0.5\n",
            "\n",
            "mié oct 01 00:27:51 2025 AUC 0.90282709221828\n",
            "\n",
            "mié oct 01 00:29:51 2025 AUC 0.913227188693619\n",
            "\n",
            "mié oct 01 00:30:13 2025 AUC 0.887251553773789\n",
            "\n",
            "mié oct 01 00:32:05 2025 AUC 0.913655063007647\n",
            "\n",
            "mié oct 01 00:33:59 2025 AUC 0.912805484061726\n",
            "\n",
            "mié oct 01 00:34:44 2025 AUC 0.913112698229171\n",
            "\n",
            "mié oct 01 00:35:15 2025 AUC 0.5\n",
            "\n",
            "mié oct 01 00:37:47 2025 AUC 0.913933602195899\n",
            "\n",
            "mié oct 01 00:40:16 2025 AUC 0.908328602720976\n",
            "\n",
            "mié oct 01 00:40:50 2025 AUC 0.907479170274986\n",
            "\n",
            "mié oct 01 00:41:26 2025 AUC 0.908448185800443\n",
            "\n",
            "mié oct 01 00:42:37 2025 AUC 0.911345930398413\n",
            "\n",
            "mié oct 01 00:43:31 2025 AUC 0.89120863263071\n",
            "\n",
            "mié oct 01 00:44:18 2025 AUC 0.906728811152636\n",
            "\n",
            "mié oct 01 00:45:39 2025 AUC 0.906375642840924\n",
            "\n",
            "mié oct 01 00:47:06 2025 AUC 0.909237236873784\n",
            "\n",
            "mié oct 01 00:47:48 2025 AUC 0.830134160981561\n",
            "\n",
            "mié oct 01 00:49:06 2025 AUC 0.893774498570773\n",
            "\n",
            "mié oct 01 00:52:44 2025 AUC 0.913745809231286\n",
            "\n",
            "mié oct 01 00:52:49 2025 AUC 0.898894691770616\n",
            "\n",
            "mié oct 01 00:55:22 2025 AUC 0.91514378177972\n",
            "\n",
            "mié oct 01 00:55:26 2025 AUC 0.5\n",
            "\n",
            "mié oct 01 00:57:45 2025 AUC 0.915112901862992\n",
            "\n",
            "mié oct 01 00:58:57 2025 AUC 0.865636466985909\n",
            "\n",
            "mié oct 01 01:00:45 2025 AUC 0.906164698677823\n",
            "\n",
            "mié oct 01 01:01:05 2025 AUC 0.896147572963938\n",
            "\n",
            "mié oct 01 01:01:54 2025 AUC 0.908126166551773\n",
            "\n",
            "mié oct 01 01:05:17 2025 AUC 0.897115655458338\n",
            "\n",
            "mié oct 01 01:05:41 2025 AUC 0.874047870341092\n",
            "\n",
            "mié oct 01 01:07:17 2025 AUC 0.910679256195901\n",
            "\n",
            "[mbo] 0: min_sum_hessian_in_leaf=0.0289; learning_rate=0.0568; feature_fraction=0.703; bagging_fraction=0.671; lambda_l1=4.35; lambda_l2=3.14; min_gain_to_split=2.1; bagging_freq=5; num_iterations=780; max_depth=7; num_leaves=588; min_data_in_leaf=2522 : y = 0.91 : 64.8 secs : initdesign\n",
            "\n",
            "[mbo] 0: min_sum_hessian_in_leaf=0.0496; learning_rate=0.0636; feature_fraction=0.338; bagging_fraction=0.707; lambda_l1=2.29; lambda_l2=2.61; min_gain_to_split=2.84; bagging_freq=5; num_iterations=1526; max_depth=0; num_leaves=1183; min_data_in_leaf=1395 : y = 0.909 : 194.7 secs : initdesign\n",
            "\n",
            "[mbo] 0: min_sum_hessian_in_leaf=0.0663; learning_rate=0.0367; feature_fraction=0.493; bagging_fraction=0.743; lambda_l1=4.65; lambda_l2=9.37; min_gain_to_split=1.84; bagging_freq=4; num_iterations=1487; max_depth=7; num_leaves=932; min_data_in_leaf=2752 : y = 0.914 : 150.8 secs : initdesign\n",
            "\n",
            "[mbo] 0: min_sum_hessian_in_leaf=0.0519; learning_rate=0.0717; feature_fraction=0.357; bagging_fraction=0.862; lambda_l1=1.53; lambda_l2=6.76; min_gain_to_split=4.91; bagging_freq=3; num_iterations=1126; max_depth=0; num_leaves=1386; min_data_in_leaf=4236 : y = 0.909 : 119.9 secs : initdesign\n",
            "\n",
            "[mbo] 0: min_sum_hessian_in_leaf=0.00596; learning_rate=0.0505; feature_fraction=0.672; bagging_fraction=0.639; lambda_l1=2.94; lambda_l2=5.66; min_gain_to_split=2.66; bagging_freq=5; num_iterations=1922; max_depth=11; num_leaves=1589; min_data_in_leaf=4503 : y = 0.913 : 143.7 secs : initdesign\n",
            "\n",
            "[mbo] 0: min_sum_hessian_in_leaf=0.0622; learning_rate=0.076; feature_fraction=0.56; bagging_fraction=0.424; lambda_l1=5.21; lambda_l2=5.85; min_gain_to_split=9.44; bagging_freq=5; num_iterations=1228; max_depth=13; num_leaves=1818; min_data_in_leaf=5911 : y = 0.906 : 67.9 secs : initdesign\n",
            "\n",
            "[mbo] 0: min_sum_hessian_in_leaf=0.0482; learning_rate=0.0354; feature_fraction=0.806; bagging_fraction=0.235; lambda_l1=5.5; lambda_l2=5.4; min_gain_to_split=12.4; bagging_freq=7; num_iterations=575; max_depth=3; num_leaves=1483; min_data_in_leaf=3830 : y = 0.905 : 19.6 secs : initdesign\n",
            "\n",
            "[mbo] 0: min_sum_hessian_in_leaf=0.0398; learning_rate=0.0531; feature_fraction=0.747; bagging_fraction=0.931; lambda_l1=0.685; lambda_l2=2.94; min_gain_to_split=4.1; bagging_freq=6; num_iterations=975; max_depth=1; num_leaves=605; min_data_in_leaf=6216 : y = 0.909 : 32.7 secs : initdesign\n",
            "\n",
            "[mbo] 0: min_sum_hessian_in_leaf=0.063; learning_rate=0.0786; feature_fraction=0.694; bagging_fraction=0.196; lambda_l1=6.83; lambda_l2=4.34; min_gain_to_split=6.01; bagging_freq=7; num_iterations=2555; max_depth=2; num_leaves=1659; min_data_in_leaf=3031 : y = 0.901 : 68.9 secs : initdesign\n",
            "\n",
            "[mbo] 0: min_sum_hessian_in_leaf=0.0607; learning_rate=0.0617; feature_fraction=0.533; bagging_fraction=0.286; lambda_l1=0.394; lambda_l2=3.92; min_gain_to_split=3.92; bagging_freq=4; num_iterations=2397; max_depth=10; num_leaves=1001; min_data_in_leaf=6076 : y = 0.899 : 94.6 secs : initdesign\n",
            "\n",
            "[mbo] 0: min_sum_hessian_in_leaf=0.0137; learning_rate=0.046; feature_fraction=0.225; bagging_fraction=0.556; lambda_l1=4.98; lambda_l2=5.47; min_gain_to_split=6.99; bagging_freq=6; num_iterations=1047; max_depth=9; num_leaves=1838; min_data_in_leaf=144 : y = 0.906 : 153.7 secs : initdesign\n",
            "\n",
            "[mbo] 0: min_sum_hessian_in_leaf=0.0816; learning_rate=0.059; feature_fraction=0.43; bagging_fraction=0.54; lambda_l1=6.47; lambda_l2=3.64; min_gain_to_split=8.33; bagging_freq=4; num_iterations=1214; max_depth=-1; num_leaves=157; min_data_in_leaf=2049 : y = 0.909 : 112.9 secs : initdesign\n",
            "\n",
            "[mbo] 0: min_sum_hessian_in_leaf=0.0738; learning_rate=0.0323; feature_fraction=0.302; bagging_fraction=0.621; lambda_l1=4.57; lambda_l2=4.76; min_gain_to_split=7.45; bagging_freq=10; num_iterations=2062; max_depth=7; num_leaves=710; min_data_in_leaf=5352 : y = 0.912 : 132.5 secs : initdesign\n",
            "\n",
            "[mbo] 0: min_sum_hessian_in_leaf=0.0165; learning_rate=0.0428; feature_fraction=0.401; bagging_fraction=0.897; lambda_l1=4.02; lambda_l2=8.94; min_gain_to_split=10.3; bagging_freq=7; num_iterations=2967; max_depth=5; num_leaves=1431; min_data_in_leaf=5675 : y = 0.913 : 189.3 secs : initdesign\n",
            "\n",
            "[mbo] 0: min_sum_hessian_in_leaf=0.0713; learning_rate=0.0836; feature_fraction=0.726; bagging_fraction=0.219; lambda_l1=3.47; lambda_l2=9.02; min_gain_to_split=9.16; bagging_freq=10; num_iterations=1862; max_depth=4; num_leaves=1080; min_data_in_leaf=6583 : y = 0.896 : 50.9 secs : initdesign\n",
            "\n",
            "[mbo] 0: min_sum_hessian_in_leaf=0.0192; learning_rate=0.0555; feature_fraction=0.76; bagging_fraction=0.829; lambda_l1=0.844; lambda_l2=8.52; min_gain_to_split=10.8; bagging_freq=5; num_iterations=1463; max_depth=14; num_leaves=335; min_data_in_leaf=4029 : y = 0.913 : 91.5 secs : initdesign\n",
            "\n",
            "[mbo] 0: min_sum_hessian_in_leaf=0.0249; learning_rate=0.0697; feature_fraction=0.648; bagging_fraction=0.392; lambda_l1=5.13; lambda_l2=2.28; min_gain_to_split=8.67; bagging_freq=4; num_iterations=305; max_depth=10; num_leaves=204; min_data_in_leaf=641 : y = 0.903 : 40.5 secs : initdesign\n",
            "\n",
            "[mbo] 0: min_sum_hessian_in_leaf=0.0459; learning_rate=0.0396; feature_fraction=0.126; bagging_fraction=0.0153; lambda_l1=8.33; lambda_l2=6.55; min_gain_to_split=1.41; bagging_freq=4; num_iterations=832; max_depth=3; num_leaves=732; min_data_in_leaf=1888 : y = 0.5 : 15.2 secs : initdesign\n",
            "\n",
            "[mbo] 0: min_sum_hessian_in_leaf=0.0354; learning_rate=0.0885; feature_fraction=0.873; bagging_fraction=0.308; lambda_l1=3.89; lambda_l2=6.38; min_gain_to_split=9.71; bagging_freq=2; num_iterations=2358; max_depth=7; num_leaves=123; min_data_in_leaf=5074 : y = 0.903 : 100.0 secs : initdesign\n",
            "\n",
            "[mbo] 0: min_sum_hessian_in_leaf=0.0925; learning_rate=0.00908; feature_fraction=0.577; bagging_fraction=0.575; lambda_l1=6.89; lambda_l2=8.27; min_gain_to_split=11.3; bagging_freq=6; num_iterations=2662; max_depth=2; num_leaves=2039; min_data_in_leaf=4676 : y = 0.913 : 120.2 secs : initdesign\n",
            "\n",
            "[mbo] 0: min_sum_hessian_in_leaf=0.0949; learning_rate=0.0844; feature_fraction=0.621; bagging_fraction=0.137; lambda_l1=9.69; lambda_l2=7.29; min_gain_to_split=5.62; bagging_freq=7; num_iterations=703; max_depth=5; num_leaves=645; min_data_in_leaf=2910 : y = 0.887 : 21.5 secs : initdesign\n",
            "\n",
            "[mbo] 0: min_sum_hessian_in_leaf=0.0368; learning_rate=0.0295; feature_fraction=0.194; bagging_fraction=0.81; lambda_l1=8.1; lambda_l2=0.183; min_gain_to_split=12.9; bagging_freq=8; num_iterations=2470; max_depth=2; num_leaves=1141; min_data_in_leaf=7679 : y = 0.914 : 112.9 secs : initdesign\n",
            "\n",
            "[mbo] 0: min_sum_hessian_in_leaf=0.00284; learning_rate=0.0195; feature_fraction=0.518; bagging_fraction=0.367; lambda_l1=9.11; lambda_l2=2.39; min_gain_to_split=5.12; bagging_freq=10; num_iterations=1645; max_depth=-1; num_leaves=977; min_data_in_leaf=2459 : y = 0.913 : 113.4 secs : initdesign\n",
            "\n",
            "[mbo] 0: min_sum_hessian_in_leaf=0.0405; learning_rate=0.0473; feature_fraction=0.275; bagging_fraction=0.88; lambda_l1=2.64; lambda_l2=1.94; min_gain_to_split=3.24; bagging_freq=6; num_iterations=453; max_depth=11; num_leaves=1277; min_data_in_leaf=4913 : y = 0.913 : 45.4 secs : initdesign\n",
            "\n",
            "[mbo] 0: min_sum_hessian_in_leaf=0.0224; learning_rate=0.00562; feature_fraction=0.37; bagging_fraction=0.1; lambda_l1=8.7; lambda_l2=7.6; min_gain_to_split=11.1; bagging_freq=8; num_iterations=1353; max_depth=12; num_leaves=880; min_data_in_leaf=6875 : y = 0.5 : 30.5 secs : initdesign\n",
            "\n",
            "[mbo] 0: min_sum_hessian_in_leaf=0.0542; learning_rate=0.0247; feature_fraction=0.889; bagging_fraction=0.51; lambda_l1=1.27; lambda_l2=4.53; min_gain_to_split=5.85; bagging_freq=1; num_iterations=1329; max_depth=11; num_leaves=1690; min_data_in_leaf=1584 : y = 0.914 : 152.6 secs : initdesign\n",
            "\n",
            "[mbo] 0: min_sum_hessian_in_leaf=0.00331; learning_rate=0.0665; feature_fraction=0.4; bagging_fraction=0.328; lambda_l1=6.18; lambda_l2=4.82; min_gain_to_split=12; bagging_freq=10; num_iterations=2629; max_depth=6; num_leaves=1561; min_data_in_leaf=3282 : y = 0.908 : 148.8 secs : initdesign\n",
            "\n",
            "[mbo] 0: min_sum_hessian_in_leaf=0.0215; learning_rate=0.0742; feature_fraction=0.979; bagging_fraction=0.762; lambda_l1=6.03; lambda_l2=6.16; min_gain_to_split=11.8; bagging_freq=8; num_iterations=263; max_depth=15; num_leaves=1328; min_data_in_leaf=2297 : y = 0.907 : 33.6 secs : initdesign\n",
            "\n",
            "[mbo] 0: min_sum_hessian_in_leaf=0.00801; learning_rate=0.034; feature_fraction=0.439; bagging_fraction=0.493; lambda_l1=6.36; lambda_l2=4.08; min_gain_to_split=14; bagging_freq=2; num_iterations=606; max_depth=0; num_leaves=405; min_data_in_leaf=6491 : y = 0.908 : 36.4 secs : initdesign\n",
            "\n",
            "[mbo] 0: min_sum_hessian_in_leaf=0.0553; learning_rate=0.096; feature_fraction=0.589; bagging_fraction=0.984; lambda_l1=7.59; lambda_l2=5.01; min_gain_to_split=0.494; bagging_freq=3; num_iterations=937; max_depth=4; num_leaves=470; min_data_in_leaf=4489 : y = 0.911 : 70.9 secs : initdesign\n",
            "\n",
            "[mbo] 0: min_sum_hessian_in_leaf=0.0303; learning_rate=0.0186; feature_fraction=0.859; bagging_fraction=0.0615; lambda_l1=5.81; lambda_l2=0.528; min_gain_to_split=14.7; bagging_freq=9; num_iterations=2293; max_depth=3; num_leaves=538; min_data_in_leaf=1755 : y = 0.891 : 53.5 secs : initdesign\n",
            "\n",
            "[mbo] 0: min_sum_hessian_in_leaf=0.0767; learning_rate=0.0936; feature_fraction=0.254; bagging_fraction=0.353; lambda_l1=2.72; lambda_l2=7.01; min_gain_to_split=10.4; bagging_freq=9; num_iterations=522; max_depth=6; num_leaves=1928; min_data_in_leaf=931 : y = 0.907 : 47.9 secs : initdesign\n",
            "\n",
            "[mbo] 0: min_sum_hessian_in_leaf=0.0684; learning_rate=0.00753; feature_fraction=0.459; bagging_fraction=0.777; lambda_l1=9.98; lambda_l2=0.326; min_gain_to_split=0.28; bagging_freq=8; num_iterations=1791; max_depth=1; num_leaves=1788; min_data_in_leaf=7190 : y = 0.906 : 80.3 secs : initdesign\n",
            "\n",
            "[mbo] 0: min_sum_hessian_in_leaf=0.0979; learning_rate=0.0658; feature_fraction=0.984; bagging_fraction=0.469; lambda_l1=1.08; lambda_l2=9.62; min_gain_to_split=4.63; bagging_freq=3; num_iterations=1965; max_depth=12; num_leaves=6; min_data_in_leaf=749 : y = 0.909 : 87.0 secs : initdesign\n",
            "\n",
            "[mbo] 0: min_sum_hessian_in_leaf=0.0574; learning_rate=0.0504; feature_fraction=0.834; bagging_fraction=0.108; lambda_l1=7.73; lambda_l2=2.85; min_gain_to_split=0.979; bagging_freq=1; num_iterations=1757; max_depth=8; num_leaves=1304; min_data_in_leaf=7141 : y = 0.83 : 42.6 secs : initdesign\n",
            "\n",
            "[mbo] 0: min_sum_hessian_in_leaf=0.0691; learning_rate=0.0868; feature_fraction=0.958; bagging_fraction=0.178; lambda_l1=7.23; lambda_l2=1.72; min_gain_to_split=7.71; bagging_freq=10; num_iterations=2893; max_depth=13; num_leaves=1504; min_data_in_leaf=5171 : y = 0.894 : 77.6 secs : initdesign\n",
            "\n",
            "[mbo] 0: min_sum_hessian_in_leaf=0.0271; learning_rate=0.0224; feature_fraction=0.144; bagging_fraction=0.96; lambda_l1=7.48; lambda_l2=9.53; min_gain_to_split=6.31; bagging_freq=2; num_iterations=2088; max_depth=14; num_leaves=1717; min_data_in_leaf=3963 : y = 0.914 : 218.2 secs : initdesign\n",
            "\n",
            "[mbo] 0: min_sum_hessian_in_leaf=0.0438; learning_rate=0.0917; feature_fraction=0.171; bagging_fraction=0.588; lambda_l1=1.84; lambda_l2=9.98; min_gain_to_split=0.681; bagging_freq=1; num_iterations=60; max_depth=15; num_leaves=232; min_data_in_leaf=5654 : y = 0.899 : 4.5 secs : initdesign\n",
            "\n",
            "[mbo] 0: min_sum_hessian_in_leaf=0.0855; learning_rate=0.027; feature_fraction=0.779; bagging_fraction=0.954; lambda_l1=3.58; lambda_l2=1.08; min_gain_to_split=8.87; bagging_freq=3; num_iterations=2871; max_depth=4; num_leaves=342; min_data_in_leaf=1046 : y = 0.915 : 153.6 secs : initdesign\n",
            "\n",
            "[mbo] 0: min_sum_hessian_in_leaf=0.0884; learning_rate=0.0152; feature_fraction=0.315; bagging_fraction=0.0781; lambda_l1=0.554; lambda_l2=8.08; min_gain_to_split=7.95; bagging_freq=9; num_iterations=155; max_depth=12; num_leaves=821; min_data_in_leaf=7542 : y = 0.5 : 3.9 secs : initdesign\n",
            "\n",
            "[mbo] 0: min_sum_hessian_in_leaf=0.0775; learning_rate=0.0145; feature_fraction=0.924; bagging_fraction=0.851; lambda_l1=0.0382; lambda_l2=8.65; min_gain_to_split=14.6; bagging_freq=9; num_iterations=2231; max_depth=8; num_leaves=271; min_data_in_leaf=7397 : y = 0.915 : 138.8 secs : initdesign\n",
            "\n",
            "[mbo] 0: min_sum_hessian_in_leaf=0.0801; learning_rate=0.0256; feature_fraction=0.936; bagging_fraction=0.0268; lambda_l1=8.82; lambda_l2=3.47; min_gain_to_split=12.5; bagging_freq=1; num_iterations=2780; max_depth=15; num_leaves=455; min_data_in_leaf=1261 : y = 0.866 : 71.7 secs : initdesign\n",
            "\n",
            "[mbo] 0: min_sum_hessian_in_leaf=0.0131; learning_rate=0.0973; feature_fraction=0.495; bagging_fraction=0.726; lambda_l1=9.21; lambda_l2=0.799; min_gain_to_split=13.4; bagging_freq=9; num_iterations=2186; max_depth=10; num_leaves=81; min_data_in_leaf=3465 : y = 0.906 : 107.8 secs : initdesign\n",
            "\n",
            "[mbo] 0: min_sum_hessian_in_leaf=0.0876; learning_rate=0.0995; feature_fraction=0.238; bagging_fraction=0.448; lambda_l1=3.2; lambda_l2=1.4; min_gain_to_split=13.2; bagging_freq=2; num_iterations=414; max_depth=5; num_leaves=797; min_data_in_leaf=7993 : y = 0.896 : 20.8 secs : initdesign\n",
            "\n",
            "[mbo] 0: min_sum_hessian_in_leaf=0.0909; learning_rate=0.0112; feature_fraction=0.182; bagging_fraction=0.664; lambda_l1=8.34; lambda_l2=0.914; min_gain_to_split=6.75; bagging_freq=2; num_iterations=191; max_depth=9; num_leaves=1225; min_data_in_leaf=269 : y = 0.908 : 49.0 secs : initdesign\n",
            "\n",
            "[mbo] 0: min_sum_hessian_in_leaf=0.00962; learning_rate=0.078; feature_fraction=0.819; bagging_fraction=0.27; lambda_l1=2; lambda_l2=1.66; min_gain_to_split=14.1; bagging_freq=1; num_iterations=2709; max_depth=9; num_leaves=1907; min_data_in_leaf=360 : y = 0.897 : 202.8 secs : initdesign\n",
            "\n",
            "[mbo] 0: min_sum_hessian_in_leaf=0.0983; learning_rate=0.0805; feature_fraction=0.111; bagging_fraction=0.155; lambda_l1=9.57; lambda_l2=7.83; min_gain_to_split=3.49; bagging_freq=6; num_iterations=883; max_depth=13; num_leaves=1987; min_data_in_leaf=6725 : y = 0.874 : 23.7 secs : initdesign\n",
            "\n",
            "[mbo] 0: min_sum_hessian_in_leaf=0.0321; learning_rate=0.0423; feature_fraction=0.637; bagging_fraction=0.401; lambda_l1=2.16; lambda_l2=7.29; min_gain_to_split=2.36; bagging_freq=7; num_iterations=1677; max_depth=-1; num_leaves=1039; min_data_in_leaf=3617 : y = 0.911 : 95.9 secs : initdesign\n",
            "\n",
            "Saved the current state after iteration 1 in the file bayesiana.RDATA.\n",
            "\n",
            "mié oct 01 01:07:44 2025 AUC 0.907172805248655\n",
            "\n",
            "[mbo] 1: min_sum_hessian_in_leaf=0.0474; learning_rate=0.0591; feature_fraction=0.909; bagging_fraction=0.323; lambda_l1=7.4; lambda_l2=1.26; min_gain_to_split=9.25; bagging_freq=6; num_iterations=750; max_depth=1; num_leaves=1624; min_data_in_leaf=3141 : y = 0.907 : 20.5 secs : infill_ei\n",
            "\n",
            "mié oct 01 01:09:09 2025 AUC 0.912670424925018\n",
            "\n",
            "[mbo] 2: min_sum_hessian_in_leaf=0.0755; learning_rate=0.0245; feature_fraction=0.752; bagging_fraction=0.463; lambda_l1=5.67; lambda_l2=0.783; min_gain_to_split=14.7; bagging_freq=9; num_iterations=2261; max_depth=3; num_leaves=650; min_data_in_leaf=2597 : y = 0.913 : 84.6 secs : infill_ei\n",
            "\n",
            "mié oct 01 01:12:33 2025 AUC 0.908860743319105\n",
            "\n",
            "[mbo] 3: min_sum_hessian_in_leaf=0.0139; learning_rate=0.0275; feature_fraction=0.938; bagging_fraction=0.285; lambda_l1=6.27; lambda_l2=2.9; min_gain_to_split=12.1; bagging_freq=8; num_iterations=2430; max_depth=-1; num_leaves=748; min_data_in_leaf=554 : y = 0.909 : 202.2 secs : infill_ei\n",
            "\n",
            "mié oct 01 01:13:15 2025 AUC 0.907879943745239\n",
            "\n",
            "[mbo] 4: min_sum_hessian_in_leaf=0.0177; learning_rate=0.0239; feature_fraction=0.49; bagging_fraction=0.666; lambda_l1=7.3; lambda_l2=2.2; min_gain_to_split=13.4; bagging_freq=3; num_iterations=897; max_depth=1; num_leaves=1330; min_data_in_leaf=3891 : y = 0.908 : 41.5 secs : infill_ei\n",
            "\n",
            "mié oct 01 01:17:15 2025 AUC 0.914772507388865\n",
            "\n",
            "[mbo] 5: min_sum_hessian_in_leaf=0.0155; learning_rate=0.0305; feature_fraction=0.538; bagging_fraction=0.517; lambda_l1=6.66; lambda_l2=3.67; min_gain_to_split=5.75; bagging_freq=10; num_iterations=2554; max_depth=0; num_leaves=1395; min_data_in_leaf=2615 : y = 0.915 : 239.1 secs : infill_ei\n",
            "\n",
            "mié oct 01 01:19:35 2025 AUC 0.914276385414875\n",
            "\n",
            "[mbo] 6: min_sum_hessian_in_leaf=0.0951; learning_rate=0.0293; feature_fraction=0.656; bagging_fraction=0.876; lambda_l1=7.92; lambda_l2=6.03; min_gain_to_split=10.8; bagging_freq=5; num_iterations=1793; max_depth=12; num_leaves=1029; min_data_in_leaf=5719 : y = 0.914 : 138.0 secs : infill_ei\n",
            "\n",
            "Saved the current state after iteration 7 in the file bayesiana.RDATA.\n",
            "\n",
            "mié oct 01 01:21:22 2025 AUC 0.900206719266733\n",
            "\n",
            "[mbo] 7: min_sum_hessian_in_leaf=0.0966; learning_rate=0.0899; feature_fraction=0.131; bagging_fraction=0.369; lambda_l1=8.74; lambda_l2=5.55; min_gain_to_split=1.91; bagging_freq=7; num_iterations=2415; max_depth=5; num_leaves=1724; min_data_in_leaf=6197 : y = 0.9 : 106.1 secs : infill_ei\n",
            "\n",
            "mié oct 01 01:23:46 2025 AUC 0.900725836488447\n",
            "\n",
            "[mbo] 8: min_sum_hessian_in_leaf=0.0899; learning_rate=0.0953; feature_fraction=0.588; bagging_fraction=0.311; lambda_l1=5.63; lambda_l2=1.4; min_gain_to_split=4.9; bagging_freq=9; num_iterations=2080; max_depth=7; num_leaves=928; min_data_in_leaf=1375 : y = 0.901 : 142.8 secs : infill_ei\n",
            "\n",
            "mié oct 01 01:27:47 2025 AUC 0.916939158389893\n",
            "\n",
            "[mbo] 9: min_sum_hessian_in_leaf=0.056; learning_rate=0.0178; feature_fraction=0.309; bagging_fraction=0.865; lambda_l1=7.27; lambda_l2=1.63; min_gain_to_split=6.9; bagging_freq=7; num_iterations=2288; max_depth=8; num_leaves=345; min_data_in_leaf=2030 : y = 0.917 : 239.4 secs : infill_ei\n",
            "\n",
            "mié oct 01 01:31:14 2025 AUC 0.914695066318452\n",
            "\n",
            "[mbo] 10: min_sum_hessian_in_leaf=0.059; learning_rate=0.0337; feature_fraction=0.535; bagging_fraction=0.772; lambda_l1=0.99; lambda_l2=2.05; min_gain_to_split=7.99; bagging_freq=2; num_iterations=2505; max_depth=6; num_leaves=386; min_data_in_leaf=6318 : y = 0.915 : 206.0 secs : infill_ei\n",
            "\n",
            "Saved the current state after iteration 11 in the file bayesiana.RDATA.\n",
            "\n",
            "mié oct 01 01:31:43 2025 AUC 0.903518799541574\n",
            "\n",
            "[mbo] 11: min_sum_hessian_in_leaf=0.0948; learning_rate=0.0901; feature_fraction=0.768; bagging_fraction=0.248; lambda_l1=5.8; lambda_l2=8.21; min_gain_to_split=13; bagging_freq=8; num_iterations=610; max_depth=7; num_leaves=1734; min_data_in_leaf=3423 : y = 0.904 : 27.3 secs : infill_ei\n",
            "\n",
            "mié oct 01 01:34:24 2025 AUC 0.910233354877241\n",
            "\n",
            "[mbo] 12: min_sum_hessian_in_leaf=0.086; learning_rate=0.0624; feature_fraction=0.221; bagging_fraction=0.734; lambda_l1=7.91; lambda_l2=5.42; min_gain_to_split=9.83; bagging_freq=5; num_iterations=2275; max_depth=14; num_leaves=1701; min_data_in_leaf=5075 : y = 0.91 : 159.7 secs : infill_ei\n",
            "\n",
            "mié oct 01 01:35:55 2025 AUC 0.907560369159525\n",
            "\n",
            "[mbo] 13: min_sum_hessian_in_leaf=0.055; learning_rate=0.0658; feature_fraction=0.538; bagging_fraction=0.557; lambda_l1=7.01; lambda_l2=3.84; min_gain_to_split=6.35; bagging_freq=4; num_iterations=2241; max_depth=1; num_leaves=477; min_data_in_leaf=6045 : y = 0.908 : 89.9 secs : infill_ei\n",
            "\n",
            "mié oct 01 01:36:55 2025 AUC 0.911262833391489\n",
            "\n",
            "[mbo] 14: min_sum_hessian_in_leaf=0.0386; learning_rate=0.032; feature_fraction=0.774; bagging_fraction=0.455; lambda_l1=5.8; lambda_l2=4.44; min_gain_to_split=12.6; bagging_freq=9; num_iterations=574; max_depth=0; num_leaves=1238; min_data_in_leaf=1628 : y = 0.911 : 58.7 secs : infill_ei\n",
            "\n",
            "mié oct 01 01:40:11 2025 AUC 0.914404631087929\n",
            "\n",
            "[mbo] 15: min_sum_hessian_in_leaf=0.0772; learning_rate=0.0211; feature_fraction=0.915; bagging_fraction=0.772; lambda_l1=3.02; lambda_l2=5.77; min_gain_to_split=6.36; bagging_freq=7; num_iterations=2286; max_depth=7; num_leaves=1178; min_data_in_leaf=3605 : y = 0.914 : 194.5 secs : infill_ei\n",
            "\n",
            "mié oct 01 01:41:56 2025 AUC 0.909256791918402\n",
            "\n",
            "[mbo] 16: min_sum_hessian_in_leaf=0.0275; learning_rate=0.0366; feature_fraction=0.826; bagging_fraction=0.327; lambda_l1=0.508; lambda_l2=0.551; min_gain_to_split=13.7; bagging_freq=5; num_iterations=2293; max_depth=7; num_leaves=952; min_data_in_leaf=3528 : y = 0.909 : 104.2 secs : infill_ei\n",
            "\n",
            "Saved the current state after iteration 17 in the file bayesiana.RDATA.\n",
            "\n",
            "mié oct 01 01:42:48 2025 AUC 0.909951484143667\n",
            "\n",
            "[mbo] 17: min_sum_hessian_in_leaf=0.0476; learning_rate=0.0851; feature_fraction=0.342; bagging_fraction=0.6; lambda_l1=8.1; lambda_l2=4.41; min_gain_to_split=5.18; bagging_freq=6; num_iterations=531; max_depth=13; num_leaves=1329; min_data_in_leaf=3476 : y = 0.91 : 50.1 secs : infill_ei\n",
            "\n",
            "mié oct 01 01:44:47 2025 AUC 0.912292941710328\n",
            "\n",
            "[mbo] 18: min_sum_hessian_in_leaf=0.0705; learning_rate=0.0486; feature_fraction=0.48; bagging_fraction=0.922; lambda_l1=5.92; lambda_l2=5.17; min_gain_to_split=11.2; bagging_freq=10; num_iterations=1920; max_depth=4; num_leaves=432; min_data_in_leaf=4339 : y = 0.912 : 117.8 secs : infill_ei\n",
            "\n",
            "mié oct 01 01:50:08 2025 AUC 0.917214311753749\n",
            "\n",
            "[mbo] 19: min_sum_hessian_in_leaf=0.0921; learning_rate=0.0174; feature_fraction=0.499; bagging_fraction=0.656; lambda_l1=3.89; lambda_l2=3.23; min_gain_to_split=8.05; bagging_freq=6; num_iterations=2072; max_depth=11; num_leaves=1789; min_data_in_leaf=735 : y = 0.917 : 319.2 secs : infill_ei\n",
            "\n",
            "mié oct 01 01:51:56 2025 AUC 0.907058252171528\n",
            "\n",
            "[mbo] 20: min_sum_hessian_in_leaf=0.0792; learning_rate=0.0745; feature_fraction=0.555; bagging_fraction=0.593; lambda_l1=4.54; lambda_l2=6.67; min_gain_to_split=12.5; bagging_freq=7; num_iterations=1584; max_depth=12; num_leaves=892; min_data_in_leaf=1060 : y = 0.907 : 107.1 secs : infill_ei\n",
            "\n",
            "mié oct 01 01:52:25 2025 AUC 0.900563233664972\n",
            "\n",
            "[mbo] 21: min_sum_hessian_in_leaf=0.0884; learning_rate=0.0972; feature_fraction=0.87; bagging_fraction=0.236; lambda_l1=9.01; lambda_l2=5.58; min_gain_to_split=10.4; bagging_freq=9; num_iterations=1254; max_depth=1; num_leaves=536; min_data_in_leaf=3163 : y = 0.901 : 26.8 secs : infill_ei\n",
            "\n",
            "Saved the current state after iteration 22 in the file bayesiana.RDATA.\n",
            "\n",
            "mié oct 01 01:55:09 2025 AUC 0.916033160605427\n",
            "\n",
            "[mbo] 22: min_sum_hessian_in_leaf=0.0966; learning_rate=0.0143; feature_fraction=0.241; bagging_fraction=0.84; lambda_l1=2.55; lambda_l2=4.85; min_gain_to_split=7.84; bagging_freq=3; num_iterations=2264; max_depth=4; num_leaves=1813; min_data_in_leaf=4155 : y = 0.916 : 163.2 secs : infill_ei\n",
            "\n",
            "mié oct 01 01:57:56 2025 AUC 0.912000662081638\n",
            "\n",
            "[mbo] 23: min_sum_hessian_in_leaf=0.0263; learning_rate=0.0503; feature_fraction=0.579; bagging_fraction=0.909; lambda_l1=6.2; lambda_l2=2.1; min_gain_to_split=5.38; bagging_freq=2; num_iterations=1903; max_depth=13; num_leaves=1552; min_data_in_leaf=1898 : y = 0.912 : 165.4 secs : infill_ei\n",
            "\n",
            "mié oct 01 01:59:33 2025 AUC 0.914370738517275\n",
            "\n",
            "[mbo] 24: min_sum_hessian_in_leaf=0.0866; learning_rate=0.0251; feature_fraction=0.869; bagging_fraction=0.625; lambda_l1=2.43; lambda_l2=6.83; min_gain_to_split=13.3; bagging_freq=1; num_iterations=1490; max_depth=10; num_leaves=169; min_data_in_leaf=4108 : y = 0.914 : 95.3 secs : infill_ei\n",
            "\n",
            "mié oct 01 02:02:55 2025 AUC 0.915063104904295\n",
            "\n",
            "[mbo] 25: min_sum_hessian_in_leaf=0.0167; learning_rate=0.0278; feature_fraction=0.255; bagging_fraction=0.791; lambda_l1=6.27; lambda_l2=2.74; min_gain_to_split=5.38; bagging_freq=10; num_iterations=2036; max_depth=8; num_leaves=1792; min_data_in_leaf=3785 : y = 0.915 : 200.3 secs : infill_ei\n",
            "\n",
            "Saved the current state after iteration 26 in the file bayesiana.RDATA.\n",
            "\n",
            "mié oct 01 02:03:50 2025 AUC 0.910299155193121\n",
            "\n",
            "[mbo] 26: min_sum_hessian_in_leaf=0.0399; learning_rate=0.0683; feature_fraction=0.284; bagging_fraction=0.787; lambda_l1=7.17; lambda_l2=4.33; min_gain_to_split=13.7; bagging_freq=1; num_iterations=607; max_depth=7; num_leaves=436; min_data_in_leaf=4133 : y = 0.91 : 54.1 secs : infill_ei\n",
            "\n",
            "mié oct 01 02:05:24 2025 AUC 0.916099030013283\n",
            "\n",
            "[mbo] 27: min_sum_hessian_in_leaf=0.0456; learning_rate=0.0116; feature_fraction=0.69; bagging_fraction=0.938; lambda_l1=4.03; lambda_l2=7.63; min_gain_to_split=4.55; bagging_freq=4; num_iterations=1559; max_depth=4; num_leaves=127; min_data_in_leaf=4815 : y = 0.916 : 91.9 secs : infill_ei\n",
            "\n",
            "mié oct 01 02:07:41 2025 AUC 0.915062737618369\n",
            "\n",
            "[mbo] 28: min_sum_hessian_in_leaf=0.0127; learning_rate=0.0198; feature_fraction=0.647; bagging_fraction=0.584; lambda_l1=7.13; lambda_l2=3.97; min_gain_to_split=6.02; bagging_freq=5; num_iterations=1767; max_depth=6; num_leaves=256; min_data_in_leaf=1783 : y = 0.915 : 135.5 secs : infill_ei\n",
            "\n",
            "mié oct 01 02:07:58 2025 AUC 0.904166388843724\n",
            "\n",
            "[mbo] 29: min_sum_hessian_in_leaf=0.0853; learning_rate=0.0873; feature_fraction=0.621; bagging_fraction=0.396; lambda_l1=9.27; lambda_l2=9.68; min_gain_to_split=4.03; bagging_freq=5; num_iterations=509; max_depth=1; num_leaves=512; min_data_in_leaf=4318 : y = 0.904 : 14.7 secs : infill_ei\n",
            "\n",
            "mié oct 01 02:12:13 2025 AUC 0.916000810978194\n",
            "\n",
            "[mbo] 30: min_sum_hessian_in_leaf=0.0493; learning_rate=0.0139; feature_fraction=0.556; bagging_fraction=0.955; lambda_l1=1.17; lambda_l2=3.23; min_gain_to_split=8.9; bagging_freq=6; num_iterations=2380; max_depth=9; num_leaves=1033; min_data_in_leaf=4675 : y = 0.916 : 254.0 secs : infill_ei\n",
            "\n",
            "mié oct 01 02:15:26 2025 AUC 0.913899972355064\n",
            "\n",
            "[mbo] 31: min_sum_hessian_in_leaf=0.06; learning_rate=0.0357; feature_fraction=0.286; bagging_fraction=0.96; lambda_l1=5.93; lambda_l2=4.11; min_gain_to_split=1.83; bagging_freq=2; num_iterations=2194; max_depth=6; num_leaves=469; min_data_in_leaf=5909 : y = 0.914 : 190.7 secs : infill_ei\n",
            "\n",
            "Saved the current state after iteration 32 in the file bayesiana.RDATA.\n",
            "\n",
            "mié oct 01 02:17:47 2025 AUC 0.908332537502718\n",
            "\n",
            "[mbo] 32: min_sum_hessian_in_leaf=0.00487; learning_rate=0.0686; feature_fraction=0.405; bagging_fraction=0.481; lambda_l1=0.109; lambda_l2=2.87; min_gain_to_split=9.04; bagging_freq=2; num_iterations=1830; max_depth=6; num_leaves=1919; min_data_in_leaf=3714 : y = 0.908 : 139.7 secs : infill_ei\n",
            "\n",
            "mié oct 01 02:19:22 2025 AUC 0.906665748797428\n",
            "\n",
            "[mbo] 33: min_sum_hessian_in_leaf=0.073; learning_rate=0.0791; feature_fraction=0.938; bagging_fraction=0.903; lambda_l1=2.5; lambda_l2=6.08; min_gain_to_split=7.96; bagging_freq=3; num_iterations=2648; max_depth=11; num_leaves=140; min_data_in_leaf=1569 : y = 0.907 : 92.6 secs : infill_ei\n",
            "\n",
            "mié oct 01 02:20:32 2025 AUC 0.909306320470915\n",
            "\n",
            "[mbo] 34: min_sum_hessian_in_leaf=0.00627; learning_rate=0.0687; feature_fraction=0.629; bagging_fraction=0.441; lambda_l1=8.26; lambda_l2=1.78; min_gain_to_split=6.72; bagging_freq=10; num_iterations=2598; max_depth=1; num_leaves=1019; min_data_in_leaf=3929 : y = 0.909 : 68.8 secs : infill_ei\n",
            "\n",
            "mié oct 01 02:22:15 2025 AUC 0.91655823925789\n",
            "\n",
            "[mbo] 35: min_sum_hessian_in_leaf=0.0572; learning_rate=0.0258; feature_fraction=0.95; bagging_fraction=0.91; lambda_l1=3.46; lambda_l2=4.75; min_gain_to_split=8.25; bagging_freq=3; num_iterations=602; max_depth=13; num_leaves=316; min_data_in_leaf=918 : y = 0.917 : 100.5 secs : infill_ei\n",
            "\n",
            "mié oct 01 02:23:48 2025 AUC 0.914786242661749\n",
            "\n",
            "[mbo] 36: min_sum_hessian_in_leaf=0.0756; learning_rate=0.0216; feature_fraction=0.366; bagging_fraction=0.96; lambda_l1=8.18; lambda_l2=6.15; min_gain_to_split=4; bagging_freq=4; num_iterations=700; max_depth=6; num_leaves=1664; min_data_in_leaf=566 : y = 0.915 : 91.1 secs : infill_ei\n",
            "\n",
            "mié oct 01 02:24:17 2025 AUC 0.908400121948257\n",
            "\n",
            "[mbo] 37: min_sum_hessian_in_leaf=0.0101; learning_rate=0.0304; feature_fraction=0.776; bagging_fraction=0.731; lambda_l1=4.78; lambda_l2=6; min_gain_to_split=14.4; bagging_freq=8; num_iterations=965; max_depth=1; num_leaves=277; min_data_in_leaf=6335 : y = 0.908 : 27.8 secs : infill_ei\n",
            "\n",
            "mié oct 01 02:27:06 2025 AUC 0.914390159671316\n",
            "\n",
            "[mbo] 38: min_sum_hessian_in_leaf=0.0858; learning_rate=0.0245; feature_fraction=0.422; bagging_fraction=0.842; lambda_l1=4.04; lambda_l2=1.97; min_gain_to_split=7.89; bagging_freq=2; num_iterations=1158; max_depth=9; num_leaves=754; min_data_in_leaf=815 : y = 0.914 : 166.6 secs : infill_ei\n",
            "\n",
            "Saved the current state after iteration 39 in the file bayesiana.RDATA.\n",
            "\n",
            "mié oct 01 02:29:15 2025 AUC 0.915363831667342\n",
            "\n",
            "[mbo] 39: min_sum_hessian_in_leaf=0.0709; learning_rate=0.0259; feature_fraction=0.822; bagging_fraction=0.963; lambda_l1=3.23; lambda_l2=8.84; min_gain_to_split=9.41; bagging_freq=2; num_iterations=1422; max_depth=8; num_leaves=1838; min_data_in_leaf=3030 : y = 0.915 : 127.4 secs : infill_ei\n",
            "\n",
            "mié oct 01 02:30:37 2025 AUC 0.909143248681916\n",
            "\n",
            "[mbo] 40: min_sum_hessian_in_leaf=0.00119; learning_rate=0.0352; feature_fraction=0.701; bagging_fraction=0.347; lambda_l1=6.18; lambda_l2=1.9; min_gain_to_split=13; bagging_freq=10; num_iterations=1220; max_depth=-1; num_leaves=1691; min_data_in_leaf=2213 : y = 0.909 : 80.4 secs : infill_ei\n",
            "\n",
            "mié oct 01 02:31:38 2025 AUC 0.911283967243582\n",
            "\n",
            "[mbo] 41: min_sum_hessian_in_leaf=0.0818; learning_rate=0.0177; feature_fraction=0.852; bagging_fraction=0.392; lambda_l1=9.24; lambda_l2=3.11; min_gain_to_split=3.98; bagging_freq=7; num_iterations=1874; max_depth=2; num_leaves=1388; min_data_in_leaf=2698 : y = 0.911 : 58.8 secs : infill_ei\n",
            "\n",
            "mié oct 01 02:33:08 2025 AUC 0.906586610754329\n",
            "\n",
            "[mbo] 42: min_sum_hessian_in_leaf=0.0141; learning_rate=0.0841; feature_fraction=0.221; bagging_fraction=0.936; lambda_l1=7.26; lambda_l2=6.99; min_gain_to_split=6.68; bagging_freq=7; num_iterations=1402; max_depth=11; num_leaves=898; min_data_in_leaf=664 : y = 0.907 : 88.0 secs : infill_ei\n",
            "\n",
            "mié oct 01 02:34:03 2025 AUC 0.911805273093475\n",
            "\n",
            "[mbo] 43: min_sum_hessian_in_leaf=0.00455; learning_rate=0.0406; feature_fraction=0.845; bagging_fraction=0.468; lambda_l1=5.98; lambda_l2=1.77; min_gain_to_split=8.59; bagging_freq=10; num_iterations=1667; max_depth=2; num_leaves=1362; min_data_in_leaf=1676 : y = 0.912 : 52.7 secs : infill_ei\n",
            "\n",
            "mié oct 01 02:34:40 2025 AUC 0.902016923342596\n",
            "\n",
            "[mbo] 44: min_sum_hessian_in_leaf=0.0975; learning_rate=0.0999; feature_fraction=0.151; bagging_fraction=0.327; lambda_l1=3.52; lambda_l2=8.62; min_gain_to_split=3.77; bagging_freq=4; num_iterations=865; max_depth=15; num_leaves=2048; min_data_in_leaf=6665 : y = 0.902 : 35.8 secs : infill_ei\n",
            "\n",
            "mié oct 01 02:36:47 2025 AUC 0.91499618757861\n",
            "\n",
            "[mbo] 45: min_sum_hessian_in_leaf=0.019; learning_rate=0.0294; feature_fraction=0.938; bagging_fraction=0.936; lambda_l1=6.25; lambda_l2=4.54; min_gain_to_split=10; bagging_freq=3; num_iterations=2012; max_depth=8; num_leaves=521; min_data_in_leaf=5233 : y = 0.915 : 125.1 secs : infill_ei\n",
            "\n",
            "mié oct 01 02:38:53 2025 AUC 0.915506275857562\n",
            "\n",
            "[mbo] 46: min_sum_hessian_in_leaf=0.075; learning_rate=0.0345; feature_fraction=0.836; bagging_fraction=0.984; lambda_l1=3.29; lambda_l2=8.71; min_gain_to_split=3.67; bagging_freq=8; num_iterations=1951; max_depth=13; num_leaves=645; min_data_in_leaf=2675 : y = 0.916 : 123.6 secs : infill_ei\n",
            "\n",
            "Saved the current state after iteration 47 in the file bayesiana.RDATA.\n",
            "\n",
            "mié oct 01 02:40:08 2025 AUC 0.904387997955417\n",
            "\n",
            "[mbo] 47: min_sum_hessian_in_leaf=0.0802; learning_rate=0.0837; feature_fraction=0.647; bagging_fraction=0.351; lambda_l1=0.362; lambda_l2=2.93; min_gain_to_split=6.77; bagging_freq=4; num_iterations=1619; max_depth=7; num_leaves=1222; min_data_in_leaf=5225 : y = 0.904 : 73.4 secs : infill_ei\n",
            "\n",
            "mié oct 01 02:42:27 2025 AUC 0.915650652887095\n",
            "\n",
            "[mbo] 48: min_sum_hessian_in_leaf=0.0427; learning_rate=0.0198; feature_fraction=0.817; bagging_fraction=0.902; lambda_l1=3.77; lambda_l2=6.37; min_gain_to_split=14.2; bagging_freq=8; num_iterations=1922; max_depth=9; num_leaves=1130; min_data_in_leaf=277 : y = 0.916 : 136.4 secs : infill_ei\n",
            "\n",
            "mié oct 01 02:45:08 2025 AUC 0.909900294690811\n",
            "\n",
            "[mbo] 49: min_sum_hessian_in_leaf=0.00105; learning_rate=0.0538; feature_fraction=0.278; bagging_fraction=0.645; lambda_l1=2.14; lambda_l2=0.359; min_gain_to_split=12.9; bagging_freq=4; num_iterations=2385; max_depth=13; num_leaves=324; min_data_in_leaf=3935 : y = 0.91 : 159.6 secs : infill_ei\n",
            "\n",
            "mié oct 01 02:45:38 2025 AUC 0.913165895433613\n",
            "\n",
            "[mbo] 50: min_sum_hessian_in_leaf=0.0209; learning_rate=0.0387; feature_fraction=0.819; bagging_fraction=0.511; lambda_l1=4.52; lambda_l2=5.88; min_gain_to_split=14.4; bagging_freq=1; num_iterations=473; max_depth=6; num_leaves=1803; min_data_in_leaf=4582 : y = 0.913 : 27.2 secs : infill_ei\n",
            "\n",
            "mié oct 01 02:47:17 2025 AUC 0.902054690523952\n",
            "\n",
            "[mbo] 51: min_sum_hessian_in_leaf=0.0682; learning_rate=0.0532; feature_fraction=0.999; bagging_fraction=0.166; lambda_l1=4.41; lambda_l2=0.272; min_gain_to_split=14.9; bagging_freq=7; num_iterations=2334; max_depth=5; num_leaves=91; min_data_in_leaf=1498 : y = 0.902 : 97.5 secs : infill_ei\n",
            "\n",
            "mié oct 01 02:49:34 2025 AUC 0.906860789800714\n",
            "\n",
            "[mbo] 52: min_sum_hessian_in_leaf=0.00464; learning_rate=0.0863; feature_fraction=0.395; bagging_fraction=0.488; lambda_l1=0.349; lambda_l2=6.67; min_gain_to_split=3.55; bagging_freq=10; num_iterations=1204; max_depth=12; num_leaves=604; min_data_in_leaf=1219 : y = 0.907 : 134.9 secs : infill_ei\n",
            "\n",
            "Saved the current state after iteration 53 in the file bayesiana.RDATA.\n",
            "\n",
            "mié oct 01 02:50:07 2025 AUC 0.908959704789137\n",
            "\n",
            "[mbo] 53: min_sum_hessian_in_leaf=0.0235; learning_rate=0.076; feature_fraction=0.45; bagging_fraction=0.607; lambda_l1=0.462; lambda_l2=3.22; min_gain_to_split=13.5; bagging_freq=1; num_iterations=518; max_depth=2; num_leaves=435; min_data_in_leaf=6185 : y = 0.909 : 30.6 secs : infill_ei\n",
            "\n",
            "mié oct 01 02:50:52 2025 AUC 0.911471301583905\n",
            "\n",
            "[mbo] 54: min_sum_hessian_in_leaf=0.00757; learning_rate=0.0427; feature_fraction=0.914; bagging_fraction=0.493; lambda_l1=3.79; lambda_l2=6.45; min_gain_to_split=2.79; bagging_freq=7; num_iterations=801; max_depth=10; num_leaves=166; min_data_in_leaf=4499 : y = 0.911 : 42.3 secs : infill_ei\n",
            "\n",
            "mié oct 01 02:55:46 2025 AUC 0.917113504750569\n",
            "\n",
            "[mbo] 55: min_sum_hessian_in_leaf=0.0682; learning_rate=0.0114; feature_fraction=0.818; bagging_fraction=0.883; lambda_l1=5.78; lambda_l2=9.36; min_gain_to_split=11.5; bagging_freq=2; num_iterations=2900; max_depth=11; num_leaves=553; min_data_in_leaf=2125 : y = 0.917 : 292.3 secs : infill_ei\n",
            "\n",
            "mié oct 01 02:57:54 2025 AUC 0.910048929432809\n",
            "\n",
            "[mbo] 56: min_sum_hessian_in_leaf=0.00204; learning_rate=0.0795; feature_fraction=0.366; bagging_fraction=0.799; lambda_l1=4.2; lambda_l2=4.94; min_gain_to_split=2.85; bagging_freq=7; num_iterations=1755; max_depth=9; num_leaves=468; min_data_in_leaf=7241 : y = 0.91 : 125.2 secs : infill_ei\n",
            "\n",
            "mié oct 01 02:59:15 2025 AUC 0.914739244010876\n",
            "\n",
            "[mbo] 57: min_sum_hessian_in_leaf=0.099; learning_rate=0.0189; feature_fraction=0.253; bagging_fraction=0.715; lambda_l1=9.98; lambda_l2=7.71; min_gain_to_split=9.79; bagging_freq=9; num_iterations=1755; max_depth=2; num_leaves=1841; min_data_in_leaf=335 : y = 0.915 : 79.0 secs : infill_ei\n",
            "\n",
            "mié oct 01 03:02:34 2025 AUC 0.916022835387031\n",
            "\n",
            "[mbo] 58: min_sum_hessian_in_leaf=0.0605; learning_rate=0.0196; feature_fraction=0.341; bagging_fraction=0.889; lambda_l1=7.99; lambda_l2=7.28; min_gain_to_split=8.01; bagging_freq=5; num_iterations=1977; max_depth=6; num_leaves=1351; min_data_in_leaf=2523 : y = 0.916 : 197.1 secs : infill_ei\n",
            "\n",
            "Saved the current state after iteration 59 in the file bayesiana.RDATA.\n",
            "\n",
            "mié oct 01 03:05:07 2025 AUC 0.912104499261598\n",
            "\n",
            "[mbo] 59: min_sum_hessian_in_leaf=0.0706; learning_rate=0.0412; feature_fraction=0.839; bagging_fraction=0.795; lambda_l1=8.51; lambda_l2=7.24; min_gain_to_split=3.79; bagging_freq=4; num_iterations=1552; max_depth=10; num_leaves=751; min_data_in_leaf=398 : y = 0.912 : 149.8 secs : infill_ei\n",
            "\n",
            "mié oct 01 03:06:14 2025 AUC 0.9154214509138\n",
            "\n",
            "[mbo] 60: min_sum_hessian_in_leaf=0.0718; learning_rate=0.0198; feature_fraction=0.656; bagging_fraction=0.758; lambda_l1=6.79; lambda_l2=7.76; min_gain_to_split=6.38; bagging_freq=7; num_iterations=498; max_depth=10; num_leaves=1832; min_data_in_leaf=1921 : y = 0.915 : 65.3 secs : infill_ei\n",
            "\n",
            "mié oct 01 03:09:25 2025 AUC 0.916899938459807\n",
            "\n",
            "[mbo] 61: min_sum_hessian_in_leaf=0.0629; learning_rate=0.014; feature_fraction=0.846; bagging_fraction=0.841; lambda_l1=4.25; lambda_l2=1.09; min_gain_to_split=5.59; bagging_freq=8; num_iterations=1919; max_depth=11; num_leaves=289; min_data_in_leaf=3186 : y = 0.917 : 188.5 secs : infill_ei\n",
            "\n",
            "mié oct 01 03:11:11 2025 AUC 0.907020165009078\n",
            "\n",
            "[mbo] 62: min_sum_hessian_in_leaf=0.0421; learning_rate=0.0553; feature_fraction=0.808; bagging_fraction=0.345; lambda_l1=8.7; lambda_l2=5.34; min_gain_to_split=7.39; bagging_freq=10; num_iterations=2091; max_depth=9; num_leaves=226; min_data_in_leaf=2871 : y = 0.907 : 104.0 secs : infill_ei\n",
            "\n",
            "mié oct 01 03:15:34 2025 AUC 0.916571357029703\n",
            "\n",
            "[mbo] 63: min_sum_hessian_in_leaf=0.0771; learning_rate=0.00606; feature_fraction=0.496; bagging_fraction=0.597; lambda_l1=7.62; lambda_l2=0.509; min_gain_to_split=3.52; bagging_freq=10; num_iterations=1429; max_depth=0; num_leaves=1018; min_data_in_leaf=967 : y = 0.917 : 260.8 secs : infill_ei\n",
            "\n",
            "Saved the current state after iteration 64 in the file bayesiana.RDATA.\n",
            "\n",
            "mié oct 01 03:16:27 2025 AUC 0.910859498721368\n",
            "\n",
            "[mbo] 64: min_sum_hessian_in_leaf=0.0746; learning_rate=0.064; feature_fraction=0.181; bagging_fraction=0.664; lambda_l1=2.58; lambda_l2=8.52; min_gain_to_split=11.9; bagging_freq=9; num_iterations=484; max_depth=8; num_leaves=1942; min_data_in_leaf=2458 : y = 0.911 : 50.5 secs : infill_ei\n",
            "\n",
            "mié oct 01 03:17:16 2025 AUC 0.910688702434719\n",
            "\n",
            "[mbo] 65: min_sum_hessian_in_leaf=0.0518; learning_rate=0.0598; feature_fraction=0.646; bagging_fraction=0.968; lambda_l1=7.45; lambda_l2=6.59; min_gain_to_split=5.87; bagging_freq=4; num_iterations=340; max_depth=10; num_leaves=397; min_data_in_leaf=1629 : y = 0.911 : 46.2 secs : infill_ei\n",
            "\n",
            "mié oct 01 03:18:46 2025 AUC 0.913852853958223\n",
            "\n",
            "[mbo] 66: min_sum_hessian_in_leaf=0.00165; learning_rate=0.0174; feature_fraction=0.719; bagging_fraction=0.47; lambda_l1=5.48; lambda_l2=2.11; min_gain_to_split=4.56; bagging_freq=2; num_iterations=1228; max_depth=-1; num_leaves=573; min_data_in_leaf=3060 : y = 0.914 : 87.7 secs : infill_ei\n",
            "\n",
            "mié oct 01 03:19:35 2025 AUC 0.905763357181161\n",
            "\n",
            "[mbo] 67: min_sum_hessian_in_leaf=0.057; learning_rate=0.0807; feature_fraction=0.362; bagging_fraction=0.72; lambda_l1=5.28; lambda_l2=3.05; min_gain_to_split=10.5; bagging_freq=9; num_iterations=322; max_depth=7; num_leaves=1917; min_data_in_leaf=471 : y = 0.906 : 45.8 secs : infill_ei\n",
            "\n",
            "mié oct 01 03:21:49 2025 AUC 0.914208563301385\n",
            "\n",
            "[mbo] 68: min_sum_hessian_in_leaf=0.083; learning_rate=0.0149; feature_fraction=0.473; bagging_fraction=0.747; lambda_l1=4.45; lambda_l2=6.37; min_gain_to_split=14.7; bagging_freq=8; num_iterations=2738; max_depth=2; num_leaves=511; min_data_in_leaf=3837 : y = 0.914 : 132.4 secs : infill_ei\n",
            "\n",
            "mié oct 01 03:22:43 2025 AUC 0.91130808399323\n",
            "\n",
            "[mbo] 69: min_sum_hessian_in_leaf=0.0779; learning_rate=0.0367; feature_fraction=0.129; bagging_fraction=0.754; lambda_l1=4.6; lambda_l2=0.633; min_gain_to_split=8.55; bagging_freq=8; num_iterations=1077; max_depth=3; num_leaves=425; min_data_in_leaf=3677 : y = 0.911 : 51.3 secs : infill_ei\n",
            "\n",
            "mié oct 01 03:23:32 2025 AUC 0.910097604661154\n",
            "\n",
            "[mbo] 70: min_sum_hessian_in_leaf=0.00312; learning_rate=0.0606; feature_fraction=0.474; bagging_fraction=0.489; lambda_l1=6.2; lambda_l2=3.86; min_gain_to_split=11.5; bagging_freq=9; num_iterations=962; max_depth=3; num_leaves=649; min_data_in_leaf=4335 : y = 0.91 : 45.5 secs : infill_ei\n",
            "\n",
            "mié oct 01 03:24:59 2025 AUC 0.909631334440636\n",
            "\n",
            "[mbo] 71: min_sum_hessian_in_leaf=0.0825; learning_rate=0.042; feature_fraction=0.884; bagging_fraction=0.624; lambda_l1=0.322; lambda_l2=9.78; min_gain_to_split=2.48; bagging_freq=6; num_iterations=426; max_depth=14; num_leaves=1734; min_data_in_leaf=951 : y = 0.91 : 84.8 secs : infill_ei\n",
            "\n",
            "mié oct 01 03:25:43 2025 AUC 0.900342536873727\n",
            "\n",
            "[mbo] 72: min_sum_hessian_in_leaf=0.0959; learning_rate=0.087; feature_fraction=0.526; bagging_fraction=0.264; lambda_l1=9.74; lambda_l2=5.02; min_gain_to_split=1.88; bagging_freq=5; num_iterations=880; max_depth=14; num_leaves=1992; min_data_in_leaf=4273 : y = 0.9 : 41.0 secs : infill_ei\n",
            "\n",
            "Saved the current state after iteration 73 in the file bayesiana.RDATA.\n",
            "\n",
            "mié oct 01 03:29:06 2025 AUC 0.9146526299598\n",
            "\n",
            "[mbo] 73: min_sum_hessian_in_leaf=0.0537; learning_rate=0.0285; feature_fraction=0.731; bagging_fraction=0.884; lambda_l1=3.5; lambda_l2=6.74; min_gain_to_split=6.13; bagging_freq=7; num_iterations=2733; max_depth=10; num_leaves=319; min_data_in_leaf=5508 : y = 0.915 : 200.0 secs : infill_ei\n",
            "\n",
            "mié oct 01 03:30:08 2025 AUC 0.91124786040472\n",
            "\n",
            "[mbo] 74: min_sum_hessian_in_leaf=0.00996; learning_rate=0.0388; feature_fraction=0.42; bagging_fraction=0.854; lambda_l1=7.7; lambda_l2=2.81; min_gain_to_split=10.2; bagging_freq=3; num_iterations=1038; max_depth=2; num_leaves=684; min_data_in_leaf=7107 : y = 0.911 : 58.7 secs : infill_ei\n",
            "\n",
            "mié oct 01 03:31:32 2025 AUC 0.91538954540418\n",
            "\n",
            "[mbo] 75: min_sum_hessian_in_leaf=0.0988; learning_rate=0.0146; feature_fraction=0.856; bagging_fraction=0.924; lambda_l1=2.99; lambda_l2=6.52; min_gain_to_split=12.3; bagging_freq=5; num_iterations=1073; max_depth=6; num_leaves=593; min_data_in_leaf=3578 : y = 0.915 : 81.8 secs : infill_ei\n",
            "\n",
            "mié oct 01 03:34:03 2025 AUC 0.914754510070111\n",
            "\n",
            "[mbo] 76: min_sum_hessian_in_leaf=0.0708; learning_rate=0.0332; feature_fraction=0.162; bagging_fraction=0.968; lambda_l1=3.63; lambda_l2=2.2; min_gain_to_split=12.7; bagging_freq=6; num_iterations=2371; max_depth=9; num_leaves=1791; min_data_in_leaf=772 : y = 0.915 : 148.9 secs : infill_ei\n",
            "\n",
            "mié oct 01 03:38:50 2025 AUC 0.915243739331387\n",
            "\n",
            "[mbo] 77: min_sum_hessian_in_leaf=0.0017; learning_rate=0.0203; feature_fraction=0.519; bagging_fraction=0.603; lambda_l1=4.03; lambda_l2=2.56; min_gain_to_split=5.6; bagging_freq=6; num_iterations=1966; max_depth=0; num_leaves=931; min_data_in_leaf=1082 : y = 0.915 : 283.2 secs : infill_ei\n",
            "\n",
            "Saved the current state after iteration 78 in the file bayesiana.RDATA.\n",
            "\n",
            "mié oct 01 03:41:38 2025 AUC 0.915350915175298\n",
            "\n",
            "[mbo] 78: min_sum_hessian_in_leaf=0.0633; learning_rate=0.0277; feature_fraction=0.593; bagging_fraction=0.931; lambda_l1=2.98; lambda_l2=9.42; min_gain_to_split=14.5; bagging_freq=2; num_iterations=2395; max_depth=5; num_leaves=157; min_data_in_leaf=2906 : y = 0.915 : 165.5 secs : infill_ei\n",
            "\n",
            "mié oct 01 03:45:07 2025 AUC 0.91110540041445\n",
            "\n",
            "[mbo] 79: min_sum_hessian_in_leaf=0.0472; learning_rate=0.0529; feature_fraction=0.793; bagging_fraction=0.483; lambda_l1=1.28; lambda_l2=8.18; min_gain_to_split=6.9; bagging_freq=1; num_iterations=2693; max_depth=13; num_leaves=946; min_data_in_leaf=4037 : y = 0.911 : 206.1 secs : infill_ei\n",
            "\n",
            "mié oct 01 03:46:46 2025 AUC 0.9119679823426\n",
            "\n",
            "[mbo] 80: min_sum_hessian_in_leaf=0.0797; learning_rate=0.0429; feature_fraction=0.298; bagging_fraction=0.676; lambda_l1=3.32; lambda_l2=8.18; min_gain_to_split=11.8; bagging_freq=2; num_iterations=1841; max_depth=2; num_leaves=1489; min_data_in_leaf=6831 : y = 0.912 : 96.2 secs : infill_ei\n",
            "\n",
            "mié oct 01 03:47:59 2025 AUC 0.903461893080983\n",
            "\n",
            "[mbo] 81: min_sum_hessian_in_leaf=0.019; learning_rate=0.0618; feature_fraction=0.889; bagging_fraction=0.288; lambda_l1=2.11; lambda_l2=7.8; min_gain_to_split=4.98; bagging_freq=9; num_iterations=1090; max_depth=8; num_leaves=1531; min_data_in_leaf=1890 : y = 0.903 : 70.4 secs : infill_ei\n",
            "\n",
            "mié oct 01 03:49:46 2025 AUC 0.915246900429664\n",
            "\n",
            "[mbo] 82: min_sum_hessian_in_leaf=0.0561; learning_rate=0.0234; feature_fraction=0.176; bagging_fraction=0.96; lambda_l1=4.64; lambda_l2=4.51; min_gain_to_split=13.9; bagging_freq=7; num_iterations=1567; max_depth=4; num_leaves=1924; min_data_in_leaf=5830 : y = 0.915 : 104.0 secs : infill_ei\n",
            "\n",
            "Saved the current state after iteration 83 in the file bayesiana.RDATA.\n",
            "\n",
            "mié oct 01 03:52:26 2025 AUC 0.915008735143665\n",
            "\n",
            "[mbo] 83: min_sum_hessian_in_leaf=0.0574; learning_rate=0.0236; feature_fraction=0.951; bagging_fraction=0.728; lambda_l1=1.71; lambda_l2=9.52; min_gain_to_split=12.2; bagging_freq=7; num_iterations=1833; max_depth=10; num_leaves=392; min_data_in_leaf=1449 : y = 0.915 : 156.8 secs : infill_ei\n",
            "\n",
            "mié oct 01 03:54:39 2025 AUC 0.901344070232205\n",
            "\n",
            "[mbo] 84: min_sum_hessian_in_leaf=0.0724; learning_rate=0.0679; feature_fraction=0.583; bagging_fraction=0.32; lambda_l1=2.95; lambda_l2=7.62; min_gain_to_split=4.36; bagging_freq=6; num_iterations=2995; max_depth=6; num_leaves=1921; min_data_in_leaf=5897 : y = 0.901 : 130.2 secs : infill_ei\n",
            "\n",
            "mié oct 01 03:56:28 2025 AUC 0.910907966627051\n",
            "\n",
            "[mbo] 85: min_sum_hessian_in_leaf=0.038; learning_rate=0.0859; feature_fraction=0.381; bagging_fraction=0.98; lambda_l1=3.4; lambda_l2=0.891; min_gain_to_split=11.8; bagging_freq=4; num_iterations=2117; max_depth=11; num_leaves=712; min_data_in_leaf=5522 : y = 0.911 : 106.5 secs : infill_ei\n",
            "\n",
            "mié oct 01 03:58:30 2025 AUC 0.912861360123646\n",
            "\n",
            "[mbo] 86: min_sum_hessian_in_leaf=0.026; learning_rate=0.00888; feature_fraction=0.99; bagging_fraction=0.418; lambda_l1=1.12; lambda_l2=2.94; min_gain_to_split=12.1; bagging_freq=10; num_iterations=1457; max_depth=7; num_leaves=1078; min_data_in_leaf=1628 : y = 0.913 : 118.2 secs : infill_ei\n",
            "\n",
            "mié oct 01 03:59:59 2025 AUC 0.896835639645502\n",
            "\n",
            "[mbo] 87: min_sum_hessian_in_leaf=0.0787; learning_rate=0.0883; feature_fraction=0.838; bagging_fraction=0.27; lambda_l1=4.96; lambda_l2=2.67; min_gain_to_split=0.27; bagging_freq=1; num_iterations=1820; max_depth=3; num_leaves=1754; min_data_in_leaf=6590 : y = 0.897 : 86.1 secs : infill_ei\n",
            "\n",
            "Saved the current state after iteration 88 in the file bayesiana.RDATA.\n",
            "\n",
            "mié oct 01 04:02:28 2025 AUC 0.915195082562752\n",
            "\n",
            "[mbo] 88: min_sum_hessian_in_leaf=0.0544; learning_rate=0.0174; feature_fraction=0.844; bagging_fraction=0.715; lambda_l1=2.35; lambda_l2=8.42; min_gain_to_split=14.2; bagging_freq=4; num_iterations=1845; max_depth=13; num_leaves=1805; min_data_in_leaf=4979 : y = 0.915 : 144.5 secs : infill_ei\n",
            "\n",
            "mié oct 01 04:03:58 2025 AUC 0.914748026269178\n",
            "\n",
            "[mbo] 89: min_sum_hessian_in_leaf=0.0516; learning_rate=0.0139; feature_fraction=0.799; bagging_fraction=0.417; lambda_l1=2.06; lambda_l2=0.299; min_gain_to_split=3.47; bagging_freq=10; num_iterations=2426; max_depth=3; num_leaves=183; min_data_in_leaf=1414 : y = 0.915 : 87.6 secs : infill_ei\n",
            "\n",
            "mié oct 01 04:05:19 2025 AUC 0.911840725164247\n",
            "\n",
            "[mbo] 90: min_sum_hessian_in_leaf=0.0167; learning_rate=0.0203; feature_fraction=0.914; bagging_fraction=0.397; lambda_l1=3.98; lambda_l2=2.88; min_gain_to_split=5.05; bagging_freq=10; num_iterations=1525; max_depth=0; num_leaves=1337; min_data_in_leaf=4142 : y = 0.912 : 77.3 secs : infill_ei\n",
            "\n",
            "mié oct 01 04:10:18 2025 AUC 0.915616877048279\n",
            "\n",
            "[mbo] 91: min_sum_hessian_in_leaf=0.0797; learning_rate=0.0138; feature_fraction=0.212; bagging_fraction=0.69; lambda_l1=7.64; lambda_l2=0.19; min_gain_to_split=10.6; bagging_freq=9; num_iterations=2958; max_depth=7; num_leaves=1599; min_data_in_leaf=1567 : y = 0.916 : 296.0 secs : infill_ei\n",
            "\n",
            "Saved the current state after iteration 92 in the file bayesiana.RDATA.\n",
            "\n",
            "mié oct 01 04:10:58 2025 AUC 0.914145968591185\n",
            "\n",
            "[mbo] 92: min_sum_hessian_in_leaf=0.0414; learning_rate=0.0345; feature_fraction=0.886; bagging_fraction=0.83; lambda_l1=3.04; lambda_l2=9.07; min_gain_to_split=4.2; bagging_freq=1; num_iterations=470; max_depth=12; num_leaves=1146; min_data_in_leaf=5626 : y = 0.914 : 36.8 secs : infill_ei\n",
            "\n",
            "mié oct 01 04:12:50 2025 AUC 0.913966204466658\n",
            "\n",
            "[mbo] 93: min_sum_hessian_in_leaf=0.0972; learning_rate=0.0296; feature_fraction=0.316; bagging_fraction=0.625; lambda_l1=9.53; lambda_l2=2.25; min_gain_to_split=9.06; bagging_freq=7; num_iterations=1465; max_depth=5; num_leaves=2040; min_data_in_leaf=3172 : y = 0.914 : 108.6 secs : infill_ei\n",
            "\n",
            "mié oct 01 04:18:40 2025 AUC 0.912175839872575\n",
            "\n",
            "[mbo] 94: min_sum_hessian_in_leaf=0.0146; learning_rate=0.0155; feature_fraction=0.579; bagging_fraction=0.438; lambda_l1=7.34; lambda_l2=0.601; min_gain_to_split=7.08; bagging_freq=10; num_iterations=1868; max_depth=0; num_leaves=603; min_data_in_leaf=48 : y = 0.912 : 346.8 secs : infill_ei\n",
            "\n",
            "mié oct 01 04:20:08 2025 AUC 0.908868785400077\n",
            "\n",
            "[mbo] 95: min_sum_hessian_in_leaf=0.0649; learning_rate=0.0151; feature_fraction=0.799; bagging_fraction=0.881; lambda_l1=3.32; lambda_l2=8.27; min_gain_to_split=13.8; bagging_freq=3; num_iterations=2137; max_depth=1; num_leaves=1462; min_data_in_leaf=6788 : y = 0.909 : 84.6 secs : infill_ei\n",
            "\n",
            "mié oct 01 04:22:34 2025 AUC 0.914969167791321\n",
            "\n",
            "[mbo] 96: min_sum_hessian_in_leaf=0.0649; learning_rate=0.0254; feature_fraction=0.489; bagging_fraction=0.644; lambda_l1=0.388; lambda_l2=0.996; min_gain_to_split=3.88; bagging_freq=9; num_iterations=1958; max_depth=5; num_leaves=73; min_data_in_leaf=2658 : y = 0.915 : 142.9 secs : infill_ei\n",
            "\n",
            "Saved the current state after iteration 97 in the file bayesiana.RDATA.\n",
            "\n",
            "mié oct 01 04:24:19 2025 AUC 0.916125870140854\n",
            "\n",
            "[mbo] 97: min_sum_hessian_in_leaf=0.0664; learning_rate=0.00655; feature_fraction=0.93; bagging_fraction=0.606; lambda_l1=5.33; lambda_l2=1.9; min_gain_to_split=8.15; bagging_freq=9; num_iterations=912; max_depth=11; num_leaves=1072; min_data_in_leaf=1994 : y = 0.916 : 101.6 secs : infill_ei\n",
            "\n",
            "mié oct 01 04:24:42 2025 AUC 0.908155626534201\n",
            "\n",
            "[mbo] 98: min_sum_hessian_in_leaf=0.0122; learning_rate=0.0385; feature_fraction=0.718; bagging_fraction=0.538; lambda_l1=5.02; lambda_l2=0.868; min_gain_to_split=13.7; bagging_freq=2; num_iterations=528; max_depth=1; num_leaves=98; min_data_in_leaf=5022 : y = 0.908 : 19.4 secs : infill_ei\n",
            "\n",
            "mié oct 01 04:27:01 2025 AUC 0.915263529032735\n",
            "\n",
            "[mbo] 99: min_sum_hessian_in_leaf=0.0611; learning_rate=0.0111; feature_fraction=0.79; bagging_fraction=0.576; lambda_l1=0.596; lambda_l2=5.82; min_gain_to_split=7.76; bagging_freq=8; num_iterations=1751; max_depth=8; num_leaves=1254; min_data_in_leaf=3230 : y = 0.915 : 134.8 secs : infill_ei\n",
            "\n",
            "mié oct 01 04:29:04 2025 AUC 0.911325122294559\n",
            "\n",
            "[mbo] 100: min_sum_hessian_in_leaf=0.0801; learning_rate=0.0771; feature_fraction=0.377; bagging_fraction=0.897; lambda_l1=4.78; lambda_l2=7.3; min_gain_to_split=6.75; bagging_freq=5; num_iterations=1931; max_depth=13; num_leaves=267; min_data_in_leaf=3132 : y = 0.911 : 119.6 secs : infill_ei\n",
            "\n",
            "Saved the final state in the file bayesiana.RDATA\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# inicio la optimizacion bayesiana, retomando si ya existe\n",
        "# es la celda mas lenta de todo el notebook\n",
        "\n",
        "if (!file.exists(kbayesiana)) {\n",
        "  bayesiana_salida <- mbo(obj.fun, learner= surr.km, control= ctrl)\n",
        "} else {\n",
        "  bayesiana_salida <- mboContinue(kbayesiana) # retomo en caso que ya exista\n",
        "}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "ssk5nnMk6INK",
        "vscode": {
          "languageId": "r"
        }
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<style>\n",
              ".list-inline {list-style: none; margin:0; padding: 0}\n",
              ".list-inline>li {display: inline-block}\n",
              ".list-inline>li:not(:last-child)::after {content: \"\\00b7\"; padding: 0 .5ex}\n",
              "</style>\n",
              "<ol class=list-inline><li>'min_sum_hessian_in_leaf'</li><li>'learning_rate'</li><li>'feature_fraction'</li><li>'bagging_fraction'</li><li>'lambda_l1'</li><li>'lambda_l2'</li><li>'min_gain_to_split'</li><li>'bagging_freq'</li><li>'num_iterations'</li><li>'max_depth'</li><li>'num_leaves'</li><li>'min_data_in_leaf'</li><li>'y'</li><li>'dob'</li><li>'eol'</li><li>'error.message'</li><li>'exec.time'</li><li>'ei'</li><li>'error.model'</li><li>'train.time'</li><li>'prop.type'</li><li>'propose.time'</li><li>'se'</li><li>'mean'</li></ol>\n"
            ],
            "text/latex": [
              "\\begin{enumerate*}\n",
              "\\item 'min\\_sum\\_hessian\\_in\\_leaf'\n",
              "\\item 'learning\\_rate'\n",
              "\\item 'feature\\_fraction'\n",
              "\\item 'bagging\\_fraction'\n",
              "\\item 'lambda\\_l1'\n",
              "\\item 'lambda\\_l2'\n",
              "\\item 'min\\_gain\\_to\\_split'\n",
              "\\item 'bagging\\_freq'\n",
              "\\item 'num\\_iterations'\n",
              "\\item 'max\\_depth'\n",
              "\\item 'num\\_leaves'\n",
              "\\item 'min\\_data\\_in\\_leaf'\n",
              "\\item 'y'\n",
              "\\item 'dob'\n",
              "\\item 'eol'\n",
              "\\item 'error.message'\n",
              "\\item 'exec.time'\n",
              "\\item 'ei'\n",
              "\\item 'error.model'\n",
              "\\item 'train.time'\n",
              "\\item 'prop.type'\n",
              "\\item 'propose.time'\n",
              "\\item 'se'\n",
              "\\item 'mean'\n",
              "\\end{enumerate*}\n"
            ],
            "text/markdown": [
              "1. 'min_sum_hessian_in_leaf'\n",
              "2. 'learning_rate'\n",
              "3. 'feature_fraction'\n",
              "4. 'bagging_fraction'\n",
              "5. 'lambda_l1'\n",
              "6. 'lambda_l2'\n",
              "7. 'min_gain_to_split'\n",
              "8. 'bagging_freq'\n",
              "9. 'num_iterations'\n",
              "10. 'max_depth'\n",
              "11. 'num_leaves'\n",
              "12. 'min_data_in_leaf'\n",
              "13. 'y'\n",
              "14. 'dob'\n",
              "15. 'eol'\n",
              "16. 'error.message'\n",
              "17. 'exec.time'\n",
              "18. 'ei'\n",
              "19. 'error.model'\n",
              "20. 'train.time'\n",
              "21. 'prop.type'\n",
              "22. 'propose.time'\n",
              "23. 'se'\n",
              "24. 'mean'\n",
              "\n",
              "\n"
            ],
            "text/plain": [
              " [1] \"min_sum_hessian_in_leaf\" \"learning_rate\"          \n",
              " [3] \"feature_fraction\"        \"bagging_fraction\"       \n",
              " [5] \"lambda_l1\"               \"lambda_l2\"              \n",
              " [7] \"min_gain_to_split\"       \"bagging_freq\"           \n",
              " [9] \"num_iterations\"          \"max_depth\"              \n",
              "[11] \"num_leaves\"              \"min_data_in_leaf\"       \n",
              "[13] \"y\"                       \"dob\"                    \n",
              "[15] \"eol\"                     \"error.message\"          \n",
              "[17] \"exec.time\"               \"ei\"                     \n",
              "[19] \"error.model\"             \"train.time\"             \n",
              "[21] \"prop.type\"               \"propose.time\"           \n",
              "[23] \"se\"                      \"mean\"                   "
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "tb_bayesiana <- as.data.table(bayesiana_salida$opt.path)\n",
        "colnames( tb_bayesiana)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "u4zq-vknhjGc",
        "vscode": {
          "languageId": "r"
        }
      },
      "outputs": [],
      "source": [
        "# almaceno los resultados de la Bayesian Optimization\n",
        "# y capturo los mejores hiperparametros encontrados\n",
        "\n",
        "tb_bayesiana <- as.data.table(bayesiana_salida$opt.path)\n",
        "\n",
        "tb_bayesiana[, iter := .I]\n",
        "\n",
        "# ordeno en forma descendente por AUC = y\n",
        "setorder(tb_bayesiana, -y)\n",
        "\n",
        "# grabo para eventualmente poder utilizarlos en OTRA corrida\n",
        "fwrite( tb_bayesiana,\n",
        "  file= \"BO_log.txt\",\n",
        "  sep= \"\\t\"\n",
        ")\n",
        "\n",
        "# los mejores hiperparámetros son los que quedaron en el registro 1 de la tabla\n",
        "PARAM$out$lgbm$mejores_hiperparametros <- tb_bayesiana[\n",
        "  1, # el primero es el de mejor AUC\n",
        "  setdiff(colnames(tb_bayesiana),\n",
        "    c(\"y\",\"dob\",\"eol\",\"error.message\",\"exec.time\",\"ei\",\"error.model\",\n",
        "      \"train.time\",\"prop.type\",\"propose.time\",\"se\",\"mean\",\"iter\")),\n",
        "  with= FALSE\n",
        "]\n",
        "\n",
        "PARAM$out$lgbm$y <- tb_bayesiana[1, y]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "id": "E8v2eA427N8e",
        "vscode": {
          "languageId": "r"
        }
      },
      "outputs": [],
      "source": [
        "write_yaml( PARAM, file=\"PARAM.yml\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "id": "iBTWexVU7PGC",
        "vscode": {
          "languageId": "r"
        }
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "   min_sum_hessian_in_leaf learning_rate feature_fraction bagging_fraction\n",
            "                     <num>         <num>            <num>            <num>\n",
            "1:              0.09209806    0.01740844        0.4988602        0.6560073\n",
            "   lambda_l1 lambda_l2 min_gain_to_split bagging_freq num_iterations max_depth\n",
            "       <num>     <num>             <num>        <int>          <int>     <int>\n",
            "1:   3.88754  3.226063          8.048736            6           2072        11\n",
            "   num_leaves min_data_in_leaf\n",
            "        <int>            <int>\n",
            "1:       1789              735\n",
            "[1] 0.9172143\n"
          ]
        }
      ],
      "source": [
        "print(PARAM$out$lgbm$mejores_hiperparametros)\n",
        "print(PARAM$out$lgbm$y)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TKsVZmAnhwX-"
      },
      "source": [
        "## 2.3  Produccion"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RQ_C33Tr5B_9"
      },
      "source": [
        "### Final Training\n",
        "Construyo el modelo final, que es uno solo, no hace ningun tipo de particion < training, validation, testing>]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8qFmFivf5Iet"
      },
      "source": [
        "#### Final Training Dataset\n",
        "\n",
        "Aqui esta la gran decision de en qué meses hago el Final Training\n",
        "<br> debo utilizar los mejores hiperparámetros que encontré en la  optimización bayesiana"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "id": "lg5WVZncvc7H",
        "vscode": {
          "languageId": "r"
        }
      },
      "outputs": [],
      "source": [
        "# clase01\n",
        "dataset[, clase01 := ifelse(clase_ternaria %in% c(\"BAJA+2\"), 1L, 0L)]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "id": "yc9QzXREv0xf",
        "vscode": {
          "languageId": "r"
        }
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<table class=\"dataframe\">\n",
              "<caption>A data.table: 3 × 2</caption>\n",
              "<thead>\n",
              "\t<tr><th scope=col>clase_ternaria</th><th scope=col>N</th></tr>\n",
              "\t<tr><th scope=col>&lt;fct&gt;</th><th scope=col>&lt;int&gt;</th></tr>\n",
              "</thead>\n",
              "<tbody>\n",
              "\t<tr><td>CONTINUA</td><td>320372</td></tr>\n",
              "\t<tr><td>BAJA+2  </td><td>  1857</td></tr>\n",
              "\t<tr><td>BAJA+1  </td><td>  1453</td></tr>\n",
              "</tbody>\n",
              "</table>\n"
            ],
            "text/latex": [
              "A data.table: 3 × 2\n",
              "\\begin{tabular}{ll}\n",
              " clase\\_ternaria & N\\\\\n",
              " <fct> & <int>\\\\\n",
              "\\hline\n",
              "\t CONTINUA & 320372\\\\\n",
              "\t BAJA+2   &   1857\\\\\n",
              "\t BAJA+1   &   1453\\\\\n",
              "\\end{tabular}\n"
            ],
            "text/markdown": [
              "\n",
              "A data.table: 3 × 2\n",
              "\n",
              "| clase_ternaria &lt;fct&gt; | N &lt;int&gt; |\n",
              "|---|---|\n",
              "| CONTINUA | 320372 |\n",
              "| BAJA+2   |   1857 |\n",
              "| BAJA+1   |   1453 |\n",
              "\n"
            ],
            "text/plain": [
              "  clase_ternaria N     \n",
              "1 CONTINUA       320372\n",
              "2 BAJA+2           1857\n",
              "3 BAJA+1           1453"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "dataset_train <- dataset[foto_mes %in% PARAM$train_final]\n",
        "dataset_train[,.N,clase_ternaria]\n",
        "dataset_train <- dataset_train[clase_ternaria != \"BAJA+1\"]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "id": "thjdqEBLuvNt",
        "vscode": {
          "languageId": "r"
        }
      },
      "outputs": [],
      "source": [
        "# dejo los datos en el formato que necesita LightGBM\n",
        "\n",
        "dtrain_final <- lgb.Dataset(\n",
        "  data= data.matrix(dataset_train[, campos_buenos, with= FALSE]),\n",
        "  label= dataset_train[, clase01]\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VNUa-WSz5Oqu"
      },
      "source": [
        "#### Final Training Hyperparameters"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "id": "FgCcvBfEwImu",
        "vscode": {
          "languageId": "r"
        }
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<dl>\n",
              "\t<dt>$boosting</dt>\n",
              "\t\t<dd>'gbdt'</dd>\n",
              "\t<dt>$objective</dt>\n",
              "\t\t<dd>'binary'</dd>\n",
              "\t<dt>$metric</dt>\n",
              "\t\t<dd>'auc'</dd>\n",
              "\t<dt>$first_metric_only</dt>\n",
              "\t\t<dd>FALSE</dd>\n",
              "\t<dt>$boost_from_average</dt>\n",
              "\t\t<dd>TRUE</dd>\n",
              "\t<dt>$feature_pre_filter</dt>\n",
              "\t\t<dd>FALSE</dd>\n",
              "\t<dt>$force_row_wise</dt>\n",
              "\t\t<dd>TRUE</dd>\n",
              "\t<dt>$verbosity</dt>\n",
              "\t\t<dd>-100</dd>\n",
              "\t<dt>$seed</dt>\n",
              "\t\t<dd>200003</dd>\n",
              "\t<dt>$max_depth</dt>\n",
              "\t\t<dd>11</dd>\n",
              "\t<dt>$min_gain_to_split</dt>\n",
              "\t\t<dd>8.04873600040865</dd>\n",
              "\t<dt>$min_sum_hessian_in_leaf</dt>\n",
              "\t\t<dd>0.0920980590873412</dd>\n",
              "\t<dt>$lambda_l1</dt>\n",
              "\t\t<dd>3.88754044481196</dd>\n",
              "\t<dt>$lambda_l2</dt>\n",
              "\t\t<dd>3.22606287387807</dd>\n",
              "\t<dt>$max_bin</dt>\n",
              "\t\t<dd>31</dd>\n",
              "\t<dt>$bagging_fraction</dt>\n",
              "\t\t<dd>0.656007257650812</dd>\n",
              "\t<dt>$pos_bagging_fraction</dt>\n",
              "\t\t<dd>1</dd>\n",
              "\t<dt>$neg_bagging_fraction</dt>\n",
              "\t\t<dd>1</dd>\n",
              "\t<dt>$is_unbalance</dt>\n",
              "\t\t<dd>TRUE</dd>\n",
              "\t<dt>$scale_pos_weight</dt>\n",
              "\t\t<dd>1</dd>\n",
              "\t<dt>$drop_rate</dt>\n",
              "\t\t<dd>0.1</dd>\n",
              "\t<dt>$max_drop</dt>\n",
              "\t\t<dd>50</dd>\n",
              "\t<dt>$skip_drop</dt>\n",
              "\t\t<dd>0.5</dd>\n",
              "\t<dt>$extra_trees</dt>\n",
              "\t\t<dd>FALSE</dd>\n",
              "\t<dt>$num_iterations</dt>\n",
              "\t\t<dd>2072</dd>\n",
              "\t<dt>$learning_rate</dt>\n",
              "\t\t<dd>0.0174084421160737</dd>\n",
              "\t<dt>$feature_fraction</dt>\n",
              "\t\t<dd>0.498860166018654</dd>\n",
              "\t<dt>$num_leaves</dt>\n",
              "\t\t<dd>1789</dd>\n",
              "\t<dt>$min_data_in_leaf</dt>\n",
              "\t\t<dd>735</dd>\n",
              "\t<dt>$bagging_freq</dt>\n",
              "\t\t<dd>6</dd>\n",
              "</dl>\n"
            ],
            "text/latex": [
              "\\begin{description}\n",
              "\\item[\\$boosting] 'gbdt'\n",
              "\\item[\\$objective] 'binary'\n",
              "\\item[\\$metric] 'auc'\n",
              "\\item[\\$first\\_metric\\_only] FALSE\n",
              "\\item[\\$boost\\_from\\_average] TRUE\n",
              "\\item[\\$feature\\_pre\\_filter] FALSE\n",
              "\\item[\\$force\\_row\\_wise] TRUE\n",
              "\\item[\\$verbosity] -100\n",
              "\\item[\\$seed] 200003\n",
              "\\item[\\$max\\_depth] 11\n",
              "\\item[\\$min\\_gain\\_to\\_split] 8.04873600040865\n",
              "\\item[\\$min\\_sum\\_hessian\\_in\\_leaf] 0.0920980590873412\n",
              "\\item[\\$lambda\\_l1] 3.88754044481196\n",
              "\\item[\\$lambda\\_l2] 3.22606287387807\n",
              "\\item[\\$max\\_bin] 31\n",
              "\\item[\\$bagging\\_fraction] 0.656007257650812\n",
              "\\item[\\$pos\\_bagging\\_fraction] 1\n",
              "\\item[\\$neg\\_bagging\\_fraction] 1\n",
              "\\item[\\$is\\_unbalance] TRUE\n",
              "\\item[\\$scale\\_pos\\_weight] 1\n",
              "\\item[\\$drop\\_rate] 0.1\n",
              "\\item[\\$max\\_drop] 50\n",
              "\\item[\\$skip\\_drop] 0.5\n",
              "\\item[\\$extra\\_trees] FALSE\n",
              "\\item[\\$num\\_iterations] 2072\n",
              "\\item[\\$learning\\_rate] 0.0174084421160737\n",
              "\\item[\\$feature\\_fraction] 0.498860166018654\n",
              "\\item[\\$num\\_leaves] 1789\n",
              "\\item[\\$min\\_data\\_in\\_leaf] 735\n",
              "\\item[\\$bagging\\_freq] 6\n",
              "\\end{description}\n"
            ],
            "text/markdown": [
              "$boosting\n",
              ":   'gbdt'\n",
              "$objective\n",
              ":   'binary'\n",
              "$metric\n",
              ":   'auc'\n",
              "$first_metric_only\n",
              ":   FALSE\n",
              "$boost_from_average\n",
              ":   TRUE\n",
              "$feature_pre_filter\n",
              ":   FALSE\n",
              "$force_row_wise\n",
              ":   TRUE\n",
              "$verbosity\n",
              ":   -100\n",
              "$seed\n",
              ":   200003\n",
              "$max_depth\n",
              ":   11\n",
              "$min_gain_to_split\n",
              ":   8.04873600040865\n",
              "$min_sum_hessian_in_leaf\n",
              ":   0.0920980590873412\n",
              "$lambda_l1\n",
              ":   3.88754044481196\n",
              "$lambda_l2\n",
              ":   3.22606287387807\n",
              "$max_bin\n",
              ":   31\n",
              "$bagging_fraction\n",
              ":   0.656007257650812\n",
              "$pos_bagging_fraction\n",
              ":   1\n",
              "$neg_bagging_fraction\n",
              ":   1\n",
              "$is_unbalance\n",
              ":   TRUE\n",
              "$scale_pos_weight\n",
              ":   1\n",
              "$drop_rate\n",
              ":   0.1\n",
              "$max_drop\n",
              ":   50\n",
              "$skip_drop\n",
              ":   0.5\n",
              "$extra_trees\n",
              ":   FALSE\n",
              "$num_iterations\n",
              ":   2072\n",
              "$learning_rate\n",
              ":   0.0174084421160737\n",
              "$feature_fraction\n",
              ":   0.498860166018654\n",
              "$num_leaves\n",
              ":   1789\n",
              "$min_data_in_leaf\n",
              ":   735\n",
              "$bagging_freq\n",
              ":   6\n",
              "\n",
              "\n"
            ],
            "text/plain": [
              "$boosting\n",
              "[1] \"gbdt\"\n",
              "\n",
              "$objective\n",
              "[1] \"binary\"\n",
              "\n",
              "$metric\n",
              "[1] \"auc\"\n",
              "\n",
              "$first_metric_only\n",
              "[1] FALSE\n",
              "\n",
              "$boost_from_average\n",
              "[1] TRUE\n",
              "\n",
              "$feature_pre_filter\n",
              "[1] FALSE\n",
              "\n",
              "$force_row_wise\n",
              "[1] TRUE\n",
              "\n",
              "$verbosity\n",
              "[1] -100\n",
              "\n",
              "$seed\n",
              "[1] 200003\n",
              "\n",
              "$max_depth\n",
              "[1] 11\n",
              "\n",
              "$min_gain_to_split\n",
              "[1] 8.048736\n",
              "\n",
              "$min_sum_hessian_in_leaf\n",
              "[1] 0.09209806\n",
              "\n",
              "$lambda_l1\n",
              "[1] 3.88754\n",
              "\n",
              "$lambda_l2\n",
              "[1] 3.226063\n",
              "\n",
              "$max_bin\n",
              "[1] 31\n",
              "\n",
              "$bagging_fraction\n",
              "[1] 0.6560073\n",
              "\n",
              "$pos_bagging_fraction\n",
              "[1] 1\n",
              "\n",
              "$neg_bagging_fraction\n",
              "[1] 1\n",
              "\n",
              "$is_unbalance\n",
              "[1] TRUE\n",
              "\n",
              "$scale_pos_weight\n",
              "[1] 1\n",
              "\n",
              "$drop_rate\n",
              "[1] 0.1\n",
              "\n",
              "$max_drop\n",
              "[1] 50\n",
              "\n",
              "$skip_drop\n",
              "[1] 0.5\n",
              "\n",
              "$extra_trees\n",
              "[1] FALSE\n",
              "\n",
              "$num_iterations\n",
              "[1] 2072\n",
              "\n",
              "$learning_rate\n",
              "[1] 0.01740844\n",
              "\n",
              "$feature_fraction\n",
              "[1] 0.4988602\n",
              "\n",
              "$num_leaves\n",
              "[1] 1789\n",
              "\n",
              "$min_data_in_leaf\n",
              "[1] 735\n",
              "\n",
              "$bagging_freq\n",
              "[1] 6\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "param_final <- modifyList(PARAM$lgbm$param_fijos,\n",
        "  PARAM$out$lgbm$mejores_hiperparametros)\n",
        "\n",
        "param_final"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TZIYn4l95TBH"
      },
      "source": [
        "#### Training\n",
        "Genero el modelo final, siempre sobre TODOS los datos de  final_train, sin hacer ningun tipo de undersampling de la clase mayoritaria y mucho menos cross validation."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "id": "vPLsd4mMRe4u",
        "vscode": {
          "languageId": "r"
        }
      },
      "outputs": [],
      "source": [
        "# este punto es muy SUTIL  y será revisado en la Clase 05\n",
        "\n",
        "param_normalizado <- copy(param_final)\n",
        "param_normalizado$min_data_in_leaf <-  round(param_final$min_data_in_leaf / PARAM$trainingstrategy$undersampling)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "id": "WRI_-taRwOXO",
        "vscode": {
          "languageId": "r"
        }
      },
      "outputs": [],
      "source": [
        "# entreno LightGBM\n",
        "\n",
        "param_normalizado$seed <- 200003\n",
        "\n",
        "modelo_final <- lgb.train(\n",
        "  data= dtrain_final,\n",
        "  param= param_normalizado\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "id": "_bkhnCvj0g3Q",
        "vscode": {
          "languageId": "r"
        }
      },
      "outputs": [],
      "source": [
        "# ahora imprimo la importancia de variables\n",
        "\n",
        "tb_importancia <- as.data.table(lgb.importance(modelo_final))\n",
        "archivo_importancia <- \"impo.txt\"\n",
        "\n",
        "fwrite(tb_importancia,\n",
        "  file= archivo_importancia,\n",
        "  sep= \"\\t\"\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "id": "lZ3sLmbh0kFj",
        "vscode": {
          "languageId": "r"
        }
      },
      "outputs": [],
      "source": [
        "# grabo a disco el modelo en un formato para seres humanos ... ponele ...\n",
        "lgb.save(modelo_final, \"modelo.txt\" )"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VEtp2--t5Ymg"
      },
      "source": [
        "### Scoring"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hI5008Mj5ZdI"
      },
      "source": [
        "Aplico el modelo final a los datos del futuro"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "id": "PimBY3N_0ryP",
        "vscode": {
          "languageId": "r"
        }
      },
      "outputs": [],
      "source": [
        "# aplico el modelo a los datos sin clase\n",
        "dfuture <- dataset[foto_mes %in% PARAM$future]\n",
        "\n",
        "# aplico el modelo a los datos nuevos\n",
        "prediccion <- predict(\n",
        "  modelo_final,\n",
        "  data.matrix(dfuture[, campos_buenos, with= FALSE])\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {
        "id": "M9_NCquymhtF",
        "vscode": {
          "languageId": "r"
        }
      },
      "outputs": [],
      "source": [
        "# inicilizo el dataset  drealidad\n",
        "drealidad <- realidad_inicializar(dfuture, PARAM)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D26rNRh55gpw"
      },
      "source": [
        "#### Tabla Prediccion"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 54,
      "metadata": {
        "id": "RJwg7LHd11yu",
        "vscode": {
          "languageId": "r"
        }
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Warning message in dir.create(\"kaggle\"):\n",
            "\"'kaggle' already exists\"\n"
          ]
        }
      ],
      "source": [
        "# tabla de prediccion\n",
        "\n",
        "tb_prediccion <- dfuture[, list(numero_de_cliente, foto_mes)]\n",
        "tb_prediccion[, prob := prediccion ]\n",
        "\n",
        "# --- Aplicación del umbral y creación de la columna de clasificación ---\n",
        "# Defino el umbral\n",
        "umbral <- 1/40\n",
        "\n",
        "# Creo la columna 'clase_predicha' (columna 2 del output final)\n",
        "# Si 'prob' > 'umbral', asigna 1 (clasificado como positivo), sino asigna 0.\n",
        "tb_prediccion[, Predicted := as.integer(prob > umbral)]\n",
        "# ----------------------------------------------------------------------\n",
        "\n",
        "# Selecciono solo las columnas requeridas (ID del cliente y la predicción binaria)\n",
        "# Aquí 'numero_de_cliente' es la columna 1, y 'Predicted' es la columna 2.\n",
        "tb_final <- tb_prediccion[, list(numero_de_cliente, Predicted)]\n",
        "\n",
        "dir.create(\"kaggle\")\n",
        "# grabo las probabilidad del modelo\n",
        "fwrite(tb_final,\n",
        "  file= \"./kaggle/prediccion.csv\",\n",
        "  sep= \",\"\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jOt4eG_55ltv"
      },
      "source": [
        "Kaggle Competition Submit"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 58,
      "metadata": {
        "id": "gWW3tatE12je",
        "vscode": {
          "languageId": "r"
        }
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "ENVIOS= 126197450180682 \t TOTAL= 160280000 \t Public= 123933333 \t Private= 175857143"
          ]
        }
      ],
      "source": [
        "resultados <- data.table()\n",
        "\n",
        "res <- realidad_evaluar(drealidad, tb_prediccion)\n",
        "\n",
        "# Obtener la cantidad de 1's predichos\n",
        "cantidad_de_1s <- tb_final[, sum(tb_prediccion)]\n",
        "\n",
        "options(scipen = 999)\n",
        "cat( \n",
        "  \"ENVIOS=\", cantidad_de_1s,\n",
        "  \"\\t TOTAL=\", res$total,\n",
        "  \"\\t Public=\", res$public,\n",
        "  \"\\t Private=\", res$private,\n",
        "  sep= \" \"\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "B9tB2X4439Hg",
        "vscode": {
          "languageId": "r"
        }
      },
      "outputs": [],
      "source": [
        "write_yaml( PARAM, file=\"PARAM.yml\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9zA_W25c15DP",
        "vscode": {
          "languageId": "r"
        }
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "'lun sept 29 17:24:31 2025'"
            ],
            "text/latex": [
              "'lun sept 29 17:24:31 2025'"
            ],
            "text/markdown": [
              "'lun sept 29 17:24:31 2025'"
            ],
            "text/plain": [
              "[1] \"lun sept 29 17:24:31 2025\""
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "\n",
        "format(Sys.time(), \"%a %b %d %X %Y\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UdVZucdLHzZ0"
      },
      "source": [
        "Finalmente usted deberá cargar el resultado de su corrida en la Google Sheet Colaborativa,  hoja **TareaHogar04**\n",
        "<br> Siéntase libre de agregar las columnas que hagan falta a la planilla"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "R",
      "language": "R",
      "name": "ir"
    },
    "language_info": {
      "codemirror_mode": "r",
      "file_extension": ".r",
      "mimetype": "text/x-r-source",
      "name": "R",
      "pygments_lexer": "r",
      "version": "4.4.3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
