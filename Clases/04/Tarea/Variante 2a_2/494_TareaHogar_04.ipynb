{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0cEmzeUKFkPh"
      },
      "source": [
        "# Tarea para el Hogar 04"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DenyKXkiJ5JN"
      },
      "source": [
        "##  1. Big Picture"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l-K2_ZsZGrVD"
      },
      "source": [
        "LightGBM es el algoritmo estado del arte para datasets estructurados.\n",
        "<br> La Bayesian Optimization es el estado del arte para optimización de hiperparámetros\n",
        "<br> Las soluciones a las tres competencias de la asignatura contendrán LightGBMs y Bayesian Optimizations\n",
        "<br> LightGBM ha aumentado en forma no darwiniana sus hiperparámetros en los últimos ocho años; no todos los existentes son útiles.\n",
        "<br> Es necesario lograr entender cuales son los hiperparámetros relevantes de LightGBM"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K9GkTOk5J9t3"
      },
      "source": [
        "## 2. Hiperparámetros del LightGBM"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VmEFy0ukKL5T"
      },
      "source": [
        "Los objetivos de esta tarea son:\n",
        "\n",
        "\n",
        "*   Aumentar la rentabilidad de la campaña de marketing de retención proactiva de clientes.\n",
        "*   Generar un mejor modelo optimizando sus hiperparámetros\n",
        "*   Conceptual : investigar los mas relevantes hiperparámetros de LightGBM\n",
        "*   Familiarizarse con la Bayesian Optimization, sus largos tiempos de corrida y opciones para reducirlos\n",
        "*   Familiarizarse con el uso de máquinas virtuales de Google Colab\n",
        "*   Ver un pipeline completo de optimización de hiperparámetros y puesta en producción"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5yvlS6JQLRMd"
      },
      "source": [
        "LightGBM cuenta con mas de 60 hiperparámetros, siendo posible utilizar 40 al mismo tiempo, aunque no razonable.\n",
        "<br> La documentación oficial de los hiperparámetros de LightGBM es  https://lightgbm.readthedocs.io/en/latest/Parameters.html#core-parameters\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eydI4YNAsFaf"
      },
      "source": [
        "Se lo alerta sobre que una Optimizacion Bayesiana lleva varias horas de corrida, y usted deberá correr VARIAS optimizaciones para descubrir cuales parámetros conviene optimizar.\n",
        "<br> A pesar que la próxima clase es recien en viernes 01 de agosto, inicie la tarea con tiempo, aprenda a planificar estratégicamente sus corridas como un@ científ@  de datos."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RzU4S0SeMcpp"
      },
      "source": [
        "Es necesario investigar cuales son los hiperparámetros de LightGBM que vale la pena optimizar en una Bayesian Optimization, ya que los realmente utiles son apenas un reducido subconjunto.\n",
        "<br>Usted deberá investigar cuales son los hiperparámetros mas relevantes de LightGBM, su primer alternativa es preguntándole a su amigo con capacidades especiales ChatGPT o sus endogámicos familiares Claude, DeepSeek, Gemini, Grok, etc\n",
        "<br> La segunda alternativa es la propia documentación de LightGBM  https://lightgbm.readthedocs.io/en/latest/Parameters-Tuning.html\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LNptUgI_NWWG"
      },
      "source": [
        "Adicionalmente podra buscar información como la que proveen esta diminuta muestra aleatoria de artículos ligeros:\n",
        "*  https://medium.com/@sarahzouinina/a-deep-dive-into-lightgbm-how-to-choose-and-tune-parameters-7c584945842e\n",
        "*  https://www.kaggle.com/code/somang1418/tuning-hyperparameters-under-10-minutes-lgbm\n",
        "*  https://towardsdatascience.com/beginners-guide-to-the-must-know-lightgbm-hyperparameters-a0005a812702/\n",
        "\n",
        "\n",
        "<br>  La muestra anterior se brinda a modo de ejemplo, usted deberá buscar muuuuchas  fuentes adicionales de información\n",
        "<br> Tenga presente que LightGBM es el estado del arte en modelado predictivo para datasets estructurado, que son el 90% del trabajo del 95% de los Data Scientists en Argentina."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WpUThBojODyK"
      },
      "source": [
        "El desafío de esta tarea es:\n",
        "* Qué hiperparparámetros conviene optimizar?  Las recomendaciones de los artículos ligeros es siempre sensata?  Sus autores realmente hicieron experimentos o son siemplemente escritores de entretenimiento carente de base científica?\n",
        "* Elegidos los hiperparámetros, cual es el  <desde, hasta> que se debe utilizar en la Bayesian Optimization ?\n",
        "* Realmente vale la pena optimizar 10 o 16 hiperparámetros al mismo tiempo ?  No resulta contraproducente una búsqueda en un espacio de tal alta dimensionalidad ?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PX0qg_c0yqob"
      },
      "source": [
        "#### 2.1  Seteo del ambiente en Google Colab"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NGY7H9xza7Zr"
      },
      "source": [
        "Esta parte se debe correr con el runtime en Python3\n",
        "<br>Ir al menu, Runtime -> Change Runtime Type -> Runtime type ->  **Python 3**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7PupIBNba7Zr"
      },
      "source": [
        "Conectar la virtual machine donde esta corriendo Google Colab con el  Google Drive, para poder tener persistencia de archivos"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9LpZCst5a7Zs",
        "vscode": {
          "languageId": "r"
        }
      },
      "outputs": [],
      "source": [
        "# primero establecer el Runtime de Python 3\n",
        "from google.colab import drive\n",
        "drive.mount('/content/.drive')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JYC_F-wla7Zs"
      },
      "source": [
        "Para correr la siguiente celda es fundamental en Arranque en Frio haber copiado el archivo kaggle.json al Google Drive, en la carpeta indicada en el instructivo\n",
        "\n",
        "<br>los siguientes comando estan en shell script de Linux\n",
        "*   Crear las carpetas en el Google Drive\n",
        "*   \"instalar\" el archivo kaggle.json desde el Google Drive a la virtual machine para que pueda ser utilizado por la libreria  kaggle de Python\n",
        "*   Bajar el  **dataset_pequeno**  al  Google Drive  y tambien al disco local de la virtual machine que esta corriendo Google Colab\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XWLelftXa7Zt",
        "vscode": {
          "languageId": "r"
        }
      },
      "outputs": [],
      "source": [
        "%%shell\n",
        "\n",
        "mkdir -p \"/content/.drive/My Drive/dmeyf\"\n",
        "mkdir -p \"/content/buckets\"\n",
        "ln -s \"/content/.drive/My Drive/dmeyf\" /content/buckets/b1\n",
        "\n",
        "\n",
        "mkdir -p /content/buckets/b1/exp\n",
        "mkdir -p /content/buckets/b1/datasets\n",
        "mkdir -p /content/datasets\n",
        "\n",
        "\n",
        "\n",
        "archivo_origen=\"https://storage.googleapis.com/open-courses/dmeyf2025-e4a2/competencia_01_crudo.csv\"\n",
        "archivo_destino=\"/content/datasets/competencia_01_crudo.csv\"\n",
        "archivo_destino_bucket=\"/content/buckets/b1/datasets/competencia_01_crudo.csv\"\n",
        "\n",
        "if ! test -f $archivo_destino_bucket; then\n",
        "  wget  $archivo_origen  -O $archivo_destino_bucket\n",
        "fi\n",
        "\n",
        "\n",
        "if ! test -f $archivo_destino; then\n",
        "  cp  $archivo_destino_bucket  $archivo_destino\n",
        "fi\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dseB4qb9RqUb"
      },
      "source": [
        "### Generacion de la clase_ternaria"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LCEnE_02RuIQ"
      },
      "source": [
        "Esta parte se debe correr con el runtime en lenguaje **R** Ir al menu, Runtime -> Change Runtime Tipe -> Runtime type -> R"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "P863YZB9R1Ua",
        "vscode": {
          "languageId": "r"
        }
      },
      "outputs": [],
      "source": [
        "require( \"data.table\" )\n",
        "\n",
        "# leo el dataset\n",
        "dataset <- fread(\"../../Competencia 01/competencia_01_crudo.csv\" )\n",
        "\n",
        "# calculo el periodo0 consecutivo\n",
        "dsimple <- dataset[, list(\n",
        "    \"pos\" = .I,\n",
        "    numero_de_cliente,\n",
        "    periodo0 = as.integer(foto_mes/100)*12 +  foto_mes%%100 ) ]\n",
        "\n",
        "\n",
        "# ordeno\n",
        "setorder( dsimple, numero_de_cliente, periodo0 )\n",
        "\n",
        "# calculo topes\n",
        "periodo_ultimo <- dsimple[, max(periodo0) ]\n",
        "periodo_anteultimo <- periodo_ultimo - 1\n",
        "\n",
        "\n",
        "# calculo los leads de orden 1 y 2\n",
        "dsimple[, c(\"periodo1\", \"periodo2\") :=\n",
        "    shift(periodo0, n=1:2, fill=NA, type=\"lead\"),  numero_de_cliente ]\n",
        "\n",
        "# assign most common class values = \"CONTINUA\"\n",
        "dsimple[ periodo0 < periodo_anteultimo, clase_ternaria := \"CONTINUA\" ]\n",
        "\n",
        "# calculo BAJA+1\n",
        "dsimple[ periodo0 < periodo_ultimo &\n",
        "    ( is.na(periodo1) | periodo0 + 1 < periodo1 ),\n",
        "    clase_ternaria := \"BAJA+1\" ]\n",
        "\n",
        "# calculo BAJA+2\n",
        "dsimple[ periodo0 < periodo_anteultimo & (periodo0+1 == periodo1 )\n",
        "    & ( is.na(periodo2) | periodo0 + 2 < periodo2 ),\n",
        "    clase_ternaria := \"BAJA+2\" ]\n",
        "\n",
        "\n",
        "# pego el resultado en el dataset original y grabo\n",
        "setorder( dsimple, pos )\n",
        "dataset[, clase_ternaria := dsimple$clase_ternaria ]\n",
        "\n",
        "fwrite( dataset,\n",
        "    file =  \"./competencia_01.csv.gz\",\n",
        "    sep = \",\"\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "S3hL7tv8W4rn",
        "vscode": {
          "languageId": "r"
        }
      },
      "outputs": [],
      "source": [
        "setorder( dataset, foto_mes, clase_ternaria, numero_de_cliente)\n",
        "dataset[, .N, list(foto_mes, clase_ternaria)]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oSKhZRToy2F7"
      },
      "source": [
        "### 2.2 Optimizacion Hiperparámetros"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2kwPpHAtSmix"
      },
      "source": [
        "Esta parte se debe correr con el runtime en lenguaje R Ir al menu, Runtime -> Change Runtime Type -> Runtime type -> R"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xp4-Bj3aYI8d"
      },
      "source": [
        "### 2.2.1 Inicio"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zy8YTZfESxeJ"
      },
      "source": [
        "limpio el ambiente de R"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "gBq__iAdQliq",
        "vscode": {
          "languageId": "r"
        }
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "'lun sept 29 12:10:50 2025'"
            ],
            "text/latex": [
              "'lun sept 29 12:10:50 2025'"
            ],
            "text/markdown": [
              "'lun sept 29 12:10:50 2025'"
            ],
            "text/plain": [
              "[1] \"lun sept 29 12:10:50 2025\""
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "format(Sys.time(), \"%a %b %d %X %Y\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "7rdVrBojS1IV",
        "vscode": {
          "languageId": "r"
        }
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<table class=\"dataframe\">\n",
              "<caption>A matrix: 2 × 6 of type dbl</caption>\n",
              "<thead>\n",
              "\t<tr><th></th><th scope=col>used</th><th scope=col>(Mb)</th><th scope=col>gc trigger</th><th scope=col>(Mb)</th><th scope=col>max used</th><th scope=col>(Mb)</th></tr>\n",
              "</thead>\n",
              "<tbody>\n",
              "\t<tr><th scope=row>Ncells</th><td> 650997</td><td>34.8</td><td>1431195</td><td>76.5</td><td>1431195</td><td>76.5</td></tr>\n",
              "\t<tr><th scope=row>Vcells</th><td>1204301</td><td> 9.2</td><td>8388608</td><td>64.0</td><td>2051465</td><td>15.7</td></tr>\n",
              "</tbody>\n",
              "</table>\n"
            ],
            "text/latex": [
              "A matrix: 2 × 6 of type dbl\n",
              "\\begin{tabular}{r|llllll}\n",
              "  & used & (Mb) & gc trigger & (Mb) & max used & (Mb)\\\\\n",
              "\\hline\n",
              "\tNcells &  650997 & 34.8 & 1431195 & 76.5 & 1431195 & 76.5\\\\\n",
              "\tVcells & 1204301 &  9.2 & 8388608 & 64.0 & 2051465 & 15.7\\\\\n",
              "\\end{tabular}\n"
            ],
            "text/markdown": [
              "\n",
              "A matrix: 2 × 6 of type dbl\n",
              "\n",
              "| <!--/--> | used | (Mb) | gc trigger | (Mb) | max used | (Mb) |\n",
              "|---|---|---|---|---|---|---|\n",
              "| Ncells |  650997 | 34.8 | 1431195 | 76.5 | 1431195 | 76.5 |\n",
              "| Vcells | 1204301 |  9.2 | 8388608 | 64.0 | 2051465 | 15.7 |\n",
              "\n"
            ],
            "text/plain": [
              "       used    (Mb) gc trigger (Mb) max used (Mb)\n",
              "Ncells  650997 34.8 1431195    76.5 1431195  76.5\n",
              "Vcells 1204301  9.2 8388608    64.0 2051465  15.7"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# limpio la memoria\n",
        "rm(list=ls(all.names=TRUE)) # remove all objects\n",
        "gc(full=TRUE, verbose=FALSE) # garbage collection"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kuPfQ7ksjwW3"
      },
      "source": [
        "### 2.2.2 Carga de Librerias"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B8BaSFlGfvma"
      },
      "source": [
        "Esta parte lleva varios minutos la primera vez en Google Colab"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 50,
      "metadata": {
        "id": "lVyxLaJ1j1J_",
        "vscode": {
          "languageId": "r"
        }
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Cargando paquete requerido: ggplot2\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# cargo las librerias que necesito\n",
        "if(!require(\"data.table\")) install.packages(\"data.table\")\n",
        "require(\"data.table\")\n",
        "\n",
        "if(!require(\"parallel\")) install.packages(\"parallel\")\n",
        "require(\"parallel\")\n",
        "\n",
        "if(!require(\"R.utils\")) install.packages(\"R.utils\")\n",
        "require(\"R.utils\")\n",
        "\n",
        "if( !require(\"primes\") ) install.packages(\"primes\")\n",
        "require(\"primes\")\n",
        "\n",
        "if( !require(\"utils\") ) install.packages(\"utils\")\n",
        "require(\"utils\")\n",
        "\n",
        "if( !require(\"rlist\") ) install.packages(\"rlist\")\n",
        "require(\"rlist\")\n",
        "\n",
        "if( !require(\"yaml\")) install.packages(\"yaml\")\n",
        "require(\"yaml\")\n",
        "\n",
        "if( !require(\"lightgbm\") ) install.packages(\"lightgbm\")\n",
        "require(\"lightgbm\")\n",
        "\n",
        "if( !require(\"DiceKriging\") ) install.packages(\"DiceKriging\")\n",
        "require(\"DiceKriging\")\n",
        "\n",
        "if( !require(\"mlrMBO\") ) install.packages(\"mlrMBO\")\n",
        "require(\"mlrMBO\")\n",
        "\n",
        "if( !require(\"ggplot2\") ) install.packages(\"ggplot2\")\n",
        "require(\"ggplot2\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Iz-6Qt6BUaA3"
      },
      "source": [
        "### 2.2.3 Definicion de Parametros"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cOdlKd7lUm2I"
      },
      "source": [
        "aqui debe cargar SU semilla primigenia\n",
        "<br>recuerde cambiar el numero de experimento en cada corrida nueva"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "ASYkebOu2mF6",
        "vscode": {
          "languageId": "r"
        }
      },
      "outputs": [],
      "source": [
        "PARAM <- list()\n",
        "PARAM$experimento <- \"4940_V2A_2\"\n",
        "PARAM$semilla_primigenia <- 200003"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "ezOhQdbA293o",
        "vscode": {
          "languageId": "r"
        }
      },
      "outputs": [],
      "source": [
        "# training y future\n",
        "PARAM$train <- c(202101,202102)\n",
        "PARAM$train_final <- c(202101,202102)\n",
        "PARAM$future <- c(202104)\n",
        "PARAM$semilla_kaggle <- 314159 #Semilla para el modelo final que va a Kaggle, primeros números de pi que sean primos.\n",
        "PARAM$cortes <- seq(0, 19000, by= 100)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "jtB0Lub42rHO",
        "vscode": {
          "languageId": "r"
        }
      },
      "outputs": [],
      "source": [
        "# un undersampling de 0.1  toma solo el 10% de los CONTINUA\n",
        "# undersampling de 1.0  implica tomar TODOS los datos\n",
        "\n",
        "PARAM$trainingstrategy$undersampling <- 0.5"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "OFxm-xiNUOJX",
        "vscode": {
          "languageId": "r"
        }
      },
      "outputs": [],
      "source": [
        "# Parametros LightGBM\n",
        "\n",
        "PARAM$hyperparametertuning$xval_folds <- 5\n",
        "\n",
        "# parametros fijos del LightGBM que se pisaran con la parte variable de la BO\n",
        "PARAM$lgbm$param_fijos <-  list(\n",
        "  boosting= \"gbdt\", # puede ir dart, ni pruebe random_forest\n",
        "  objective= \"binary\", #default regression\n",
        "  metric= \"auc\", # default \"\" \n",
        "  first_metric_only= FALSE, # default FALSE\n",
        "  boost_from_average= TRUE, # default TRUE\n",
        "  feature_pre_filter= FALSE, # default TRUE\n",
        "  force_row_wise= TRUE, # para reducir warnings\n",
        "  verbosity= -100,\n",
        "\n",
        "  seed= PARAM$semilla_primigenia,\n",
        "\n",
        "  max_depth= -1L, # -1 significa no limitar,  por ahora lo dejo fijo\n",
        "  min_gain_to_split= 0, # min_gain_to_split >= 0\n",
        "  min_sum_hessian_in_leaf= 0.001, #  min_sum_hessian_in_leaf >= 0.0\n",
        "  lambda_l1= 0.0, # lambda_l1 >= 0.0\n",
        "  lambda_l2= 0.0, # lambda_l2 >= 0.0\n",
        "  max_bin= 31L, # lo debo dejar fijo, no participa de la BO\n",
        "\n",
        "  bagging_fraction= 1.0, # 0.0 < bagging_fraction <= 1.0\n",
        "  pos_bagging_fraction= 1.0, # 0.0 < pos_bagging_fraction <= 1.0\n",
        "  neg_bagging_fraction= 1.0, # 0.0 < neg_bagging_fraction <= 1.0\n",
        "  is_unbalance= TRUE, # Default FALSE\n",
        "  scale_pos_weight= 1.0, # scale_pos_weight > 0.0\n",
        "\n",
        "  drop_rate= 0.1, # 0.0 < neg_bagging_fraction <= 1.0\n",
        "  max_drop= 50, # <=0 means no limit\n",
        "  skip_drop= 0.5, # 0.0 <= skip_drop <= 1.0\n",
        "\n",
        "  extra_trees= FALSE, # default FALSE\n",
        "\n",
        "  num_iterations= 1200, # default 100\n",
        "  learning_rate= 0.02, # default 0.1\n",
        "  feature_fraction= 0.5, # default 1\n",
        "  num_leaves= 750, # default 31\n",
        "  min_data_in_leaf= 5000 # default 20\n",
        ")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D5Yj-JV4yvOt"
      },
      "source": [
        "Aqui se definen los hiperparámetros de LightGBM que participan de la Bayesian Optimization\n",
        "- si es un numero entero debe ir makeIntegerParam\n",
        "- si es un numero real (con decimales) debe ir makeNumericParam\n",
        "\n",
        "Es muy importante leer cuales son un lower y upper permitidos y además razonables"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "jENpR26ZyuS8",
        "vscode": {
          "languageId": "r"
        }
      },
      "outputs": [],
      "source": [
        "# Aqui se cargan los bordes de los hiperparametros de la BO\n",
        "PARAM$hypeparametertuning$hs <- makeParamSet(\n",
        "  makeNumericParam(\"min_sum_hessian_in_leaf\", lower= 0.001, upper= 0.1),\n",
        "  makeNumericParam(\"learning_rate\", lower= 0.005, upper= 0.1),\n",
        "  makeNumericParam(\"feature_fraction\", lower= 0.1, upper= 1.0),\n",
        "  makeNumericParam(\"bagging_fraction\", lower= 0.0, upper= 1.0),\n",
        "  makeNumericParam(\"lambda_l1\", lower= 0.0, upper= 10.0),\n",
        "  makeNumericParam(\"lambda_l2\", lower= 0.0, upper= 10.0),\n",
        "  makeNumericParam(\"min_gain_to_split\", lower= 0.0, upper= 15.0),\n",
        "  makeIntegerParam(\"bagging_freq\", lower= 1L, upper= 10L),\n",
        "  makeIntegerParam(\"num_iterations\", lower= 50L, upper= 3000L),\n",
        "  makeIntegerParam(\"max_depth\", lower= -1L, upper= 15L),\n",
        "  makeIntegerParam(\"num_leaves\", lower= 1L, upper= 2048L),\n",
        "  makeIntegerParam(\"min_data_in_leaf\", lower= 1L, upper= 8000L)\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-_RPFUb3zMoW"
      },
      "source": [
        "A mayor cantidad de hiperparámetros, se debe aumentar las iteraciones de la Bayesian Optimization: 30 es un valor muy tacaño, pero corre rápido deberia partir de 50, alcanzando los 100 si se dispone de tiempo."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "q5Rd3pnbzSiG",
        "vscode": {
          "languageId": "r"
        }
      },
      "outputs": [],
      "source": [
        "PARAM$hyperparametertuning$iteraciones <- 100 # iteraciones bayesianas"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "or53-q3bmE5d",
        "vscode": {
          "languageId": "r"
        }
      },
      "outputs": [],
      "source": [
        "# particionar agrega una columna llamada fold a un dataset\n",
        "#   que consiste en una particion estratificada segun agrupa\n",
        "# particionar( data=dataset, division=c(70,30),\n",
        "#  agrupa=clase_ternaria, seed=semilla)   crea una particion 70, 30\n",
        "\n",
        "particionar <- function(data, division, agrupa= \"\", campo= \"fold\", start= 1, seed= NA) {\n",
        "  if (!is.na(seed)) set.seed(seed, \"L'Ecuyer-CMRG\")\n",
        "\n",
        "  bloque <- unlist(mapply(\n",
        "    function(x, y) {rep(y, x)},division, seq(from= start, length.out= length(division))))\n",
        "\n",
        "  data[, (campo) := sample(rep(bloque,ceiling(.N / length(bloque))))[1:.N],by= agrupa]\n",
        "}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "CGKOZ9aMmKxi",
        "vscode": {
          "languageId": "r"
        }
      },
      "outputs": [],
      "source": [
        "# iniciliazo el dataset de realidad, para medir ganancia\n",
        "realidad_inicializar <- function( pfuture, pparam) {\n",
        "\n",
        "  # datos para verificar la ganancia\n",
        "  drealidad <- pfuture[, list(numero_de_cliente, foto_mes, clase_ternaria)]\n",
        "\n",
        "  particionar(drealidad,\n",
        "    division= c(3, 7),\n",
        "    agrupa= \"clase_ternaria\",\n",
        "    seed= PARAM$semilla_kaggle\n",
        "  )\n",
        "\n",
        "  return( drealidad )\n",
        "}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "6aVLFlEbmM3s",
        "vscode": {
          "languageId": "r"
        }
      },
      "outputs": [],
      "source": [
        "# evaluo ganancia en los datos de la realidad\n",
        "\n",
        "realidad_evaluar <- function( prealidad, pprediccion) {\n",
        "\n",
        "  prealidad[ pprediccion,\n",
        "    on= c(\"numero_de_cliente\", \"foto_mes\"),\n",
        "    predicted:= i.Predicted\n",
        "  ]\n",
        "\n",
        "  tbl <- prealidad[, list(\"qty\"=.N), list(fold, predicted, clase_ternaria)]\n",
        "\n",
        "  res <- list()\n",
        "  res$public  <- tbl[fold==1 & predicted==1L, sum(qty*ifelse(clase_ternaria==\"BAJA+2\", 780000, -20000))]/0.3\n",
        "  res$private <- tbl[fold==2 & predicted==1L, sum(qty*ifelse(clase_ternaria==\"BAJA+2\", 780000, -20000))]/0.7\n",
        "  res$total <- tbl[predicted==1L, sum(qty*ifelse(clase_ternaria==\"BAJA+2\", 780000, -20000))]\n",
        "\n",
        "  prealidad[, predicted:=NULL]\n",
        "  return( res )\n",
        "}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4RWZXL1VZjMI"
      },
      "source": [
        "### 2.2.4  Preprocesamiento"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "FM3lxKoLZ643",
        "vscode": {
          "languageId": "r"
        }
      },
      "outputs": [],
      "source": [
        "# lectura del dataset\n",
        "dataset <- fread(\"./competencia_01.csv.gz\", stringsAsFactors= TRUE)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "OsJ-91UeZ-I_",
        "vscode": {
          "languageId": "r"
        }
      },
      "outputs": [],
      "source": [
        "dataset_train <- dataset[foto_mes %in% PARAM$train]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "vrWE7BE0aB2J",
        "vscode": {
          "languageId": "r"
        }
      },
      "outputs": [],
      "source": [
        "# paso la clase a binaria que tome valores {0,1}  enteros\n",
        "#  BAJA+1 y BAJA+2  son  1,   CONTINUA es 0\n",
        "#  a partir de ahora ya NO puedo cortar  por prob(BAJA+2) > 1/40\n",
        "\n",
        "dataset_train[,\n",
        "  clase01 := ifelse(clase_ternaria %in% c(\"BAJA+2\",\"BAJA+1\"), 1L, 0L)\n",
        "]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "jP7YlQBnaW6W",
        "vscode": {
          "languageId": "r"
        }
      },
      "outputs": [],
      "source": [
        "# defino los datos que forma parte del training\n",
        "# aqui se hace el undersampling de los CONTINUA\n",
        "# notar que para esto utilizo la SEGUNDA semilla\n",
        "\n",
        "set.seed(PARAM$semilla_primigenia, kind = \"L'Ecuyer-CMRG\")\n",
        "dataset_train[, azar := runif(nrow(dataset_train))]\n",
        "dataset_train[, training := 0L]\n",
        "\n",
        "dataset_train[\n",
        "  foto_mes %in%  PARAM$train &\n",
        "    (azar <= PARAM$trainingstrategy$undersampling | clase_ternaria %in% c(\"BAJA+1\", \"BAJA+2\")),\n",
        "  training := 1L\n",
        "]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "xElu4s5W4rX7",
        "vscode": {
          "languageId": "r"
        }
      },
      "outputs": [],
      "source": [
        "# los campos que se van a utilizar\n",
        "\n",
        "campos_buenos <- setdiff(\n",
        "  colnames(dataset_train),\n",
        "  c(\"clase_ternaria\", \"clase01\", \"azar\", \"training\")\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "PppMHcGYaaol",
        "vscode": {
          "languageId": "r"
        }
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "163737"
            ],
            "text/latex": [
              "163737"
            ],
            "text/markdown": [
              "163737"
            ],
            "text/plain": [
              "[1] 163737"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "154"
            ],
            "text/latex": [
              "154"
            ],
            "text/markdown": [
              "154"
            ],
            "text/plain": [
              "[1] 154"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# dejo los datos en el formato que necesita LightGBM\n",
        "\n",
        "dtrain <- lgb.Dataset(\n",
        "  data= data.matrix(dataset_train[training == 1L, campos_buenos, with= FALSE]),\n",
        "  label= dataset_train[training == 1L, clase01],\n",
        "  free_raw_data= FALSE\n",
        ")\n",
        "\n",
        "nrow(dtrain)\n",
        "ncol(dtrain)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ta-EkOu3cphF"
      },
      "source": [
        "2.2.5 Configuracion Bayesian Optimization"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "cjgfurjdfiXb",
        "vscode": {
          "languageId": "r"
        }
      },
      "outputs": [],
      "source": [
        "# En el argumento x llegan los parmaetros de la bayesiana\n",
        "#  devuelve la AUC en cross validation del modelo entrenado\n",
        "\n",
        "EstimarGanancia_AUC_lightgbm <- function(x) {\n",
        "\n",
        "  # x pisa (o agrega) a param_fijos\n",
        "  param_completo <- modifyList(PARAM$lgbm$param_fijos, x)\n",
        "\n",
        "  # entreno LightGBM\n",
        "  modelocv <- lgb.cv(\n",
        "    data= dtrain,\n",
        "    nfold= PARAM$hyperparametertuning$xval_folds,\n",
        "    stratified= TRUE,\n",
        "    param= param_completo\n",
        "  )\n",
        "\n",
        "  # obtengo la ganancia\n",
        "  AUC <- modelocv$best_score\n",
        "\n",
        "  # hago espacio en la memoria\n",
        "  rm(modelocv)\n",
        "  gc(full= TRUE, verbose= FALSE)\n",
        "\n",
        "  message(format(Sys.time(), \"%a %b %d %X %Y\"), \" AUC \", AUC)\n",
        "\n",
        "  return(AUC)\n",
        "}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "WLi_o1hocvN-",
        "vscode": {
          "languageId": "r"
        }
      },
      "outputs": [],
      "source": [
        "# Aqui comienza la configuracion de la Bayesian Optimization\n",
        "\n",
        "# en este archivo quedan la evolucion binaria de la BO\n",
        "kbayesiana <- \"bayesiana.RDATA\"\n",
        "\n",
        "funcion_optimizar <- EstimarGanancia_AUC_lightgbm # la funcion que voy a maximizar\n",
        "\n",
        "configureMlr(show.learner.output= FALSE)\n",
        "\n",
        "# configuro la busqueda bayesiana,  los hiperparametros que se van a optimizar\n",
        "# por favor, no desesperarse por lo complejo\n",
        "\n",
        "obj.fun <- makeSingleObjectiveFunction(\n",
        "  fn= funcion_optimizar, # la funcion que voy a maximizar\n",
        "  minimize= FALSE, # estoy Maximizando la ganancia\n",
        "  noisy= TRUE,\n",
        "  par.set= PARAM$hypeparametertuning$hs, # definido al comienzo del programa\n",
        "  has.simple.signature= FALSE # paso los parametros en una lista\n",
        ")\n",
        "\n",
        "# cada 600 segundos guardo el resultado intermedio\n",
        "ctrl <- makeMBOControl(\n",
        "  save.on.disk.at.time= 600, # se graba cada 600 segundos\n",
        "  save.file.path= kbayesiana\n",
        ") # se graba cada 600 segundos\n",
        "\n",
        "# indico la cantidad de iteraciones que va a tener la Bayesian Optimization\n",
        "ctrl <- setMBOControlTermination(\n",
        "  ctrl,\n",
        "  iters= PARAM$hyperparametertuning$iteraciones\n",
        ") # cantidad de iteraciones\n",
        "\n",
        "# defino el método estandar para la creacion de los puntos iniciales,\n",
        "# los \"No Inteligentes\"\n",
        "ctrl <- setMBOControlInfill(ctrl, crit= makeMBOInfillCritEI())\n",
        "\n",
        "# establezco la funcion que busca el maximo\n",
        "surr.km <- makeLearner(\n",
        "  \"regr.km\",\n",
        "  predict.type= \"se\",\n",
        "  covtype= \"matern3_2\",\n",
        "  control= list(trace= TRUE)\n",
        ")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_uUeVo5pc4zc"
      },
      "source": [
        "2.2.6 Corrida Bayesian Optimization"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "RcABNaKGciaz",
        "vscode": {
          "languageId": "r"
        }
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Computing y column(s) for design. Not provided.\n",
            "\n",
            "lun sept 29 12:13:07 2025 AUC 0.931407600206146\n",
            "\n",
            "lun sept 29 12:14:48 2025 AUC 0.927150680141032\n",
            "\n",
            "lun sept 29 12:16:11 2025 AUC 0.932766073398486\n",
            "\n",
            "lun sept 29 12:17:41 2025 AUC 0.93765445020784\n",
            "\n",
            "lun sept 29 12:20:06 2025 AUC 0.932382870001722\n",
            "\n",
            "lun sept 29 12:20:48 2025 AUC 0.932674997289019\n",
            "\n",
            "lun sept 29 12:22:46 2025 AUC 0.935078031782577\n",
            "\n",
            "lun sept 29 12:24:53 2025 AUC 0.931195963553283\n",
            "\n",
            "lun sept 29 12:26:14 2025 AUC 0.930088086308943\n",
            "\n",
            "lun sept 29 12:26:42 2025 AUC 0.931891345690352\n",
            "\n",
            "lun sept 29 12:27:05 2025 AUC 0.5\n",
            "\n",
            "lun sept 29 12:32:04 2025 AUC 0.938789920404872\n",
            "\n",
            "lun sept 29 12:35:30 2025 AUC 0.938678411226793\n",
            "\n",
            "lun sept 29 12:37:31 2025 AUC 0.933209703545001\n",
            "\n",
            "lun sept 29 12:38:22 2025 AUC 0.927081939321893\n",
            "\n",
            "lun sept 29 12:39:08 2025 AUC 0.915179279738477\n",
            "\n",
            "lun sept 29 12:40:45 2025 AUC 0.936285015462043\n",
            "\n",
            "lun sept 29 12:41:11 2025 AUC 0.928230448009456\n",
            "\n",
            "lun sept 29 12:42:32 2025 AUC 0.932911801994876\n",
            "\n",
            "lun sept 29 12:43:40 2025 AUC 0.91722247206603\n",
            "\n",
            "lun sept 29 12:43:45 2025 AUC 0.908851601501315\n",
            "\n",
            "lun sept 29 12:44:18 2025 AUC 0.920804770365848\n",
            "\n",
            "lun sept 29 12:44:57 2025 AUC 0.914546294754478\n",
            "\n",
            "lun sept 29 12:45:53 2025 AUC 0.922038926706296\n",
            "\n",
            "lun sept 29 12:47:19 2025 AUC 0.932751668811796\n",
            "\n",
            "lun sept 29 12:47:35 2025 AUC 0.918405238006407\n",
            "\n",
            "lun sept 29 12:50:52 2025 AUC 0.937343875866693\n",
            "\n",
            "lun sept 29 12:51:04 2025 AUC 0.5\n",
            "\n",
            "lun sept 29 12:52:57 2025 AUC 0.932408185089655\n",
            "\n",
            "lun sept 29 12:53:10 2025 AUC 0.91741192825112\n",
            "\n",
            "lun sept 29 12:53:50 2025 AUC 0.917521809977073\n",
            "\n",
            "lun sept 29 12:55:26 2025 AUC 0.93555131795846\n",
            "\n",
            "lun sept 29 12:56:58 2025 AUC 0.93046978307803\n",
            "\n",
            "lun sept 29 12:58:29 2025 AUC 0.925924230343626\n",
            "\n",
            "lun sept 29 12:59:20 2025 AUC 0.895123603151371\n",
            "\n",
            "lun sept 29 12:59:31 2025 AUC 0.5\n",
            "\n",
            "lun sept 29 13:04:08 2025 AUC 0.934879852747796\n",
            "\n",
            "lun sept 29 13:06:18 2025 AUC 0.931663220067223\n",
            "\n",
            "lun sept 29 13:06:59 2025 AUC 0.930187304216362\n",
            "\n",
            "lun sept 29 13:09:25 2025 AUC 0.925323490173526\n",
            "\n",
            "lun sept 29 13:10:11 2025 AUC 0.5\n",
            "\n",
            "lun sept 29 13:11:29 2025 AUC 0.92492622513368\n",
            "\n",
            "lun sept 29 13:11:52 2025 AUC 0.931239832967524\n",
            "\n",
            "lun sept 29 13:13:13 2025 AUC 0.934162915302311\n",
            "\n",
            "lun sept 29 13:13:29 2025 AUC 0.927509000717844\n",
            "\n",
            "lun sept 29 13:14:19 2025 AUC 0.75525993339943\n",
            "\n",
            "lun sept 29 13:15:27 2025 AUC 0.92630003221359\n",
            "\n",
            "lun sept 29 13:17:29 2025 AUC 0.933190340323132\n",
            "\n",
            "[mbo] 0: min_sum_hessian_in_leaf=0.0677; learning_rate=0.0611; feature_fraction=0.412; bagging_fraction=0.519; lambda_l1=1.75; lambda_l2=3.8; min_gain_to_split=5.02; bagging_freq=4; num_iterations=1888; max_depth=9; num_leaves=676; min_data_in_leaf=5125 : y = 0.931 : 116.0 secs : initdesign\n",
            "\n",
            "[mbo] 0: min_sum_hessian_in_leaf=0.0649; learning_rate=0.0454; feature_fraction=0.694; bagging_fraction=0.365; lambda_l1=2.75; lambda_l2=3.04; min_gain_to_split=5.37; bagging_freq=5; num_iterations=2466; max_depth=11; num_leaves=1043; min_data_in_leaf=5445 : y = 0.927 : 101.4 secs : initdesign\n",
            "\n",
            "[mbo] 0: min_sum_hessian_in_leaf=0.0352; learning_rate=0.0319; feature_fraction=0.804; bagging_fraction=0.553; lambda_l1=4.4; lambda_l2=6.01; min_gain_to_split=4.51; bagging_freq=7; num_iterations=1471; max_depth=0; num_leaves=783; min_data_in_leaf=4298 : y = 0.933 : 82.9 secs : initdesign\n",
            "\n",
            "[mbo] 0: min_sum_hessian_in_leaf=0.0325; learning_rate=0.0592; feature_fraction=0.31; bagging_fraction=0.684; lambda_l1=5.32; lambda_l2=5.62; min_gain_to_split=4.73; bagging_freq=1; num_iterations=835; max_depth=8; num_leaves=868; min_data_in_leaf=1721 : y = 0.938 : 90.1 secs : initdesign\n",
            "\n",
            "[mbo] 0: min_sum_hessian_in_leaf=0.0812; learning_rate=0.0471; feature_fraction=0.642; bagging_fraction=0.392; lambda_l1=7.56; lambda_l2=6.77; min_gain_to_split=10.1; bagging_freq=7; num_iterations=2522; max_depth=7; num_leaves=494; min_data_in_leaf=1635 : y = 0.932 : 144.8 secs : initdesign\n",
            "\n",
            "[mbo] 0: min_sum_hessian_in_leaf=0.0503; learning_rate=0.0713; feature_fraction=0.509; bagging_fraction=0.758; lambda_l1=3.51; lambda_l2=5.14; min_gain_to_split=10.7; bagging_freq=9; num_iterations=333; max_depth=0; num_leaves=1188; min_data_in_leaf=2364 : y = 0.933 : 41.9 secs : initdesign\n",
            "\n",
            "[mbo] 0: min_sum_hessian_in_leaf=0.0236; learning_rate=0.0128; feature_fraction=0.43; bagging_fraction=0.749; lambda_l1=2.98; lambda_l2=7.41; min_gain_to_split=11.7; bagging_freq=9; num_iterations=1178; max_depth=10; num_leaves=598; min_data_in_leaf=2827 : y = 0.935 : 117.5 secs : initdesign\n",
            "\n",
            "[mbo] 0: min_sum_hessian_in_leaf=0.0318; learning_rate=0.0425; feature_fraction=0.218; bagging_fraction=0.607; lambda_l1=4.04; lambda_l2=3.98; min_gain_to_split=6.74; bagging_freq=8; num_iterations=2342; max_depth=6; num_leaves=326; min_data_in_leaf=6411 : y = 0.931 : 127.6 secs : initdesign\n",
            "\n",
            "[mbo] 0: min_sum_hessian_in_leaf=0.0527; learning_rate=0.0762; feature_fraction=0.926; bagging_fraction=0.582; lambda_l1=8.8; lambda_l2=1.22; min_gain_to_split=8.36; bagging_freq=8; num_iterations=2411; max_depth=2; num_leaves=1909; min_data_in_leaf=3733 : y = 0.93 : 80.4 secs : initdesign\n",
            "\n",
            "[mbo] 0: min_sum_hessian_in_leaf=0.0478; learning_rate=0.0229; feature_fraction=0.583; bagging_fraction=0.659; lambda_l1=6.5; lambda_l2=3.33; min_gain_to_split=7.9; bagging_freq=4; num_iterations=371; max_depth=5; num_leaves=815; min_data_in_leaf=1386 : y = 0.932 : 28.8 secs : initdesign\n",
            "\n",
            "[mbo] 0: min_sum_hessian_in_leaf=0.0372; learning_rate=0.0874; feature_fraction=0.211; bagging_fraction=0.024; lambda_l1=6.19; lambda_l2=2.63; min_gain_to_split=8.55; bagging_freq=6; num_iterations=1300; max_depth=3; num_leaves=573; min_data_in_leaf=2837 : y = 0.5 : 22.6 secs : initdesign\n",
            "\n",
            "[mbo] 0: min_sum_hessian_in_leaf=0.00545; learning_rate=0.0274; feature_fraction=0.342; bagging_fraction=0.926; lambda_l1=4.69; lambda_l2=5.7; min_gain_to_split=0.921; bagging_freq=7; num_iterations=2739; max_depth=8; num_leaves=1529; min_data_in_leaf=3533 : y = 0.939 : 298.6 secs : initdesign\n",
            "\n",
            "[mbo] 0: min_sum_hessian_in_leaf=0.0728; learning_rate=0.0377; feature_fraction=0.923; bagging_fraction=0.49; lambda_l1=5.44; lambda_l2=6.61; min_gain_to_split=0.581; bagging_freq=6; num_iterations=2028; max_depth=7; num_leaves=1284; min_data_in_leaf=1012 : y = 0.939 : 206.1 secs : initdesign\n",
            "\n",
            "[mbo] 0: min_sum_hessian_in_leaf=0.0164; learning_rate=0.0701; feature_fraction=0.706; bagging_fraction=0.909; lambda_l1=9.13; lambda_l2=8.37; min_gain_to_split=9.95; bagging_freq=1; num_iterations=2999; max_depth=12; num_leaves=1369; min_data_in_leaf=3483 : y = 0.933 : 121.0 secs : initdesign\n",
            "\n",
            "[mbo] 0: min_sum_hessian_in_leaf=0.0859; learning_rate=0.049; feature_fraction=0.653; bagging_fraction=0.475; lambda_l1=6.99; lambda_l2=9.57; min_gain_to_split=2.62; bagging_freq=3; num_iterations=1249; max_depth=3; num_leaves=406; min_data_in_leaf=6578 : y = 0.927 : 50.7 secs : initdesign\n",
            "\n",
            "[mbo] 0: min_sum_hessian_in_leaf=0.0522; learning_rate=0.0406; feature_fraction=0.766; bagging_fraction=0.2; lambda_l1=4.34; lambda_l2=0.388; min_gain_to_split=12.2; bagging_freq=4; num_iterations=1695; max_depth=5; num_leaves=350; min_data_in_leaf=5607 : y = 0.915 : 46.2 secs : initdesign\n",
            "\n",
            "[mbo] 0: min_sum_hessian_in_leaf=0.04; learning_rate=0.0341; feature_fraction=0.871; bagging_fraction=0.876; lambda_l1=3.84; lambda_l2=0.647; min_gain_to_split=11; bagging_freq=4; num_iterations=1600; max_depth=15; num_leaves=995; min_data_in_leaf=2317 : y = 0.936 : 97.6 secs : initdesign\n",
            "\n",
            "[mbo] 0: min_sum_hessian_in_leaf=0.0666; learning_rate=0.0354; feature_fraction=0.623; bagging_fraction=0.522; lambda_l1=7.83; lambda_l2=1.75; min_gain_to_split=3.68; bagging_freq=10; num_iterations=609; max_depth=3; num_leaves=1721; min_data_in_leaf=4049 : y = 0.928 : 25.7 secs : initdesign\n",
            "\n",
            "[mbo] 0: min_sum_hessian_in_leaf=0.0434; learning_rate=0.0954; feature_fraction=0.176; bagging_fraction=0.822; lambda_l1=8.44; lambda_l2=1.55; min_gain_to_split=6.46; bagging_freq=9; num_iterations=1436; max_depth=4; num_leaves=909; min_data_in_leaf=1302 : y = 0.933 : 80.6 secs : initdesign\n",
            "\n",
            "[mbo] 0: min_sum_hessian_in_leaf=0.097; learning_rate=0.0652; feature_fraction=0.389; bagging_fraction=0.236; lambda_l1=1.16; lambda_l2=9.15; min_gain_to_split=9.01; bagging_freq=7; num_iterations=2116; max_depth=4; num_leaves=1547; min_data_in_leaf=7694 : y = 0.917 : 68.1 secs : initdesign\n",
            "\n",
            "[mbo] 0: min_sum_hessian_in_leaf=0.0452; learning_rate=0.0784; feature_fraction=0.452; bagging_fraction=0.296; lambda_l1=3.3; lambda_l2=1.96; min_gain_to_split=7.19; bagging_freq=1; num_iterations=83; max_depth=9; num_leaves=1358; min_data_in_leaf=6990 : y = 0.909 : 5.0 secs : initdesign\n",
            "\n",
            "[mbo] 0: min_sum_hessian_in_leaf=0.0414; learning_rate=0.0734; feature_fraction=0.742; bagging_fraction=0.15; lambda_l1=9.69; lambda_l2=0.9; min_gain_to_split=13.7; bagging_freq=7; num_iterations=882; max_depth=10; num_leaves=1097; min_data_in_leaf=1914 : y = 0.921 : 33.3 secs : initdesign\n",
            "\n",
            "[mbo] 0: min_sum_hessian_in_leaf=0.0702; learning_rate=0.0979; feature_fraction=0.898; bagging_fraction=0.253; lambda_l1=3.67; lambda_l2=5.27; min_gain_to_split=9.55; bagging_freq=5; num_iterations=1355; max_depth=13; num_leaves=36; min_data_in_leaf=5950 : y = 0.915 : 39.1 secs : initdesign\n",
            "\n",
            "[mbo] 0: min_sum_hessian_in_leaf=0.00136; learning_rate=0.0299; feature_fraction=0.173; bagging_fraction=0.143; lambda_l1=8.15; lambda_l2=4.59; min_gain_to_split=14.1; bagging_freq=5; num_iterations=1921; max_depth=2; num_leaves=1226; min_data_in_leaf=2626 : y = 0.922 : 55.9 secs : initdesign\n",
            "\n",
            "[mbo] 0: min_sum_hessian_in_leaf=0.0789; learning_rate=0.0679; feature_fraction=0.835; bagging_fraction=0.97; lambda_l1=4.86; lambda_l2=6.24; min_gain_to_split=1.34; bagging_freq=4; num_iterations=1102; max_depth=12; num_leaves=1968; min_data_in_leaf=7578 : y = 0.933 : 86.4 secs : initdesign\n",
            "\n",
            "[mbo] 0: min_sum_hessian_in_leaf=0.0146; learning_rate=0.00879; feature_fraction=0.47; bagging_fraction=0.454; lambda_l1=0.303; lambda_l2=7.66; min_gain_to_split=1.65; bagging_freq=2; num_iterations=240; max_depth=7; num_leaves=685; min_data_in_leaf=4979 : y = 0.918 : 15.2 secs : initdesign\n",
            "\n",
            "[mbo] 0: min_sum_hessian_in_leaf=0.0206; learning_rate=0.0251; feature_fraction=0.263; bagging_fraction=0.629; lambda_l1=7.42; lambda_l2=8.2; min_gain_to_split=3.26; bagging_freq=6; num_iterations=770; max_depth=9; num_leaves=1804; min_data_in_leaf=104 : y = 0.937 : 197.6 secs : initdesign\n",
            "\n",
            "[mbo] 0: min_sum_hessian_in_leaf=0.0614; learning_rate=0.0187; feature_fraction=0.108; bagging_fraction=0.0692; lambda_l1=2.03; lambda_l2=8.79; min_gain_to_split=5.8; bagging_freq=10; num_iterations=589; max_depth=15; num_leaves=1621; min_data_in_leaf=5818 : y = 0.5 : 12.1 secs : initdesign\n",
            "\n",
            "[mbo] 0: min_sum_hessian_in_leaf=0.0765; learning_rate=0.0806; feature_fraction=0.589; bagging_fraction=0.938; lambda_l1=1.54; lambda_l2=3.56; min_gain_to_split=11.5; bagging_freq=2; num_iterations=2279; max_depth=6; num_leaves=515; min_data_in_leaf=7172 : y = 0.932 : 112.1 secs : initdesign\n",
            "\n",
            "[mbo] 0: min_sum_hessian_in_leaf=0.0269; learning_rate=0.057; feature_fraction=0.281; bagging_fraction=0.429; lambda_l1=0.152; lambda_l2=4.82; min_gain_to_split=7.72; bagging_freq=10; num_iterations=453; max_depth=1; num_leaves=86; min_data_in_leaf=6776 : y = 0.917 : 13.7 secs : initdesign\n",
            "\n",
            "[mbo] 0: min_sum_hessian_in_leaf=0.0748; learning_rate=0.0893; feature_fraction=0.133; bagging_fraction=0.334; lambda_l1=9.81; lambda_l2=0.0248; min_gain_to_split=13.2; bagging_freq=5; num_iterations=1042; max_depth=4; num_leaves=1625; min_data_in_leaf=7009 : y = 0.918 : 39.3 secs : initdesign\n",
            "\n",
            "[mbo] 0: min_sum_hessian_in_leaf=0.0253; learning_rate=0.0554; feature_fraction=0.785; bagging_fraction=0.774; lambda_l1=6.41; lambda_l2=9.96; min_gain_to_split=9.16; bagging_freq=8; num_iterations=2190; max_depth=-1; num_leaves=269; min_data_in_leaf=169 : y = 0.936 : 96.0 secs : initdesign\n",
            "\n",
            "[mbo] 0: min_sum_hessian_in_leaf=0.091; learning_rate=0.0993; feature_fraction=0.859; bagging_fraction=0.329; lambda_l1=9.36; lambda_l2=6.32; min_gain_to_split=6.1; bagging_freq=3; num_iterations=1010; max_depth=10; num_leaves=2041; min_data_in_leaf=691 : y = 0.93 : 92.3 secs : initdesign\n",
            "\n",
            "[mbo] 0: min_sum_hessian_in_leaf=0.0842; learning_rate=0.0827; feature_fraction=0.242; bagging_fraction=0.21; lambda_l1=0.632; lambda_l2=4.35; min_gain_to_split=0.247; bagging_freq=6; num_iterations=1981; max_depth=6; num_leaves=973; min_data_in_leaf=2074 : y = 0.926 : 90.8 secs : initdesign\n",
            "\n",
            "[mbo] 0: min_sum_hessian_in_leaf=0.0294; learning_rate=0.0145; feature_fraction=0.987; bagging_fraction=0.172; lambda_l1=5.12; lambda_l2=9.3; min_gain_to_split=13.8; bagging_freq=9; num_iterations=2580; max_depth=1; num_leaves=1254; min_data_in_leaf=7351 : y = 0.895 : 51.6 secs : initdesign\n",
            "\n",
            "[mbo] 0: min_sum_hessian_in_leaf=0.0586; learning_rate=0.0163; feature_fraction=0.545; bagging_fraction=0.0438; lambda_l1=5.97; lambda_l2=1.42; min_gain_to_split=1.06; bagging_freq=2; num_iterations=529; max_depth=15; num_leaves=1850; min_data_in_leaf=3053 : y = 0.5 : 10.6 secs : initdesign\n",
            "\n",
            "[mbo] 0: min_sum_hessian_in_leaf=0.0949; learning_rate=0.00673; feature_fraction=0.487; bagging_fraction=0.85; lambda_l1=1.38; lambda_l2=7.96; min_gain_to_split=2.4; bagging_freq=3; num_iterations=2635; max_depth=13; num_leaves=732; min_data_in_leaf=3878 : y = 0.935 : 277.1 secs : initdesign\n",
            "\n",
            "[mbo] 0: min_sum_hessian_in_leaf=0.0603; learning_rate=0.0781; feature_fraction=0.347; bagging_fraction=0.874; lambda_l1=7.16; lambda_l2=6.88; min_gain_to_split=12.6; bagging_freq=9; num_iterations=2848; max_depth=13; num_leaves=1147; min_data_in_leaf=4411 : y = 0.932 : 129.5 secs : initdesign\n",
            "\n",
            "[mbo] 0: min_sum_hessian_in_leaf=0.00732; learning_rate=0.0441; feature_fraction=0.681; bagging_fraction=0.6; lambda_l1=9.48; lambda_l2=4.53; min_gain_to_split=12.9; bagging_freq=2; num_iterations=687; max_depth=0; num_leaves=232; min_data_in_leaf=6176 : y = 0.93 : 41.2 secs : initdesign\n",
            "\n",
            "[mbo] 0: min_sum_hessian_in_leaf=0.00967; learning_rate=0.0211; feature_fraction=0.956; bagging_fraction=0.0859; lambda_l1=0.519; lambda_l2=2.36; min_gain_to_split=11.9; bagging_freq=2; num_iterations=2879; max_depth=6; num_leaves=1412; min_data_in_leaf=666 : y = 0.925 : 145.7 secs : initdesign\n",
            "\n",
            "[mbo] 0: min_sum_hessian_in_leaf=0.0937; learning_rate=0.052; feature_fraction=0.727; bagging_fraction=0.0146; lambda_l1=8.7; lambda_l2=2.8; min_gain_to_split=4.26; bagging_freq=10; num_iterations=2786; max_depth=14; num_leaves=1485; min_data_in_leaf=4612 : y = 0.5 : 46.4 secs : initdesign\n",
            "\n",
            "[mbo] 0: min_sum_hessian_in_leaf=0.00317; learning_rate=0.0626; feature_fraction=0.556; bagging_fraction=0.413; lambda_l1=2.5; lambda_l2=7.21; min_gain_to_split=3.03; bagging_freq=5; num_iterations=1546; max_depth=-1; num_leaves=1930; min_data_in_leaf=6161 : y = 0.925 : 78.5 secs : initdesign\n",
            "\n",
            "[mbo] 0: min_sum_hessian_in_leaf=0.0559; learning_rate=0.093; feature_fraction=0.522; bagging_fraction=0.999; lambda_l1=2.67; lambda_l2=7.89; min_gain_to_split=1.99; bagging_freq=2; num_iterations=160; max_depth=12; num_leaves=172; min_data_in_leaf=3270 : y = 0.931 : 22.5 secs : initdesign\n",
            "\n",
            "[mbo] 0: min_sum_hessian_in_leaf=0.0989; learning_rate=0.0198; feature_fraction=0.82; bagging_fraction=0.288; lambda_l1=0.874; lambda_l2=9.78; min_gain_to_split=10.5; bagging_freq=6; num_iterations=962; max_depth=0; num_leaves=446; min_data_in_leaf=909 : y = 0.934 : 81.2 secs : initdesign\n",
            "\n",
            "[mbo] 0: min_sum_hessian_in_leaf=0.0826; learning_rate=0.0913; feature_fraction=0.29; bagging_fraction=0.693; lambda_l1=2.22; lambda_l2=0.438; min_gain_to_split=14.4; bagging_freq=8; num_iterations=204; max_depth=14; num_leaves=1694; min_data_in_leaf=5175 : y = 0.928 : 16.0 secs : initdesign\n",
            "\n",
            "[mbo] 0: min_sum_hessian_in_leaf=0.0175; learning_rate=0.0853; feature_fraction=0.37; bagging_fraction=0.118; lambda_l1=6.73; lambda_l2=8.64; min_gain_to_split=14.7; bagging_freq=3; num_iterations=2241; max_depth=13; num_leaves=53; min_data_in_leaf=7985 : y = 0.755 : 49.5 secs : initdesign\n",
            "\n",
            "[mbo] 0: min_sum_hessian_in_leaf=0.0883; learning_rate=0.0541; feature_fraction=0.151; bagging_fraction=0.709; lambda_l1=7.98; lambda_l2=2.19; min_gain_to_split=6.98; bagging_freq=1; num_iterations=1779; max_depth=1; num_leaves=1761; min_data_in_leaf=500 : y = 0.926 : 68.5 secs : initdesign\n",
            "\n",
            "[mbo] 0: min_sum_hessian_in_leaf=0.0127; learning_rate=0.0107; feature_fraction=0.974; bagging_fraction=0.796; lambda_l1=5.75; lambda_l2=3.33; min_gain_to_split=3.77; bagging_freq=10; num_iterations=1756; max_depth=11; num_leaves=171; min_data_in_leaf=4756 : y = 0.933 : 122.2 secs : initdesign\n",
            "\n",
            "Saved the current state after iteration 1 in the file bayesiana.RDATA.\n",
            "\n",
            "lun sept 29 13:19:06 2025 AUC 0.928340948649903\n",
            "\n",
            "[mbo] 1: min_sum_hessian_in_leaf=0.0227; learning_rate=0.0554; feature_fraction=0.952; bagging_fraction=0.186; lambda_l1=4.93; lambda_l2=2; min_gain_to_split=12.5; bagging_freq=3; num_iterations=2463; max_depth=3; num_leaves=1342; min_data_in_leaf=175 : y = 0.928 : 94.9 secs : infill_ei\n",
            "\n",
            "lun sept 29 13:20:29 2025 AUC 0.928922356945432\n",
            "\n",
            "[mbo] 2: min_sum_hessian_in_leaf=0.0297; learning_rate=0.036; feature_fraction=0.298; bagging_fraction=0.215; lambda_l1=7.81; lambda_l2=6.54; min_gain_to_split=14.5; bagging_freq=3; num_iterations=1985; max_depth=3; num_leaves=1244; min_data_in_leaf=1864 : y = 0.929 : 81.4 secs : infill_ei\n",
            "\n",
            "lun sept 29 13:21:50 2025 AUC 0.936062583109577\n",
            "\n",
            "[mbo] 3: min_sum_hessian_in_leaf=0.0459; learning_rate=0.0568; feature_fraction=0.73; bagging_fraction=0.901; lambda_l1=4.75; lambda_l2=7.51; min_gain_to_split=2.67; bagging_freq=5; num_iterations=1151; max_depth=6; num_leaves=714; min_data_in_leaf=4192 : y = 0.936 : 80.6 secs : infill_ei\n",
            "\n",
            "lun sept 29 13:22:50 2025 AUC 0.924866412737939\n",
            "\n",
            "[mbo] 4: min_sum_hessian_in_leaf=0.0744; learning_rate=0.0798; feature_fraction=0.733; bagging_fraction=0.28; lambda_l1=7.3; lambda_l2=1.84; min_gain_to_split=12.1; bagging_freq=8; num_iterations=1406; max_depth=6; num_leaves=958; min_data_in_leaf=2696 : y = 0.925 : 59.0 secs : infill_ei\n",
            "\n",
            "lun sept 29 13:25:48 2025 AUC 0.937285424205935\n",
            "\n",
            "[mbo] 5: min_sum_hessian_in_leaf=0.0606; learning_rate=0.0513; feature_fraction=0.668; bagging_fraction=0.778; lambda_l1=6.98; lambda_l2=3.02; min_gain_to_split=5.15; bagging_freq=4; num_iterations=2388; max_depth=12; num_leaves=1516; min_data_in_leaf=2714 : y = 0.937 : 176.1 secs : infill_ei\n",
            "\n",
            "lun sept 29 13:29:11 2025 AUC 0.92927526168844\n",
            "\n",
            "[mbo] 6: min_sum_hessian_in_leaf=0.0153; learning_rate=0.024; feature_fraction=0.868; bagging_fraction=0.147; lambda_l1=0.42; lambda_l2=3.73; min_gain_to_split=13.5; bagging_freq=5; num_iterations=2215; max_depth=7; num_leaves=1043; min_data_in_leaf=24 : y = 0.929 : 202.3 secs : infill_ei\n",
            "\n",
            "Saved the current state after iteration 7 in the file bayesiana.RDATA.\n",
            "\n",
            "lun sept 29 13:30:49 2025 AUC 0.93316588874537\n",
            "\n",
            "[mbo] 7: min_sum_hessian_in_leaf=0.034; learning_rate=0.0757; feature_fraction=0.702; bagging_fraction=0.674; lambda_l1=7.32; lambda_l2=5.97; min_gain_to_split=8.92; bagging_freq=8; num_iterations=1619; max_depth=11; num_leaves=1421; min_data_in_leaf=4960 : y = 0.933 : 96.6 secs : infill_ei\n",
            "\n",
            "lun sept 29 13:32:30 2025 AUC 0.935316657629707\n",
            "\n",
            "[mbo] 8: min_sum_hessian_in_leaf=0.0815; learning_rate=0.0801; feature_fraction=0.267; bagging_fraction=0.602; lambda_l1=6.9; lambda_l2=7.8; min_gain_to_split=6.25; bagging_freq=8; num_iterations=1321; max_depth=8; num_leaves=860; min_data_in_leaf=2154 : y = 0.935 : 100.4 secs : infill_ei\n",
            "\n",
            "lun sept 29 13:34:51 2025 AUC 0.935743734579439\n",
            "\n",
            "[mbo] 9: min_sum_hessian_in_leaf=0.0826; learning_rate=0.0353; feature_fraction=0.361; bagging_fraction=0.955; lambda_l1=5.44; lambda_l2=2.68; min_gain_to_split=7.84; bagging_freq=3; num_iterations=1716; max_depth=14; num_leaves=1344; min_data_in_leaf=3891 : y = 0.936 : 138.9 secs : infill_ei\n",
            "\n",
            "lun sept 29 13:37:18 2025 AUC 0.933341505350426\n",
            "\n",
            "[mbo] 10: min_sum_hessian_in_leaf=0.0196; learning_rate=0.0526; feature_fraction=0.392; bagging_fraction=0.823; lambda_l1=2.87; lambda_l2=7.18; min_gain_to_split=9.26; bagging_freq=4; num_iterations=1909; max_depth=9; num_leaves=1221; min_data_in_leaf=5033 : y = 0.933 : 146.5 secs : infill_ei\n",
            "\n",
            "lun sept 29 13:38:17 2025 AUC 0.932205411551455\n",
            "\n",
            "[mbo] 11: min_sum_hessian_in_leaf=0.0819; learning_rate=0.076; feature_fraction=0.388; bagging_fraction=0.369; lambda_l1=2.1; lambda_l2=7.83; min_gain_to_split=4.57; bagging_freq=5; num_iterations=1051; max_depth=4; num_leaves=912; min_data_in_leaf=865 : y = 0.932 : 57.5 secs : infill_ei\n",
            "\n",
            "lun sept 29 13:40:32 2025 AUC 0.926393389837989\n",
            "\n",
            "[mbo] 12: min_sum_hessian_in_leaf=0.0217; learning_rate=0.00871; feature_fraction=0.977; bagging_fraction=0.129; lambda_l1=1.95; lambda_l2=0.848; min_gain_to_split=13.8; bagging_freq=1; num_iterations=2984; max_depth=-1; num_leaves=1508; min_data_in_leaf=1983 : y = 0.926 : 133.8 secs : infill_ei\n",
            "\n",
            "Saved the current state after iteration 13 in the file bayesiana.RDATA.\n",
            "\n",
            "lun sept 29 13:42:42 2025 AUC 0.938231456385177\n",
            "\n",
            "[mbo] 13: min_sum_hessian_in_leaf=0.0553; learning_rate=0.0495; feature_fraction=0.877; bagging_fraction=0.942; lambda_l1=0.513; lambda_l2=8.55; min_gain_to_split=4.84; bagging_freq=6; num_iterations=2709; max_depth=14; num_leaves=1323; min_data_in_leaf=670 : y = 0.938 : 129.1 secs : infill_ei\n",
            "\n",
            "lun sept 29 13:44:13 2025 AUC 0.933105456017421\n",
            "\n",
            "[mbo] 14: min_sum_hessian_in_leaf=0.0398; learning_rate=0.0492; feature_fraction=0.766; bagging_fraction=0.452; lambda_l1=7.67; lambda_l2=3.96; min_gain_to_split=11.2; bagging_freq=5; num_iterations=1269; max_depth=10; num_leaves=1184; min_data_in_leaf=2386 : y = 0.933 : 89.1 secs : infill_ei\n",
            "\n",
            "lun sept 29 13:46:23 2025 AUC 0.937104068424759\n",
            "\n",
            "[mbo] 15: min_sum_hessian_in_leaf=0.0706; learning_rate=0.0804; feature_fraction=0.87; bagging_fraction=0.916; lambda_l1=2.46; lambda_l2=3.72; min_gain_to_split=2.52; bagging_freq=4; num_iterations=2322; max_depth=11; num_leaves=1375; min_data_in_leaf=3696 : y = 0.937 : 128.7 secs : infill_ei\n",
            "\n",
            "lun sept 29 13:48:07 2025 AUC 0.933548847088867\n",
            "\n",
            "[mbo] 16: min_sum_hessian_in_leaf=0.0221; learning_rate=0.048; feature_fraction=0.282; bagging_fraction=0.613; lambda_l1=3.99; lambda_l2=5.73; min_gain_to_split=8.35; bagging_freq=2; num_iterations=1403; max_depth=5; num_leaves=1650; min_data_in_leaf=3686 : y = 0.934 : 102.9 secs : infill_ei\n",
            "\n",
            "lun sept 29 13:51:42 2025 AUC 0.936670629813281\n",
            "\n",
            "[mbo] 17: min_sum_hessian_in_leaf=0.0331; learning_rate=0.0393; feature_fraction=0.584; bagging_fraction=0.85; lambda_l1=4.13; lambda_l2=4.16; min_gain_to_split=3.12; bagging_freq=7; num_iterations=2775; max_depth=8; num_leaves=260; min_data_in_leaf=343 : y = 0.937 : 213.9 secs : infill_ei\n",
            "\n",
            "Saved the current state after iteration 18 in the file bayesiana.RDATA.\n",
            "\n",
            "lun sept 29 13:54:29 2025 AUC 0.936073087381552\n",
            "\n",
            "[mbo] 18: min_sum_hessian_in_leaf=0.0761; learning_rate=0.0678; feature_fraction=0.394; bagging_fraction=0.768; lambda_l1=5.45; lambda_l2=3.57; min_gain_to_split=6.53; bagging_freq=4; num_iterations=2251; max_depth=11; num_leaves=372; min_data_in_leaf=2847 : y = 0.936 : 166.0 secs : infill_ei\n",
            "\n",
            "lun sept 29 13:54:45 2025 AUC 0.920865802764056\n",
            "\n",
            "[mbo] 19: min_sum_hessian_in_leaf=0.00152; learning_rate=0.0422; feature_fraction=0.725; bagging_fraction=0.187; lambda_l1=9.84; lambda_l2=0.763; min_gain_to_split=12.4; bagging_freq=8; num_iterations=717; max_depth=1; num_leaves=1012; min_data_in_leaf=1338 : y = 0.921 : 14.4 secs : infill_ei\n",
            "\n",
            "lun sept 29 13:56:15 2025 AUC 0.93453757598031\n",
            "\n",
            "[mbo] 20: min_sum_hessian_in_leaf=0.0212; learning_rate=0.0764; feature_fraction=0.674; bagging_fraction=0.967; lambda_l1=5.61; lambda_l2=7.19; min_gain_to_split=3.31; bagging_freq=6; num_iterations=2099; max_depth=13; num_leaves=655; min_data_in_leaf=3665 : y = 0.935 : 88.6 secs : infill_ei\n",
            "\n",
            "lun sept 29 13:58:42 2025 AUC 0.936381188363618\n",
            "\n",
            "[mbo] 21: min_sum_hessian_in_leaf=0.0829; learning_rate=0.0118; feature_fraction=0.827; bagging_fraction=0.835; lambda_l1=7.34; lambda_l2=6.71; min_gain_to_split=9.41; bagging_freq=8; num_iterations=2034; max_depth=5; num_leaves=1483; min_data_in_leaf=1417 : y = 0.936 : 146.2 secs : infill_ei\n",
            "\n",
            "lun sept 29 13:59:41 2025 AUC 0.934692998938543\n",
            "\n",
            "[mbo] 22: min_sum_hessian_in_leaf=0.0237; learning_rate=0.082; feature_fraction=0.372; bagging_fraction=0.943; lambda_l1=0.842; lambda_l2=7.45; min_gain_to_split=8.85; bagging_freq=3; num_iterations=650; max_depth=9; num_leaves=1793; min_data_in_leaf=2234 : y = 0.935 : 56.9 secs : infill_ei\n",
            "\n",
            "lun sept 29 14:02:58 2025 AUC 0.937399446718828\n",
            "\n",
            "[mbo] 23: min_sum_hessian_in_leaf=0.0155; learning_rate=0.0294; feature_fraction=0.391; bagging_fraction=0.799; lambda_l1=8.5; lambda_l2=7.55; min_gain_to_split=5.19; bagging_freq=7; num_iterations=1258; max_depth=15; num_leaves=880; min_data_in_leaf=121 : y = 0.937 : 195.5 secs : infill_ei\n",
            "\n",
            "Saved the current state after iteration 24 in the file bayesiana.RDATA.\n",
            "\n",
            "lun sept 29 14:05:08 2025 AUC 0.928697105946302\n",
            "\n",
            "[mbo] 24: min_sum_hessian_in_leaf=0.0738; learning_rate=0.0522; feature_fraction=0.543; bagging_fraction=0.304; lambda_l1=1.64; lambda_l2=9.38; min_gain_to_split=0.0716; bagging_freq=5; num_iterations=2404; max_depth=0; num_leaves=661; min_data_in_leaf=2982 : y = 0.929 : 128.5 secs : infill_ei\n",
            "\n",
            "lun sept 29 14:09:25 2025 AUC 0.938036954129375\n",
            "\n",
            "[mbo] 25: min_sum_hessian_in_leaf=0.0105; learning_rate=0.0493; feature_fraction=0.414; bagging_fraction=0.576; lambda_l1=9.54; lambda_l2=3.1; min_gain_to_split=1.51; bagging_freq=5; num_iterations=1937; max_depth=10; num_leaves=1205; min_data_in_leaf=1180 : y = 0.938 : 255.4 secs : infill_ei\n",
            "\n",
            "lun sept 29 14:11:06 2025 AUC 0.929894091649272\n",
            "\n",
            "[mbo] 26: min_sum_hessian_in_leaf=0.0189; learning_rate=0.0271; feature_fraction=0.34; bagging_fraction=0.717; lambda_l1=6.85; lambda_l2=4.1; min_gain_to_split=1.17; bagging_freq=9; num_iterations=2235; max_depth=2; num_leaves=1120; min_data_in_leaf=2293 : y = 0.93 : 100.2 secs : infill_ei\n",
            "\n",
            "lun sept 29 14:13:06 2025 AUC 0.936476244209335\n",
            "\n",
            "[mbo] 27: min_sum_hessian_in_leaf=0.073; learning_rate=0.0411; feature_fraction=0.597; bagging_fraction=0.797; lambda_l1=1.76; lambda_l2=4.95; min_gain_to_split=9.13; bagging_freq=9; num_iterations=1698; max_depth=10; num_leaves=828; min_data_in_leaf=192 : y = 0.936 : 118.3 secs : infill_ei\n",
            "\n",
            "Saved the current state after iteration 28 in the file bayesiana.RDATA.\n",
            "\n",
            "lun sept 29 14:15:29 2025 AUC 0.937298975543012\n",
            "\n",
            "[mbo] 28: min_sum_hessian_in_leaf=0.0651; learning_rate=0.05; feature_fraction=0.331; bagging_fraction=0.9; lambda_l1=3.12; lambda_l2=9.68; min_gain_to_split=7.34; bagging_freq=5; num_iterations=2281; max_depth=9; num_leaves=927; min_data_in_leaf=1965 : y = 0.937 : 141.2 secs : infill_ei\n",
            "\n",
            "lun sept 29 14:17:08 2025 AUC 0.936127396217038\n",
            "\n",
            "[mbo] 29: min_sum_hessian_in_leaf=0.0651; learning_rate=0.0358; feature_fraction=0.549; bagging_fraction=0.742; lambda_l1=8.66; lambda_l2=2.94; min_gain_to_split=5.95; bagging_freq=6; num_iterations=913; max_depth=9; num_leaves=1440; min_data_in_leaf=3093 : y = 0.936 : 97.5 secs : infill_ei\n",
            "\n",
            "lun sept 29 14:19:01 2025 AUC 0.931527892918431\n",
            "\n",
            "[mbo] 30: min_sum_hessian_in_leaf=0.0276; learning_rate=0.0348; feature_fraction=0.141; bagging_fraction=0.497; lambda_l1=9.53; lambda_l2=6.89; min_gain_to_split=7.55; bagging_freq=8; num_iterations=2153; max_depth=4; num_leaves=1167; min_data_in_leaf=3070 : y = 0.932 : 111.5 secs : infill_ei\n",
            "\n",
            "lun sept 29 14:20:02 2025 AUC 0.92512140502886\n",
            "\n",
            "[mbo] 31: min_sum_hessian_in_leaf=0.0475; learning_rate=0.0395; feature_fraction=0.707; bagging_fraction=0.974; lambda_l1=3.57; lambda_l2=6.26; min_gain_to_split=2.71; bagging_freq=1; num_iterations=2132; max_depth=1; num_leaves=1507; min_data_in_leaf=2136 : y = 0.925 : 60.1 secs : infill_ei\n",
            "\n",
            "lun sept 29 14:22:48 2025 AUC 0.934820106458758\n",
            "\n",
            "[mbo] 32: min_sum_hessian_in_leaf=0.0481; learning_rate=0.018; feature_fraction=0.605; bagging_fraction=0.934; lambda_l1=1.09; lambda_l2=9.03; min_gain_to_split=3.98; bagging_freq=5; num_iterations=1798; max_depth=15; num_leaves=1244; min_data_in_leaf=5945 : y = 0.935 : 164.5 secs : infill_ei\n",
            "\n",
            "lun sept 29 14:23:38 2025 AUC 0.926901961547274\n",
            "\n",
            "[mbo] 33: min_sum_hessian_in_leaf=0.0977; learning_rate=0.0541; feature_fraction=0.899; bagging_fraction=0.341; lambda_l1=1.61; lambda_l2=9.44; min_gain_to_split=12.9; bagging_freq=5; num_iterations=1312; max_depth=3; num_leaves=1341; min_data_in_leaf=4181 : y = 0.927 : 48.1 secs : infill_ei\n",
            "\n",
            "Saved the current state after iteration 34 in the file bayesiana.RDATA.\n",
            "\n",
            "lun sept 29 14:24:52 2025 AUC 0.933025837900465\n",
            "\n",
            "[mbo] 34: min_sum_hessian_in_leaf=0.0111; learning_rate=0.0701; feature_fraction=0.347; bagging_fraction=0.621; lambda_l1=5.93; lambda_l2=0.49; min_gain_to_split=11.8; bagging_freq=8; num_iterations=847; max_depth=11; num_leaves=840; min_data_in_leaf=1636 : y = 0.933 : 72.4 secs : infill_ei\n",
            "\n",
            "lun sept 29 14:27:24 2025 AUC 0.927590152812906\n",
            "\n",
            "[mbo] 35: min_sum_hessian_in_leaf=0.00211; learning_rate=0.058; feature_fraction=0.379; bagging_fraction=0.162; lambda_l1=9.53; lambda_l2=1.99; min_gain_to_split=12.3; bagging_freq=4; num_iterations=2980; max_depth=5; num_leaves=1258; min_data_in_leaf=1259 : y = 0.928 : 150.8 secs : infill_ei\n",
            "\n",
            "lun sept 29 14:28:37 2025 AUC 0.933787723682163\n",
            "\n",
            "[mbo] 36: min_sum_hessian_in_leaf=0.0365; learning_rate=0.0407; feature_fraction=0.731; bagging_fraction=0.783; lambda_l1=6.2; lambda_l2=5.52; min_gain_to_split=5.41; bagging_freq=4; num_iterations=1552; max_depth=3; num_leaves=696; min_data_in_leaf=1924 : y = 0.934 : 71.3 secs : infill_ei\n",
            "\n",
            "lun sept 29 14:31:06 2025 AUC 0.931107664568511\n",
            "\n",
            "[mbo] 37: min_sum_hessian_in_leaf=0.0943; learning_rate=0.0694; feature_fraction=0.561; bagging_fraction=0.423; lambda_l1=8.96; lambda_l2=8.91; min_gain_to_split=3.21; bagging_freq=6; num_iterations=1978; max_depth=8; num_leaves=1713; min_data_in_leaf=2669 : y = 0.931 : 147.9 secs : infill_ei\n",
            "\n",
            "lun sept 29 14:32:32 2025 AUC 0.919976190145074\n",
            "\n",
            "[mbo] 38: min_sum_hessian_in_leaf=0.0628; learning_rate=0.0184; feature_fraction=0.954; bagging_fraction=0.278; lambda_l1=2.35; lambda_l2=7.46; min_gain_to_split=11.3; bagging_freq=6; num_iterations=2921; max_depth=-1; num_leaves=878; min_data_in_leaf=6616 : y = 0.92 : 84.1 secs : infill_ei\n",
            "\n",
            "lun sept 29 14:35:40 2025 AUC 0.937117207984136\n",
            "\n",
            "[mbo] 39: min_sum_hessian_in_leaf=0.0451; learning_rate=0.0259; feature_fraction=0.79; bagging_fraction=0.593; lambda_l1=8.54; lambda_l2=8.17; min_gain_to_split=12; bagging_freq=4; num_iterations=2647; max_depth=12; num_leaves=614; min_data_in_leaf=1476 : y = 0.937 : 185.4 secs : infill_ei\n",
            "\n",
            "Saved the current state after iteration 40 in the file bayesiana.RDATA.\n",
            "\n",
            "lun sept 29 14:39:37 2025 AUC 0.94003307707225\n",
            "\n",
            "[mbo] 40: min_sum_hessian_in_leaf=0.0425; learning_rate=0.0323; feature_fraction=0.48; bagging_fraction=0.869; lambda_l1=5.22; lambda_l2=5.36; min_gain_to_split=3.51; bagging_freq=7; num_iterations=1829; max_depth=14; num_leaves=1812; min_data_in_leaf=891 : y = 0.94 : 235.5 secs : infill_ei\n",
            "\n",
            "lun sept 29 14:41:12 2025 AUC 0.936526984567012\n",
            "\n",
            "[mbo] 41: min_sum_hessian_in_leaf=0.0292; learning_rate=0.0695; feature_fraction=0.637; bagging_fraction=0.699; lambda_l1=5.17; lambda_l2=6.5; min_gain_to_split=9.97; bagging_freq=7; num_iterations=2075; max_depth=13; num_leaves=1560; min_data_in_leaf=700 : y = 0.937 : 93.9 secs : infill_ei\n",
            "\n",
            "lun sept 29 14:42:16 2025 AUC 0.932835679932768\n",
            "\n",
            "[mbo] 42: min_sum_hessian_in_leaf=0.0697; learning_rate=0.067; feature_fraction=0.576; bagging_fraction=0.536; lambda_l1=8.32; lambda_l2=7.08; min_gain_to_split=10.7; bagging_freq=3; num_iterations=1138; max_depth=3; num_leaves=1438; min_data_in_leaf=200 : y = 0.933 : 62.3 secs : infill_ei\n",
            "\n",
            "lun sept 29 14:43:24 2025 AUC 0.93634645997236\n",
            "\n",
            "[mbo] 43: min_sum_hessian_in_leaf=0.0443; learning_rate=0.0426; feature_fraction=0.791; bagging_fraction=0.942; lambda_l1=6.41; lambda_l2=4.33; min_gain_to_split=5.3; bagging_freq=9; num_iterations=471; max_depth=12; num_leaves=1214; min_data_in_leaf=1954 : y = 0.936 : 66.2 secs : infill_ei\n",
            "\n",
            "lun sept 29 14:45:01 2025 AUC 0.932163329686227\n",
            "\n",
            "[mbo] 44: min_sum_hessian_in_leaf=0.0185; learning_rate=0.0717; feature_fraction=0.34; bagging_fraction=0.635; lambda_l1=9.55; lambda_l2=7.45; min_gain_to_split=10.4; bagging_freq=5; num_iterations=2220; max_depth=2; num_leaves=320; min_data_in_leaf=130 : y = 0.932 : 94.3 secs : infill_ei\n",
            "\n",
            "lun sept 29 14:47:45 2025 AUC 0.93857594310163\n",
            "\n",
            "[mbo] 45: min_sum_hessian_in_leaf=0.0266; learning_rate=0.0499; feature_fraction=0.613; bagging_fraction=0.837; lambda_l1=6.48; lambda_l2=7.64; min_gain_to_split=4.03; bagging_freq=9; num_iterations=1754; max_depth=14; num_leaves=1202; min_data_in_leaf=2632 : y = 0.939 : 162.5 secs : infill_ei\n",
            "\n",
            "Saved the current state after iteration 46 in the file bayesiana.RDATA.\n",
            "\n",
            "lun sept 29 14:50:21 2025 AUC 0.935080311254789\n",
            "\n",
            "[mbo] 46: min_sum_hessian_in_leaf=0.0566; learning_rate=0.0425; feature_fraction=0.508; bagging_fraction=0.596; lambda_l1=3.95; lambda_l2=7.15; min_gain_to_split=7.92; bagging_freq=7; num_iterations=2739; max_depth=3; num_leaves=1510; min_data_in_leaf=1024 : y = 0.935 : 154.6 secs : infill_ei\n",
            "\n",
            "lun sept 29 14:51:29 2025 AUC 0.934940811843945\n",
            "\n",
            "[mbo] 47: min_sum_hessian_in_leaf=0.0231; learning_rate=0.0942; feature_fraction=0.563; bagging_fraction=0.721; lambda_l1=8.12; lambda_l2=5.72; min_gain_to_split=5.68; bagging_freq=9; num_iterations=667; max_depth=11; num_leaves=152; min_data_in_leaf=512 : y = 0.935 : 66.4 secs : infill_ei\n",
            "\n",
            "lun sept 29 14:52:32 2025 AUC 0.937774678639331\n",
            "\n",
            "[mbo] 48: min_sum_hessian_in_leaf=0.0861; learning_rate=0.0782; feature_fraction=0.694; bagging_fraction=0.94; lambda_l1=3.94; lambda_l2=6.35; min_gain_to_split=3.88; bagging_freq=1; num_iterations=712; max_depth=15; num_leaves=716; min_data_in_leaf=1047 : y = 0.938 : 60.9 secs : infill_ei\n",
            "\n",
            "lun sept 29 14:53:48 2025 AUC 0.934249194415627\n",
            "\n",
            "[mbo] 49: min_sum_hessian_in_leaf=0.00676; learning_rate=0.0696; feature_fraction=0.692; bagging_fraction=0.77; lambda_l1=9.5; lambda_l2=2.33; min_gain_to_split=14.2; bagging_freq=10; num_iterations=2234; max_depth=10; num_leaves=1329; min_data_in_leaf=421 : y = 0.934 : 73.5 secs : infill_ei\n",
            "\n",
            "lun sept 29 14:55:36 2025 AUC 0.931397302074877\n",
            "\n",
            "[mbo] 50: min_sum_hessian_in_leaf=0.0599; learning_rate=0.0177; feature_fraction=0.416; bagging_fraction=0.573; lambda_l1=9.16; lambda_l2=5.31; min_gain_to_split=12.6; bagging_freq=6; num_iterations=1549; max_depth=12; num_leaves=1584; min_data_in_leaf=4893 : y = 0.931 : 107.0 secs : infill_ei\n",
            "\n",
            "lun sept 29 14:58:05 2025 AUC 0.935692690536986\n",
            "\n",
            "[mbo] 51: min_sum_hessian_in_leaf=0.0417; learning_rate=0.0211; feature_fraction=0.754; bagging_fraction=0.818; lambda_l1=8.3; lambda_l2=6.17; min_gain_to_split=12.4; bagging_freq=7; num_iterations=2565; max_depth=13; num_leaves=483; min_data_in_leaf=2307 : y = 0.936 : 146.6 secs : infill_ei\n",
            "\n",
            "Saved the current state after iteration 52 in the file bayesiana.RDATA.\n",
            "\n",
            "lun sept 29 14:59:31 2025 AUC 0.936648922043723\n",
            "\n",
            "[mbo] 52: min_sum_hessian_in_leaf=0.0272; learning_rate=0.0728; feature_fraction=0.993; bagging_fraction=0.584; lambda_l1=5.64; lambda_l2=8.61; min_gain_to_split=3.57; bagging_freq=5; num_iterations=642; max_depth=13; num_leaves=1365; min_data_in_leaf=1378 : y = 0.937 : 84.1 secs : infill_ei\n",
            "\n",
            "lun sept 29 15:00:46 2025 AUC 0.935871358811372\n",
            "\n",
            "[mbo] 53: min_sum_hessian_in_leaf=0.0438; learning_rate=0.0415; feature_fraction=0.629; bagging_fraction=0.532; lambda_l1=7.98; lambda_l2=7.4; min_gain_to_split=6.79; bagging_freq=7; num_iterations=735; max_depth=11; num_leaves=168; min_data_in_leaf=1457 : y = 0.936 : 73.1 secs : infill_ei\n",
            "\n",
            "lun sept 29 15:04:16 2025 AUC 0.932296432934497\n",
            "\n",
            "[mbo] 54: min_sum_hessian_in_leaf=0.0488; learning_rate=0.0101; feature_fraction=0.587; bagging_fraction=0.863; lambda_l1=8.54; lambda_l2=0.303; min_gain_to_split=6.29; bagging_freq=7; num_iterations=2671; max_depth=9; num_leaves=1453; min_data_in_leaf=7639 : y = 0.932 : 207.9 secs : infill_ei\n",
            "\n",
            "lun sept 29 15:04:46 2025 AUC 0.924922555829638\n",
            "\n",
            "[mbo] 55: min_sum_hessian_in_leaf=0.0675; learning_rate=0.0143; feature_fraction=0.18; bagging_fraction=0.845; lambda_l1=4.99; lambda_l2=1.56; min_gain_to_split=7.56; bagging_freq=8; num_iterations=334; max_depth=12; num_leaves=945; min_data_in_leaf=4417 : y = 0.925 : 28.1 secs : infill_ei\n",
            "\n",
            "lun sept 29 15:05:57 2025 AUC 0.925439710735729\n",
            "\n",
            "[mbo] 56: min_sum_hessian_in_leaf=0.0268; learning_rate=0.0365; feature_fraction=0.905; bagging_fraction=0.176; lambda_l1=7.08; lambda_l2=6.84; min_gain_to_split=14.7; bagging_freq=6; num_iterations=2343; max_depth=3; num_leaves=493; min_data_in_leaf=2197 : y = 0.925 : 69.1 secs : infill_ei\n",
            "\n",
            "lun sept 29 15:06:44 2025 AUC 0.922622988613574\n",
            "\n",
            "[mbo] 57: min_sum_hessian_in_leaf=0.0793; learning_rate=0.0849; feature_fraction=0.962; bagging_fraction=0.201; lambda_l1=9.41; lambda_l2=1.36; min_gain_to_split=14.8; bagging_freq=5; num_iterations=988; max_depth=8; num_leaves=1035; min_data_in_leaf=2030 : y = 0.923 : 44.5 secs : infill_ei\n",
            "\n",
            "lun sept 29 15:09:36 2025 AUC 0.93413761300422\n",
            "\n",
            "[mbo] 58: min_sum_hessian_in_leaf=0.00858; learning_rate=0.0714; feature_fraction=0.736; bagging_fraction=0.523; lambda_l1=6.97; lambda_l2=8.26; min_gain_to_split=4.28; bagging_freq=6; num_iterations=2229; max_depth=12; num_leaves=1928; min_data_in_leaf=1972 : y = 0.934 : 170.4 secs : infill_ei\n",
            "\n",
            "Saved the current state after iteration 59 in the file bayesiana.RDATA.\n",
            "\n",
            "lun sept 29 15:10:48 2025 AUC 0.932147751158981\n",
            "\n",
            "[mbo] 59: min_sum_hessian_in_leaf=0.0513; learning_rate=0.0635; feature_fraction=0.133; bagging_fraction=0.711; lambda_l1=7.89; lambda_l2=7.88; min_gain_to_split=14.3; bagging_freq=7; num_iterations=857; max_depth=9; num_leaves=1042; min_data_in_leaf=829 : y = 0.932 : 69.6 secs : infill_ei\n",
            "\n",
            "lun sept 29 15:13:01 2025 AUC 0.935693637688306\n",
            "\n",
            "[mbo] 60: min_sum_hessian_in_leaf=0.0795; learning_rate=0.0511; feature_fraction=0.682; bagging_fraction=0.627; lambda_l1=7.86; lambda_l2=5.35; min_gain_to_split=1.14; bagging_freq=3; num_iterations=1655; max_depth=14; num_leaves=410; min_data_in_leaf=3180 : y = 0.936 : 130.7 secs : infill_ei\n",
            "\n",
            "lun sept 29 15:15:50 2025 AUC 0.936410689236944\n",
            "\n",
            "[mbo] 61: min_sum_hessian_in_leaf=0.0906; learning_rate=0.028; feature_fraction=0.219; bagging_fraction=0.299; lambda_l1=1.26; lambda_l2=7.15; min_gain_to_split=7.87; bagging_freq=6; num_iterations=1965; max_depth=6; num_leaves=1637; min_data_in_leaf=593 : y = 0.936 : 167.0 secs : infill_ei\n",
            "\n",
            "lun sept 29 15:17:28 2025 AUC 0.934521507406005\n",
            "\n",
            "[mbo] 62: min_sum_hessian_in_leaf=0.033; learning_rate=0.0438; feature_fraction=0.772; bagging_fraction=0.928; lambda_l1=6.43; lambda_l2=4.51; min_gain_to_split=12; bagging_freq=7; num_iterations=2645; max_depth=8; num_leaves=1924; min_data_in_leaf=3246 : y = 0.935 : 96.2 secs : infill_ei\n",
            "\n",
            "lun sept 29 15:19:44 2025 AUC 0.936577460047482\n",
            "\n",
            "[mbo] 63: min_sum_hessian_in_leaf=0.0113; learning_rate=0.0325; feature_fraction=0.68; bagging_fraction=0.608; lambda_l1=3.61; lambda_l2=9.43; min_gain_to_split=7.24; bagging_freq=6; num_iterations=1398; max_depth=10; num_leaves=318; min_data_in_leaf=1339 : y = 0.937 : 133.3 secs : infill_ei\n",
            "\n",
            "Saved the current state after iteration 64 in the file bayesiana.RDATA.\n",
            "\n",
            "lun sept 29 15:21:37 2025 AUC 0.928282202191655\n",
            "\n",
            "[mbo] 64: min_sum_hessian_in_leaf=0.0872; learning_rate=0.0766; feature_fraction=0.887; bagging_fraction=0.262; lambda_l1=0.0335; lambda_l2=6.79; min_gain_to_split=3.63; bagging_freq=5; num_iterations=2299; max_depth=4; num_leaves=1717; min_data_in_leaf=1193 : y = 0.928 : 110.4 secs : infill_ei\n",
            "\n",
            "lun sept 29 15:29:35 2025 AUC 0.940864054652693\n",
            "\n",
            "[mbo] 65: min_sum_hessian_in_leaf=0.0366; learning_rate=0.00916; feature_fraction=0.641; bagging_fraction=0.913; lambda_l1=8.15; lambda_l2=3.82; min_gain_to_split=2.88; bagging_freq=4; num_iterations=2607; max_depth=13; num_leaves=1077; min_data_in_leaf=1302 : y = 0.941 : 475.3 secs : infill_ei\n",
            "\n",
            "lun sept 29 15:30:27 2025 AUC 0.923581597519177\n",
            "\n",
            "[mbo] 66: min_sum_hessian_in_leaf=0.0813; learning_rate=0.0771; feature_fraction=0.165; bagging_fraction=0.258; lambda_l1=0.0778; lambda_l2=4.19; min_gain_to_split=6.69; bagging_freq=6; num_iterations=1971; max_depth=1; num_leaves=539; min_data_in_leaf=923 : y = 0.924 : 50.4 secs : infill_ei\n",
            "\n",
            "Saved the current state after iteration 67 in the file bayesiana.RDATA.\n",
            "\n",
            "lun sept 29 15:32:32 2025 AUC 0.937408726907854\n",
            "\n",
            "[mbo] 67: min_sum_hessian_in_leaf=0.0686; learning_rate=0.0333; feature_fraction=0.605; bagging_fraction=0.934; lambda_l1=1.6; lambda_l2=4.78; min_gain_to_split=6.9; bagging_freq=5; num_iterations=1461; max_depth=12; num_leaves=132; min_data_in_leaf=2446 : y = 0.937 : 122.9 secs : infill_ei\n",
            "\n",
            "lun sept 29 15:33:47 2025 AUC 0.931769658690046\n",
            "\n",
            "[mbo] 68: min_sum_hessian_in_leaf=0.0424; learning_rate=0.0164; feature_fraction=0.714; bagging_fraction=0.342; lambda_l1=8.18; lambda_l2=7.41; min_gain_to_split=3.93; bagging_freq=5; num_iterations=1225; max_depth=8; num_leaves=682; min_data_in_leaf=2094 : y = 0.932 : 71.9 secs : infill_ei\n",
            "\n",
            "lun sept 29 15:35:41 2025 AUC 0.934446274760342\n",
            "\n",
            "[mbo] 69: min_sum_hessian_in_leaf=0.0103; learning_rate=0.0845; feature_fraction=0.209; bagging_fraction=0.753; lambda_l1=3.38; lambda_l2=1.4; min_gain_to_split=4.1; bagging_freq=7; num_iterations=936; max_depth=12; num_leaves=1516; min_data_in_leaf=582 : y = 0.934 : 112.4 secs : infill_ei\n",
            "\n",
            "lun sept 29 15:40:57 2025 AUC 0.936732873637115\n",
            "\n",
            "[mbo] 70: min_sum_hessian_in_leaf=0.0198; learning_rate=0.00874; feature_fraction=0.815; bagging_fraction=0.88; lambda_l1=3.97; lambda_l2=7.01; min_gain_to_split=7.59; bagging_freq=7; num_iterations=2791; max_depth=11; num_leaves=1090; min_data_in_leaf=2639 : y = 0.937 : 313.8 secs : infill_ei\n",
            "\n",
            "Saved the current state after iteration 71 in the file bayesiana.RDATA.\n",
            "\n",
            "lun sept 29 15:44:01 2025 AUC 0.937228244744746\n",
            "\n",
            "[mbo] 71: min_sum_hessian_in_leaf=0.075; learning_rate=0.0797; feature_fraction=0.547; bagging_fraction=0.626; lambda_l1=5.89; lambda_l2=1.21; min_gain_to_split=3.46; bagging_freq=5; num_iterations=1654; max_depth=13; num_leaves=1820; min_data_in_leaf=1108 : y = 0.937 : 181.5 secs : infill_ei\n",
            "\n",
            "lun sept 29 15:45:55 2025 AUC 0.932955476094338\n",
            "\n",
            "[mbo] 72: min_sum_hessian_in_leaf=0.0752; learning_rate=0.0583; feature_fraction=0.644; bagging_fraction=0.757; lambda_l1=5.08; lambda_l2=4.99; min_gain_to_split=5.54; bagging_freq=8; num_iterations=1899; max_depth=10; num_leaves=682; min_data_in_leaf=6621 : y = 0.933 : 111.0 secs : infill_ei\n",
            "\n",
            "lun sept 29 15:47:02 2025 AUC 0.933392149288802\n",
            "\n",
            "[mbo] 73: min_sum_hessian_in_leaf=0.0296; learning_rate=0.075; feature_fraction=0.406; bagging_fraction=0.929; lambda_l1=5.69; lambda_l2=3.36; min_gain_to_split=4.73; bagging_freq=1; num_iterations=813; max_depth=13; num_leaves=980; min_data_in_leaf=6828 : y = 0.933 : 64.6 secs : infill_ei\n",
            "\n",
            "lun sept 29 15:49:23 2025 AUC 0.938585593701437\n",
            "\n",
            "[mbo] 74: min_sum_hessian_in_leaf=0.0529; learning_rate=0.0504; feature_fraction=0.91; bagging_fraction=0.623; lambda_l1=7.25; lambda_l2=4.55; min_gain_to_split=4.53; bagging_freq=8; num_iterations=2114; max_depth=9; num_leaves=941; min_data_in_leaf=263 : y = 0.939 : 138.8 secs : infill_ei\n",
            "\n",
            "lun sept 29 15:52:03 2025 AUC 0.937665038540161\n",
            "\n",
            "[mbo] 75: min_sum_hessian_in_leaf=0.0911; learning_rate=0.0738; feature_fraction=0.563; bagging_fraction=0.859; lambda_l1=9.78; lambda_l2=4.06; min_gain_to_split=6.49; bagging_freq=2; num_iterations=2664; max_depth=11; num_leaves=1083; min_data_in_leaf=946 : y = 0.938 : 157.6 secs : infill_ei\n",
            "\n",
            "Saved the current state after iteration 76 in the file bayesiana.RDATA.\n",
            "\n",
            "lun sept 29 15:55:20 2025 AUC 0.9386579009761\n",
            "\n",
            "[mbo] 76: min_sum_hessian_in_leaf=0.0714; learning_rate=0.0717; feature_fraction=0.894; bagging_fraction=0.744; lambda_l1=1.51; lambda_l2=9.79; min_gain_to_split=0.948; bagging_freq=5; num_iterations=1328; max_depth=12; num_leaves=1024; min_data_in_leaf=881 : y = 0.939 : 193.7 secs : infill_ei\n",
            "\n",
            "lun sept 29 15:58:16 2025 AUC 0.937270546773527\n",
            "\n",
            "[mbo] 77: min_sum_hessian_in_leaf=0.0554; learning_rate=0.0801; feature_fraction=0.548; bagging_fraction=0.759; lambda_l1=9.51; lambda_l2=9.71; min_gain_to_split=3.02; bagging_freq=8; num_iterations=2449; max_depth=9; num_leaves=1170; min_data_in_leaf=323 : y = 0.937 : 174.3 secs : infill_ei\n",
            "\n",
            "lun sept 29 15:59:02 2025 AUC 0.933776741799524\n",
            "\n",
            "[mbo] 78: min_sum_hessian_in_leaf=0.0516; learning_rate=0.0969; feature_fraction=0.962; bagging_fraction=0.795; lambda_l1=5.86; lambda_l2=7.98; min_gain_to_split=10.4; bagging_freq=7; num_iterations=818; max_depth=13; num_leaves=1311; min_data_in_leaf=831 : y = 0.934 : 43.0 secs : infill_ei\n",
            "\n",
            "lun sept 29 16:02:54 2025 AUC 0.939174476992035\n",
            "\n",
            "[mbo] 79: min_sum_hessian_in_leaf=0.0875; learning_rate=0.0805; feature_fraction=0.331; bagging_fraction=0.947; lambda_l1=4.59; lambda_l2=5.68; min_gain_to_split=0.283; bagging_freq=7; num_iterations=1367; max_depth=9; num_leaves=1241; min_data_in_leaf=624 : y = 0.939 : 229.5 secs : infill_ei\n",
            "\n",
            "Saved the current state after iteration 80 in the file bayesiana.RDATA.\n",
            "\n",
            "lun sept 29 16:06:07 2025 AUC 0.934795680384286\n",
            "\n",
            "[mbo] 80: min_sum_hessian_in_leaf=0.0838; learning_rate=0.0457; feature_fraction=0.789; bagging_fraction=0.9; lambda_l1=7.5; lambda_l2=4.15; min_gain_to_split=3.81; bagging_freq=4; num_iterations=2763; max_depth=11; num_leaves=1495; min_data_in_leaf=6313 : y = 0.935 : 191.1 secs : infill_ei\n",
            "\n",
            "lun sept 29 16:09:05 2025 AUC 0.930432430663448\n",
            "\n",
            "[mbo] 81: min_sum_hessian_in_leaf=0.058; learning_rate=0.0967; feature_fraction=0.443; bagging_fraction=0.331; lambda_l1=1.71; lambda_l2=6.5; min_gain_to_split=5.7; bagging_freq=6; num_iterations=2309; max_depth=7; num_leaves=1461; min_data_in_leaf=1131 : y = 0.93 : 174.8 secs : infill_ei\n",
            "\n",
            "lun sept 29 16:10:24 2025 AUC 0.933853139792516\n",
            "\n",
            "[mbo] 82: min_sum_hessian_in_leaf=0.0484; learning_rate=0.0839; feature_fraction=0.737; bagging_fraction=0.715; lambda_l1=1.34; lambda_l2=0.266; min_gain_to_split=9.4; bagging_freq=6; num_iterations=1520; max_depth=8; num_leaves=535; min_data_in_leaf=3157 : y = 0.934 : 76.5 secs : infill_ei\n",
            "\n",
            "lun sept 29 16:11:55 2025 AUC 0.936809598221442\n",
            "\n",
            "[mbo] 83: min_sum_hessian_in_leaf=0.0552; learning_rate=0.0647; feature_fraction=0.579; bagging_fraction=0.92; lambda_l1=7.76; lambda_l2=4.75; min_gain_to_split=8.08; bagging_freq=5; num_iterations=1361; max_depth=9; num_leaves=1492; min_data_in_leaf=1396 : y = 0.937 : 89.1 secs : infill_ei\n",
            "\n",
            "lun sept 29 16:13:05 2025 AUC 0.93388896280703\n",
            "\n",
            "[mbo] 84: min_sum_hessian_in_leaf=0.0686; learning_rate=0.0798; feature_fraction=0.476; bagging_fraction=0.964; lambda_l1=1.27; lambda_l2=5.67; min_gain_to_split=5.33; bagging_freq=7; num_iterations=845; max_depth=11; num_leaves=823; min_data_in_leaf=4549 : y = 0.934 : 67.5 secs : infill_ei\n",
            "\n",
            "Saved the current state after iteration 85 in the file bayesiana.RDATA.\n",
            "\n",
            "lun sept 29 16:16:15 2025 AUC 0.9365779966359\n",
            "\n",
            "[mbo] 85: min_sum_hessian_in_leaf=0.0465; learning_rate=0.0394; feature_fraction=0.279; bagging_fraction=0.481; lambda_l1=4.42; lambda_l2=4.95; min_gain_to_split=3.73; bagging_freq=5; num_iterations=1164; max_depth=9; num_leaves=1948; min_data_in_leaf=443 : y = 0.937 : 186.7 secs : infill_ei\n",
            "\n",
            "lun sept 29 16:18:10 2025 AUC 0.935406743252512\n",
            "\n",
            "[mbo] 86: min_sum_hessian_in_leaf=0.0693; learning_rate=0.0238; feature_fraction=0.753; bagging_fraction=0.39; lambda_l1=3.78; lambda_l2=7.04; min_gain_to_split=7.59; bagging_freq=7; num_iterations=1134; max_depth=8; num_leaves=1894; min_data_in_leaf=964 : y = 0.935 : 112.8 secs : infill_ei\n",
            "\n",
            "lun sept 29 16:18:51 2025 AUC 0.929320189670614\n",
            "\n",
            "[mbo] 87: min_sum_hessian_in_leaf=0.0533; learning_rate=0.0701; feature_fraction=0.748; bagging_fraction=0.607; lambda_l1=4.65; lambda_l2=3.12; min_gain_to_split=3.93; bagging_freq=5; num_iterations=657; max_depth=10; num_leaves=1388; min_data_in_leaf=6178 : y = 0.929 : 37.4 secs : infill_ei\n",
            "\n",
            "lun sept 29 16:23:46 2025 AUC 0.941499857876532\n",
            "\n",
            "[mbo] 88: min_sum_hessian_in_leaf=0.0205; learning_rate=0.0532; feature_fraction=0.549; bagging_fraction=0.946; lambda_l1=1.61; lambda_l2=4.46; min_gain_to_split=0.322; bagging_freq=3; num_iterations=1194; max_depth=14; num_leaves=1133; min_data_in_leaf=1214 : y = 0.941 : 292.6 secs : infill_ei\n",
            "\n",
            "Saved the current state after iteration 89 in the file bayesiana.RDATA.\n",
            "\n",
            "lun sept 29 16:31:18 2025 AUC 0.940983321300338\n",
            "\n",
            "[mbo] 89: min_sum_hessian_in_leaf=0.0553; learning_rate=0.0469; feature_fraction=0.298; bagging_fraction=0.645; lambda_l1=2.75; lambda_l2=7.48; min_gain_to_split=0.394; bagging_freq=4; num_iterations=1892; max_depth=15; num_leaves=944; min_data_in_leaf=299 : y = 0.941 : 449.2 secs : infill_ei\n",
            "\n",
            "lun sept 29 16:33:53 2025 AUC 0.937530624117571\n",
            "\n",
            "[mbo] 90: min_sum_hessian_in_leaf=0.0323; learning_rate=0.0971; feature_fraction=0.464; bagging_fraction=0.878; lambda_l1=2.53; lambda_l2=7.42; min_gain_to_split=3.24; bagging_freq=1; num_iterations=1853; max_depth=15; num_leaves=236; min_data_in_leaf=2084 : y = 0.938 : 151.9 secs : infill_ei\n",
            "\n",
            "Saved the current state after iteration 91 in the file bayesiana.RDATA.\n",
            "\n",
            "lun sept 29 16:36:09 2025 AUC 0.938660883049257\n",
            "\n",
            "[mbo] 91: min_sum_hessian_in_leaf=0.0748; learning_rate=0.0568; feature_fraction=0.373; bagging_fraction=0.686; lambda_l1=0.68; lambda_l2=6.7; min_gain_to_split=1.72; bagging_freq=8; num_iterations=867; max_depth=10; num_leaves=1486; min_data_in_leaf=1419 : y = 0.939 : 133.8 secs : infill_ei\n",
            "\n",
            "lun sept 29 16:40:40 2025 AUC 0.941202501592332\n",
            "\n",
            "[mbo] 92: min_sum_hessian_in_leaf=0.0779; learning_rate=0.0244; feature_fraction=0.877; bagging_fraction=0.744; lambda_l1=6.49; lambda_l2=7.96; min_gain_to_split=3.43; bagging_freq=9; num_iterations=2026; max_depth=15; num_leaves=246; min_data_in_leaf=137 : y = 0.941 : 267.8 secs : infill_ei\n",
            "\n",
            "lun sept 29 16:47:09 2025 AUC 0.939173198094422\n",
            "\n",
            "[mbo] 93: min_sum_hessian_in_leaf=0.0715; learning_rate=0.0204; feature_fraction=0.51; bagging_fraction=0.567; lambda_l1=5.3; lambda_l2=7.16; min_gain_to_split=3.27; bagging_freq=4; num_iterations=1316; max_depth=15; num_leaves=987; min_data_in_leaf=15 : y = 0.939 : 386.5 secs : infill_ei\n",
            "\n",
            "Saved the current state after iteration 94 in the file bayesiana.RDATA.\n",
            "\n",
            "lun sept 29 16:51:22 2025 AUC 0.939698544925158\n",
            "\n",
            "[mbo] 94: min_sum_hessian_in_leaf=0.0544; learning_rate=0.0534; feature_fraction=0.191; bagging_fraction=0.936; lambda_l1=5.94; lambda_l2=6.83; min_gain_to_split=1.68; bagging_freq=2; num_iterations=2913; max_depth=14; num_leaves=451; min_data_in_leaf=619 : y = 0.94 : 249.7 secs : infill_ei\n",
            "\n",
            "lun sept 29 16:57:10 2025 AUC 0.941117472302323\n",
            "\n",
            "[mbo] 95: min_sum_hessian_in_leaf=0.097; learning_rate=0.0314; feature_fraction=0.774; bagging_fraction=0.678; lambda_l1=6.1; lambda_l2=9.16; min_gain_to_split=2.35; bagging_freq=3; num_iterations=2278; max_depth=12; num_leaves=1349; min_data_in_leaf=433 : y = 0.941 : 345.5 secs : infill_ei\n",
            "\n",
            "Saved the current state after iteration 96 in the file bayesiana.RDATA.\n",
            "\n",
            "lun sept 29 17:00:08 2025 AUC 0.939207997138734\n",
            "\n",
            "[mbo] 96: min_sum_hessian_in_leaf=0.0502; learning_rate=0.0514; feature_fraction=0.716; bagging_fraction=0.691; lambda_l1=5.97; lambda_l2=9.23; min_gain_to_split=3.81; bagging_freq=6; num_iterations=2109; max_depth=12; num_leaves=494; min_data_in_leaf=992 : y = 0.939 : 174.5 secs : infill_ei\n",
            "\n",
            "lun sept 29 17:01:55 2025 AUC 0.939685918790514\n",
            "\n",
            "[mbo] 97: min_sum_hessian_in_leaf=0.0458; learning_rate=0.0701; feature_fraction=0.662; bagging_fraction=0.835; lambda_l1=3.29; lambda_l2=5.26; min_gain_to_split=2.32; bagging_freq=7; num_iterations=849; max_depth=14; num_leaves=256; min_data_in_leaf=1418 : y = 0.94 : 104.3 secs : infill_ei\n",
            "\n",
            "lun sept 29 17:09:32 2025 AUC 0.940636094191095\n",
            "\n",
            "[mbo] 98: min_sum_hessian_in_leaf=0.0941; learning_rate=0.0191; feature_fraction=0.213; bagging_fraction=0.736; lambda_l1=4.41; lambda_l2=7.08; min_gain_to_split=1.06; bagging_freq=3; num_iterations=1641; max_depth=15; num_leaves=1311; min_data_in_leaf=634 : y = 0.941 : 454.6 secs : infill_ei\n",
            "\n",
            "Saved the current state after iteration 99 in the file bayesiana.RDATA.\n",
            "\n",
            "lun sept 29 17:16:06 2025 AUC 0.939887573364632\n",
            "\n",
            "[mbo] 99: min_sum_hessian_in_leaf=0.0997; learning_rate=0.0648; feature_fraction=0.838; bagging_fraction=0.729; lambda_l1=5.2; lambda_l2=1.09; min_gain_to_split=0.155; bagging_freq=9; num_iterations=2311; max_depth=15; num_leaves=1445; min_data_in_leaf=603 : y = 0.94 : 391.5 secs : infill_ei\n",
            "\n",
            "lun sept 29 17:22:26 2025 AUC 0.940337830758677\n",
            "\n",
            "[mbo] 100: min_sum_hessian_in_leaf=0.0991; learning_rate=0.0549; feature_fraction=0.48; bagging_fraction=0.71; lambda_l1=6.2; lambda_l2=9.05; min_gain_to_split=0.391; bagging_freq=6; num_iterations=910; max_depth=15; num_leaves=1708; min_data_in_leaf=68 : y = 0.94 : 377.1 secs : infill_ei\n",
            "\n",
            "Saved the final state in the file bayesiana.RDATA\n",
            "\n",
            "Saved the final state in the file bayesiana.RDATA\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# inicio la optimizacion bayesiana, retomando si ya existe\n",
        "# es la celda mas lenta de todo el notebook\n",
        "\n",
        "if (!file.exists(kbayesiana)) {\n",
        "  bayesiana_salida <- mbo(obj.fun, learner= surr.km, control= ctrl)\n",
        "} else {\n",
        "  bayesiana_salida <- mboContinue(kbayesiana) # retomo en caso que ya exista\n",
        "}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "ssk5nnMk6INK",
        "vscode": {
          "languageId": "r"
        }
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<style>\n",
              ".list-inline {list-style: none; margin:0; padding: 0}\n",
              ".list-inline>li {display: inline-block}\n",
              ".list-inline>li:not(:last-child)::after {content: \"\\00b7\"; padding: 0 .5ex}\n",
              "</style>\n",
              "<ol class=list-inline><li>'min_sum_hessian_in_leaf'</li><li>'learning_rate'</li><li>'feature_fraction'</li><li>'bagging_fraction'</li><li>'lambda_l1'</li><li>'lambda_l2'</li><li>'min_gain_to_split'</li><li>'bagging_freq'</li><li>'num_iterations'</li><li>'max_depth'</li><li>'num_leaves'</li><li>'min_data_in_leaf'</li><li>'y'</li><li>'dob'</li><li>'eol'</li><li>'error.message'</li><li>'exec.time'</li><li>'ei'</li><li>'error.model'</li><li>'train.time'</li><li>'prop.type'</li><li>'propose.time'</li><li>'se'</li><li>'mean'</li></ol>\n"
            ],
            "text/latex": [
              "\\begin{enumerate*}\n",
              "\\item 'min\\_sum\\_hessian\\_in\\_leaf'\n",
              "\\item 'learning\\_rate'\n",
              "\\item 'feature\\_fraction'\n",
              "\\item 'bagging\\_fraction'\n",
              "\\item 'lambda\\_l1'\n",
              "\\item 'lambda\\_l2'\n",
              "\\item 'min\\_gain\\_to\\_split'\n",
              "\\item 'bagging\\_freq'\n",
              "\\item 'num\\_iterations'\n",
              "\\item 'max\\_depth'\n",
              "\\item 'num\\_leaves'\n",
              "\\item 'min\\_data\\_in\\_leaf'\n",
              "\\item 'y'\n",
              "\\item 'dob'\n",
              "\\item 'eol'\n",
              "\\item 'error.message'\n",
              "\\item 'exec.time'\n",
              "\\item 'ei'\n",
              "\\item 'error.model'\n",
              "\\item 'train.time'\n",
              "\\item 'prop.type'\n",
              "\\item 'propose.time'\n",
              "\\item 'se'\n",
              "\\item 'mean'\n",
              "\\end{enumerate*}\n"
            ],
            "text/markdown": [
              "1. 'min_sum_hessian_in_leaf'\n",
              "2. 'learning_rate'\n",
              "3. 'feature_fraction'\n",
              "4. 'bagging_fraction'\n",
              "5. 'lambda_l1'\n",
              "6. 'lambda_l2'\n",
              "7. 'min_gain_to_split'\n",
              "8. 'bagging_freq'\n",
              "9. 'num_iterations'\n",
              "10. 'max_depth'\n",
              "11. 'num_leaves'\n",
              "12. 'min_data_in_leaf'\n",
              "13. 'y'\n",
              "14. 'dob'\n",
              "15. 'eol'\n",
              "16. 'error.message'\n",
              "17. 'exec.time'\n",
              "18. 'ei'\n",
              "19. 'error.model'\n",
              "20. 'train.time'\n",
              "21. 'prop.type'\n",
              "22. 'propose.time'\n",
              "23. 'se'\n",
              "24. 'mean'\n",
              "\n",
              "\n"
            ],
            "text/plain": [
              " [1] \"min_sum_hessian_in_leaf\" \"learning_rate\"          \n",
              " [3] \"feature_fraction\"        \"bagging_fraction\"       \n",
              " [5] \"lambda_l1\"               \"lambda_l2\"              \n",
              " [7] \"min_gain_to_split\"       \"bagging_freq\"           \n",
              " [9] \"num_iterations\"          \"max_depth\"              \n",
              "[11] \"num_leaves\"              \"min_data_in_leaf\"       \n",
              "[13] \"y\"                       \"dob\"                    \n",
              "[15] \"eol\"                     \"error.message\"          \n",
              "[17] \"exec.time\"               \"ei\"                     \n",
              "[19] \"error.model\"             \"train.time\"             \n",
              "[21] \"prop.type\"               \"propose.time\"           \n",
              "[23] \"se\"                      \"mean\"                   "
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "\n",
        "tb_bayesiana <- as.data.table(bayesiana_salida$opt.path)\n",
        "colnames( tb_bayesiana)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "u4zq-vknhjGc",
        "vscode": {
          "languageId": "r"
        }
      },
      "outputs": [],
      "source": [
        "# almaceno los resultados de la Bayesian Optimization\n",
        "# y capturo los mejores hiperparametros encontrados\n",
        "\n",
        "tb_bayesiana <- as.data.table(bayesiana_salida$opt.path)\n",
        "\n",
        "tb_bayesiana[, iter := .I]\n",
        "\n",
        "# ordeno en forma descendente por AUC = y\n",
        "setorder(tb_bayesiana, -y)\n",
        "\n",
        "# grabo para eventualmente poder utilizarlos en OTRA corrida\n",
        "fwrite( tb_bayesiana,\n",
        "  file= \"BO_log.txt\",\n",
        "  sep= \"\\t\"\n",
        ")\n",
        "\n",
        "# los mejores hiperparámetros son los que quedaron en el registro 1 de la tabla\n",
        "PARAM$out$lgbm$mejores_hiperparametros <- tb_bayesiana[\n",
        "  1, # el primero es el de mejor AUC\n",
        "  setdiff(colnames(tb_bayesiana),\n",
        "    c(\"y\",\"dob\",\"eol\",\"error.message\",\"exec.time\",\"ei\",\"error.model\",\n",
        "      \"train.time\",\"prop.type\",\"propose.time\",\"se\",\"mean\",\"iter\")),\n",
        "  with= FALSE\n",
        "]\n",
        "\n",
        "\n",
        "PARAM$out$lgbm$y <- tb_bayesiana[1, y]\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "id": "E8v2eA427N8e",
        "vscode": {
          "languageId": "r"
        }
      },
      "outputs": [],
      "source": [
        "write_yaml( PARAM, file=\"PARAM.yml\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "id": "iBTWexVU7PGC",
        "vscode": {
          "languageId": "r"
        }
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "   min_sum_hessian_in_leaf learning_rate feature_fraction bagging_fraction\n",
            "                     <num>         <num>            <num>            <num>\n",
            "1:              0.02051487     0.0532346         0.549293         0.945844\n",
            "   lambda_l1 lambda_l2 min_gain_to_split bagging_freq num_iterations max_depth\n",
            "       <num>     <num>             <num>        <int>          <int>     <int>\n",
            "1:  1.607724  4.457547          0.322211            3           1194        14\n",
            "   num_leaves min_data_in_leaf\n",
            "        <int>            <int>\n",
            "1:       1133             1214\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[1] 0.9414999\n"
          ]
        }
      ],
      "source": [
        "print(PARAM$out$lgbm$mejores_hiperparametros)\n",
        "print(PARAM$out$lgbm$y)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TKsVZmAnhwX-"
      },
      "source": [
        "## 2.3  Produccion"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RQ_C33Tr5B_9"
      },
      "source": [
        "### Final Training\n",
        "Construyo el modelo final, que es uno solo, no hace ningun tipo de particion < training, validation, testing>]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8qFmFivf5Iet"
      },
      "source": [
        "#### Final Training Dataset\n",
        "\n",
        "Aqui esta la gran decision de en qué meses hago el Final Training\n",
        "<br> debo utilizar los mejores hiperparámetros que encontré en la  optimización bayesiana"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "id": "lg5WVZncvc7H",
        "vscode": {
          "languageId": "r"
        }
      },
      "outputs": [],
      "source": [
        "# clase01\n",
        "dataset[, clase01 := ifelse(clase_ternaria %in% c(\"BAJA+1\", \"BAJA+2\"), 1L, 0L)]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "id": "yc9QzXREv0xf",
        "vscode": {
          "languageId": "r"
        }
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<table class=\"dataframe\">\n",
              "<caption>A data.table: 3 × 2</caption>\n",
              "<thead>\n",
              "\t<tr><th scope=col>clase_ternaria</th><th scope=col>N</th></tr>\n",
              "\t<tr><th scope=col>&lt;fct&gt;</th><th scope=col>&lt;int&gt;</th></tr>\n",
              "</thead>\n",
              "<tbody>\n",
              "\t<tr><td>CONTINUA</td><td>320372</td></tr>\n",
              "\t<tr><td>BAJA+2  </td><td>  1857</td></tr>\n",
              "\t<tr><td>BAJA+1  </td><td>  1453</td></tr>\n",
              "</tbody>\n",
              "</table>\n"
            ],
            "text/latex": [
              "A data.table: 3 × 2\n",
              "\\begin{tabular}{ll}\n",
              " clase\\_ternaria & N\\\\\n",
              " <fct> & <int>\\\\\n",
              "\\hline\n",
              "\t CONTINUA & 320372\\\\\n",
              "\t BAJA+2   &   1857\\\\\n",
              "\t BAJA+1   &   1453\\\\\n",
              "\\end{tabular}\n"
            ],
            "text/markdown": [
              "\n",
              "A data.table: 3 × 2\n",
              "\n",
              "| clase_ternaria &lt;fct&gt; | N &lt;int&gt; |\n",
              "|---|---|\n",
              "| CONTINUA | 320372 |\n",
              "| BAJA+2   |   1857 |\n",
              "| BAJA+1   |   1453 |\n",
              "\n"
            ],
            "text/plain": [
              "  clase_ternaria N     \n",
              "1 CONTINUA       320372\n",
              "2 BAJA+2           1857\n",
              "3 BAJA+1           1453"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "dataset_train <- dataset[foto_mes %in% PARAM$train_final]\n",
        "dataset_train[,.N,clase_ternaria]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "id": "thjdqEBLuvNt",
        "vscode": {
          "languageId": "r"
        }
      },
      "outputs": [],
      "source": [
        "# dejo los datos en el formato que necesita LightGBM\n",
        "\n",
        "dtrain_final <- lgb.Dataset(\n",
        "  data= data.matrix(dataset_train[, campos_buenos, with= FALSE]),\n",
        "  label= dataset_train[, clase01]\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VNUa-WSz5Oqu"
      },
      "source": [
        "#### Final Training Hyperparameters"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "id": "FgCcvBfEwImu",
        "vscode": {
          "languageId": "r"
        }
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<dl>\n",
              "\t<dt>$boosting</dt>\n",
              "\t\t<dd>'gbdt'</dd>\n",
              "\t<dt>$objective</dt>\n",
              "\t\t<dd>'binary'</dd>\n",
              "\t<dt>$metric</dt>\n",
              "\t\t<dd>'auc'</dd>\n",
              "\t<dt>$first_metric_only</dt>\n",
              "\t\t<dd>FALSE</dd>\n",
              "\t<dt>$boost_from_average</dt>\n",
              "\t\t<dd>TRUE</dd>\n",
              "\t<dt>$feature_pre_filter</dt>\n",
              "\t\t<dd>FALSE</dd>\n",
              "\t<dt>$force_row_wise</dt>\n",
              "\t\t<dd>TRUE</dd>\n",
              "\t<dt>$verbosity</dt>\n",
              "\t\t<dd>-100</dd>\n",
              "\t<dt>$seed</dt>\n",
              "\t\t<dd>200003</dd>\n",
              "\t<dt>$max_depth</dt>\n",
              "\t\t<dd>14</dd>\n",
              "\t<dt>$min_gain_to_split</dt>\n",
              "\t\t<dd>0.322210973004424</dd>\n",
              "\t<dt>$min_sum_hessian_in_leaf</dt>\n",
              "\t\t<dd>0.0205148742960888</dd>\n",
              "\t<dt>$lambda_l1</dt>\n",
              "\t\t<dd>1.60772367235884</dd>\n",
              "\t<dt>$lambda_l2</dt>\n",
              "\t\t<dd>4.45754701100804</dd>\n",
              "\t<dt>$max_bin</dt>\n",
              "\t\t<dd>31</dd>\n",
              "\t<dt>$bagging_fraction</dt>\n",
              "\t\t<dd>0.945843953544725</dd>\n",
              "\t<dt>$pos_bagging_fraction</dt>\n",
              "\t\t<dd>1</dd>\n",
              "\t<dt>$neg_bagging_fraction</dt>\n",
              "\t\t<dd>1</dd>\n",
              "\t<dt>$is_unbalance</dt>\n",
              "\t\t<dd>TRUE</dd>\n",
              "\t<dt>$scale_pos_weight</dt>\n",
              "\t\t<dd>1</dd>\n",
              "\t<dt>$drop_rate</dt>\n",
              "\t\t<dd>0.1</dd>\n",
              "\t<dt>$max_drop</dt>\n",
              "\t\t<dd>50</dd>\n",
              "\t<dt>$skip_drop</dt>\n",
              "\t\t<dd>0.5</dd>\n",
              "\t<dt>$extra_trees</dt>\n",
              "\t\t<dd>FALSE</dd>\n",
              "\t<dt>$num_iterations</dt>\n",
              "\t\t<dd>1194</dd>\n",
              "\t<dt>$learning_rate</dt>\n",
              "\t\t<dd>0.0532346041523692</dd>\n",
              "\t<dt>$feature_fraction</dt>\n",
              "\t\t<dd>0.549293046374839</dd>\n",
              "\t<dt>$num_leaves</dt>\n",
              "\t\t<dd>1133</dd>\n",
              "\t<dt>$min_data_in_leaf</dt>\n",
              "\t\t<dd>1214</dd>\n",
              "\t<dt>$bagging_freq</dt>\n",
              "\t\t<dd>3</dd>\n",
              "</dl>\n"
            ],
            "text/latex": [
              "\\begin{description}\n",
              "\\item[\\$boosting] 'gbdt'\n",
              "\\item[\\$objective] 'binary'\n",
              "\\item[\\$metric] 'auc'\n",
              "\\item[\\$first\\_metric\\_only] FALSE\n",
              "\\item[\\$boost\\_from\\_average] TRUE\n",
              "\\item[\\$feature\\_pre\\_filter] FALSE\n",
              "\\item[\\$force\\_row\\_wise] TRUE\n",
              "\\item[\\$verbosity] -100\n",
              "\\item[\\$seed] 200003\n",
              "\\item[\\$max\\_depth] 14\n",
              "\\item[\\$min\\_gain\\_to\\_split] 0.322210973004424\n",
              "\\item[\\$min\\_sum\\_hessian\\_in\\_leaf] 0.0205148742960888\n",
              "\\item[\\$lambda\\_l1] 1.60772367235884\n",
              "\\item[\\$lambda\\_l2] 4.45754701100804\n",
              "\\item[\\$max\\_bin] 31\n",
              "\\item[\\$bagging\\_fraction] 0.945843953544725\n",
              "\\item[\\$pos\\_bagging\\_fraction] 1\n",
              "\\item[\\$neg\\_bagging\\_fraction] 1\n",
              "\\item[\\$is\\_unbalance] TRUE\n",
              "\\item[\\$scale\\_pos\\_weight] 1\n",
              "\\item[\\$drop\\_rate] 0.1\n",
              "\\item[\\$max\\_drop] 50\n",
              "\\item[\\$skip\\_drop] 0.5\n",
              "\\item[\\$extra\\_trees] FALSE\n",
              "\\item[\\$num\\_iterations] 1194\n",
              "\\item[\\$learning\\_rate] 0.0532346041523692\n",
              "\\item[\\$feature\\_fraction] 0.549293046374839\n",
              "\\item[\\$num\\_leaves] 1133\n",
              "\\item[\\$min\\_data\\_in\\_leaf] 1214\n",
              "\\item[\\$bagging\\_freq] 3\n",
              "\\end{description}\n"
            ],
            "text/markdown": [
              "$boosting\n",
              ":   'gbdt'\n",
              "$objective\n",
              ":   'binary'\n",
              "$metric\n",
              ":   'auc'\n",
              "$first_metric_only\n",
              ":   FALSE\n",
              "$boost_from_average\n",
              ":   TRUE\n",
              "$feature_pre_filter\n",
              ":   FALSE\n",
              "$force_row_wise\n",
              ":   TRUE\n",
              "$verbosity\n",
              ":   -100\n",
              "$seed\n",
              ":   200003\n",
              "$max_depth\n",
              ":   14\n",
              "$min_gain_to_split\n",
              ":   0.322210973004424\n",
              "$min_sum_hessian_in_leaf\n",
              ":   0.0205148742960888\n",
              "$lambda_l1\n",
              ":   1.60772367235884\n",
              "$lambda_l2\n",
              ":   4.45754701100804\n",
              "$max_bin\n",
              ":   31\n",
              "$bagging_fraction\n",
              ":   0.945843953544725\n",
              "$pos_bagging_fraction\n",
              ":   1\n",
              "$neg_bagging_fraction\n",
              ":   1\n",
              "$is_unbalance\n",
              ":   TRUE\n",
              "$scale_pos_weight\n",
              ":   1\n",
              "$drop_rate\n",
              ":   0.1\n",
              "$max_drop\n",
              ":   50\n",
              "$skip_drop\n",
              ":   0.5\n",
              "$extra_trees\n",
              ":   FALSE\n",
              "$num_iterations\n",
              ":   1194\n",
              "$learning_rate\n",
              ":   0.0532346041523692\n",
              "$feature_fraction\n",
              ":   0.549293046374839\n",
              "$num_leaves\n",
              ":   1133\n",
              "$min_data_in_leaf\n",
              ":   1214\n",
              "$bagging_freq\n",
              ":   3\n",
              "\n",
              "\n"
            ],
            "text/plain": [
              "$boosting\n",
              "[1] \"gbdt\"\n",
              "\n",
              "$objective\n",
              "[1] \"binary\"\n",
              "\n",
              "$metric\n",
              "[1] \"auc\"\n",
              "\n",
              "$first_metric_only\n",
              "[1] FALSE\n",
              "\n",
              "$boost_from_average\n",
              "[1] TRUE\n",
              "\n",
              "$feature_pre_filter\n",
              "[1] FALSE\n",
              "\n",
              "$force_row_wise\n",
              "[1] TRUE\n",
              "\n",
              "$verbosity\n",
              "[1] -100\n",
              "\n",
              "$seed\n",
              "[1] 200003\n",
              "\n",
              "$max_depth\n",
              "[1] 14\n",
              "\n",
              "$min_gain_to_split\n",
              "[1] 0.322211\n",
              "\n",
              "$min_sum_hessian_in_leaf\n",
              "[1] 0.02051487\n",
              "\n",
              "$lambda_l1\n",
              "[1] 1.607724\n",
              "\n",
              "$lambda_l2\n",
              "[1] 4.457547\n",
              "\n",
              "$max_bin\n",
              "[1] 31\n",
              "\n",
              "$bagging_fraction\n",
              "[1] 0.945844\n",
              "\n",
              "$pos_bagging_fraction\n",
              "[1] 1\n",
              "\n",
              "$neg_bagging_fraction\n",
              "[1] 1\n",
              "\n",
              "$is_unbalance\n",
              "[1] TRUE\n",
              "\n",
              "$scale_pos_weight\n",
              "[1] 1\n",
              "\n",
              "$drop_rate\n",
              "[1] 0.1\n",
              "\n",
              "$max_drop\n",
              "[1] 50\n",
              "\n",
              "$skip_drop\n",
              "[1] 0.5\n",
              "\n",
              "$extra_trees\n",
              "[1] FALSE\n",
              "\n",
              "$num_iterations\n",
              "[1] 1194\n",
              "\n",
              "$learning_rate\n",
              "[1] 0.0532346\n",
              "\n",
              "$feature_fraction\n",
              "[1] 0.549293\n",
              "\n",
              "$num_leaves\n",
              "[1] 1133\n",
              "\n",
              "$min_data_in_leaf\n",
              "[1] 1214\n",
              "\n",
              "$bagging_freq\n",
              "[1] 3\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "param_final <- modifyList(PARAM$lgbm$param_fijos,\n",
        "  PARAM$out$lgbm$mejores_hiperparametros)\n",
        "\n",
        "param_final"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TZIYn4l95TBH"
      },
      "source": [
        "#### Training\n",
        "Genero el modelo final, siempre sobre TODOS los datos de  final_train, sin hacer ningun tipo de undersampling de la clase mayoritaria y mucho menos cross validation."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "id": "vPLsd4mMRe4u",
        "vscode": {
          "languageId": "r"
        }
      },
      "outputs": [],
      "source": [
        "# este punto es muy SUTIL  y será revisado en la Clase 05\n",
        "\n",
        "param_normalizado <- copy(param_final)\n",
        "param_normalizado$min_data_in_leaf <-  round(param_final$min_data_in_leaf / PARAM$trainingstrategy$undersampling)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "metadata": {
        "id": "WRI_-taRwOXO",
        "vscode": {
          "languageId": "r"
        }
      },
      "outputs": [],
      "source": [
        "# entreno LightGBM\n",
        "\n",
        "param_normalizado$seed <- 200003\n",
        "\n",
        "modelo_final <- lgb.train(\n",
        "  data= dtrain_final,\n",
        "  param= param_normalizado\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "id": "_bkhnCvj0g3Q",
        "vscode": {
          "languageId": "r"
        }
      },
      "outputs": [],
      "source": [
        "# ahora imprimo la importancia de variables\n",
        "\n",
        "tb_importancia <- as.data.table(lgb.importance(modelo_final))\n",
        "archivo_importancia <- \"impo.txt\"\n",
        "\n",
        "fwrite(tb_importancia,\n",
        "  file= archivo_importancia,\n",
        "  sep= \"\\t\"\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "id": "lZ3sLmbh0kFj",
        "vscode": {
          "languageId": "r"
        }
      },
      "outputs": [],
      "source": [
        "# grabo a disco el modelo en un formato para seres humanos ... ponele ...\n",
        "lgb.save(modelo_final, \"modelo.txt\" )"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VEtp2--t5Ymg"
      },
      "source": [
        "### Scoring"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hI5008Mj5ZdI"
      },
      "source": [
        "Aplico el modelo final a los datos del futuro"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "metadata": {
        "id": "PimBY3N_0ryP",
        "vscode": {
          "languageId": "r"
        }
      },
      "outputs": [],
      "source": [
        "# aplico el modelo a los datos sin clase\n",
        "dfuture <- dataset[foto_mes %in% PARAM$future]\n",
        "\n",
        "# aplico el modelo a los datos nuevos\n",
        "prediccion <- predict(\n",
        "  modelo_final,\n",
        "  data.matrix(dfuture[, campos_buenos, with= FALSE])\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 45,
      "metadata": {
        "id": "M9_NCquymhtF",
        "vscode": {
          "languageId": "r"
        }
      },
      "outputs": [],
      "source": [
        "# inicilizo el dataset  drealidad\n",
        "drealidad <- realidad_inicializar( dfuture, PARAM)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D26rNRh55gpw"
      },
      "source": [
        "#### Tabla Prediccion"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 46,
      "metadata": {
        "id": "RJwg7LHd11yu",
        "vscode": {
          "languageId": "r"
        }
      },
      "outputs": [],
      "source": [
        "# tabla de prediccion\n",
        "\n",
        "tb_prediccion <- dfuture[, list(numero_de_cliente, foto_mes)]\n",
        "tb_prediccion[, prob := prediccion ]\n",
        "\n",
        "# grabo las probabilidad del modelo\n",
        "fwrite(tb_prediccion,\n",
        "  file= \"prediccion.txt\",\n",
        "  sep= \"\\t\"\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jOt4eG_55ltv"
      },
      "source": [
        "Kaggle Competition Submit"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {
        "id": "Vdu3moTfJ1Vl",
        "vscode": {
          "languageId": "r"
        }
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<style>\n",
              ".list-inline {list-style: none; margin:0; padding: 0}\n",
              ".list-inline>li {display: inline-block}\n",
              ".list-inline>li:not(:last-child)::after {content: \"\\00b7\"; padding: 0 .5ex}\n",
              "</style>\n",
              "<ol class=list-inline><li>0</li><li>100</li><li>200</li><li>300</li><li>400</li><li>500</li><li>600</li><li>700</li><li>800</li><li>900</li><li>1000</li><li>1100</li><li>1200</li><li>1300</li><li>1400</li><li>1500</li><li>1600</li><li>1700</li><li>1800</li><li>1900</li><li>2000</li><li>2100</li><li>2200</li><li>2300</li><li>2400</li><li>2500</li><li>2600</li><li>2700</li><li>2800</li><li>2900</li><li>3000</li><li>3100</li><li>3200</li><li>3300</li><li>3400</li><li>3500</li><li>3600</li><li>3700</li><li>3800</li><li>3900</li><li>4000</li><li>4100</li><li>4200</li><li>4300</li><li>4400</li><li>4500</li><li>4600</li><li>4700</li><li>4800</li><li>4900</li><li>5000</li><li>5100</li><li>5200</li><li>5300</li><li>5400</li><li>5500</li><li>5600</li><li>5700</li><li>5800</li><li>5900</li><li>6000</li><li>6100</li><li>6200</li><li>6300</li><li>6400</li><li>6500</li><li>6600</li><li>6700</li><li>6800</li><li>6900</li><li>7000</li><li>7100</li><li>7200</li><li>7300</li><li>7400</li><li>7500</li><li>7600</li><li>7700</li><li>7800</li><li>7900</li><li>8000</li><li>8100</li><li>8200</li><li>8300</li><li>8400</li><li>8500</li><li>8600</li><li>8700</li><li>8800</li><li>8900</li><li>9000</li><li>9100</li><li>9200</li><li>9300</li><li>9400</li><li>9500</li><li>9600</li><li>9700</li><li>9800</li><li>9900</li><li>10000</li><li>10100</li><li>10200</li><li>10300</li><li>10400</li><li>10500</li><li>10600</li><li>10700</li><li>10800</li><li>10900</li><li>11000</li><li>11100</li><li>11200</li><li>11300</li><li>11400</li><li>11500</li><li>11600</li><li>11700</li><li>11800</li><li>11900</li><li>12000</li><li>12100</li><li>12200</li><li>12300</li><li>12400</li><li>12500</li><li>12600</li><li>12700</li><li>12800</li><li>12900</li><li>13000</li><li>13100</li><li>13200</li><li>13300</li><li>13400</li><li>13500</li><li>13600</li><li>13700</li><li>13800</li><li>13900</li><li>14000</li><li>14100</li><li>14200</li><li>14300</li><li>14400</li><li>14500</li><li>14600</li><li>14700</li><li>14800</li><li>14900</li><li>15000</li><li>15100</li><li>15200</li><li>15300</li><li>15400</li><li>15500</li><li>15600</li><li>15700</li><li>15800</li><li>15900</li><li>16000</li><li>16100</li><li>16200</li><li>16300</li><li>16400</li><li>16500</li><li>16600</li><li>16700</li><li>16800</li><li>16900</li><li>17000</li><li>17100</li><li>17200</li><li>17300</li><li>17400</li><li>17500</li><li>17600</li><li>17700</li><li>17800</li><li>17900</li><li>18000</li><li>18100</li><li>18200</li><li>18300</li><li>18400</li><li>18500</li><li>18600</li><li>18700</li><li>18800</li><li>18900</li><li>19000</li></ol>\n"
            ],
            "text/latex": [
              "\\begin{enumerate*}\n",
              "\\item 0\n",
              "\\item 100\n",
              "\\item 200\n",
              "\\item 300\n",
              "\\item 400\n",
              "\\item 500\n",
              "\\item 600\n",
              "\\item 700\n",
              "\\item 800\n",
              "\\item 900\n",
              "\\item 1000\n",
              "\\item 1100\n",
              "\\item 1200\n",
              "\\item 1300\n",
              "\\item 1400\n",
              "\\item 1500\n",
              "\\item 1600\n",
              "\\item 1700\n",
              "\\item 1800\n",
              "\\item 1900\n",
              "\\item 2000\n",
              "\\item 2100\n",
              "\\item 2200\n",
              "\\item 2300\n",
              "\\item 2400\n",
              "\\item 2500\n",
              "\\item 2600\n",
              "\\item 2700\n",
              "\\item 2800\n",
              "\\item 2900\n",
              "\\item 3000\n",
              "\\item 3100\n",
              "\\item 3200\n",
              "\\item 3300\n",
              "\\item 3400\n",
              "\\item 3500\n",
              "\\item 3600\n",
              "\\item 3700\n",
              "\\item 3800\n",
              "\\item 3900\n",
              "\\item 4000\n",
              "\\item 4100\n",
              "\\item 4200\n",
              "\\item 4300\n",
              "\\item 4400\n",
              "\\item 4500\n",
              "\\item 4600\n",
              "\\item 4700\n",
              "\\item 4800\n",
              "\\item 4900\n",
              "\\item 5000\n",
              "\\item 5100\n",
              "\\item 5200\n",
              "\\item 5300\n",
              "\\item 5400\n",
              "\\item 5500\n",
              "\\item 5600\n",
              "\\item 5700\n",
              "\\item 5800\n",
              "\\item 5900\n",
              "\\item 6000\n",
              "\\item 6100\n",
              "\\item 6200\n",
              "\\item 6300\n",
              "\\item 6400\n",
              "\\item 6500\n",
              "\\item 6600\n",
              "\\item 6700\n",
              "\\item 6800\n",
              "\\item 6900\n",
              "\\item 7000\n",
              "\\item 7100\n",
              "\\item 7200\n",
              "\\item 7300\n",
              "\\item 7400\n",
              "\\item 7500\n",
              "\\item 7600\n",
              "\\item 7700\n",
              "\\item 7800\n",
              "\\item 7900\n",
              "\\item 8000\n",
              "\\item 8100\n",
              "\\item 8200\n",
              "\\item 8300\n",
              "\\item 8400\n",
              "\\item 8500\n",
              "\\item 8600\n",
              "\\item 8700\n",
              "\\item 8800\n",
              "\\item 8900\n",
              "\\item 9000\n",
              "\\item 9100\n",
              "\\item 9200\n",
              "\\item 9300\n",
              "\\item 9400\n",
              "\\item 9500\n",
              "\\item 9600\n",
              "\\item 9700\n",
              "\\item 9800\n",
              "\\item 9900\n",
              "\\item 10000\n",
              "\\item 10100\n",
              "\\item 10200\n",
              "\\item 10300\n",
              "\\item 10400\n",
              "\\item 10500\n",
              "\\item 10600\n",
              "\\item 10700\n",
              "\\item 10800\n",
              "\\item 10900\n",
              "\\item 11000\n",
              "\\item 11100\n",
              "\\item 11200\n",
              "\\item 11300\n",
              "\\item 11400\n",
              "\\item 11500\n",
              "\\item 11600\n",
              "\\item 11700\n",
              "\\item 11800\n",
              "\\item 11900\n",
              "\\item 12000\n",
              "\\item 12100\n",
              "\\item 12200\n",
              "\\item 12300\n",
              "\\item 12400\n",
              "\\item 12500\n",
              "\\item 12600\n",
              "\\item 12700\n",
              "\\item 12800\n",
              "\\item 12900\n",
              "\\item 13000\n",
              "\\item 13100\n",
              "\\item 13200\n",
              "\\item 13300\n",
              "\\item 13400\n",
              "\\item 13500\n",
              "\\item 13600\n",
              "\\item 13700\n",
              "\\item 13800\n",
              "\\item 13900\n",
              "\\item 14000\n",
              "\\item 14100\n",
              "\\item 14200\n",
              "\\item 14300\n",
              "\\item 14400\n",
              "\\item 14500\n",
              "\\item 14600\n",
              "\\item 14700\n",
              "\\item 14800\n",
              "\\item 14900\n",
              "\\item 15000\n",
              "\\item 15100\n",
              "\\item 15200\n",
              "\\item 15300\n",
              "\\item 15400\n",
              "\\item 15500\n",
              "\\item 15600\n",
              "\\item 15700\n",
              "\\item 15800\n",
              "\\item 15900\n",
              "\\item 16000\n",
              "\\item 16100\n",
              "\\item 16200\n",
              "\\item 16300\n",
              "\\item 16400\n",
              "\\item 16500\n",
              "\\item 16600\n",
              "\\item 16700\n",
              "\\item 16800\n",
              "\\item 16900\n",
              "\\item 17000\n",
              "\\item 17100\n",
              "\\item 17200\n",
              "\\item 17300\n",
              "\\item 17400\n",
              "\\item 17500\n",
              "\\item 17600\n",
              "\\item 17700\n",
              "\\item 17800\n",
              "\\item 17900\n",
              "\\item 18000\n",
              "\\item 18100\n",
              "\\item 18200\n",
              "\\item 18300\n",
              "\\item 18400\n",
              "\\item 18500\n",
              "\\item 18600\n",
              "\\item 18700\n",
              "\\item 18800\n",
              "\\item 18900\n",
              "\\item 19000\n",
              "\\end{enumerate*}\n"
            ],
            "text/markdown": [
              "1. 0\n",
              "2. 100\n",
              "3. 200\n",
              "4. 300\n",
              "5. 400\n",
              "6. 500\n",
              "7. 600\n",
              "8. 700\n",
              "9. 800\n",
              "10. 900\n",
              "11. 1000\n",
              "12. 1100\n",
              "13. 1200\n",
              "14. 1300\n",
              "15. 1400\n",
              "16. 1500\n",
              "17. 1600\n",
              "18. 1700\n",
              "19. 1800\n",
              "20. 1900\n",
              "21. 2000\n",
              "22. 2100\n",
              "23. 2200\n",
              "24. 2300\n",
              "25. 2400\n",
              "26. 2500\n",
              "27. 2600\n",
              "28. 2700\n",
              "29. 2800\n",
              "30. 2900\n",
              "31. 3000\n",
              "32. 3100\n",
              "33. 3200\n",
              "34. 3300\n",
              "35. 3400\n",
              "36. 3500\n",
              "37. 3600\n",
              "38. 3700\n",
              "39. 3800\n",
              "40. 3900\n",
              "41. 4000\n",
              "42. 4100\n",
              "43. 4200\n",
              "44. 4300\n",
              "45. 4400\n",
              "46. 4500\n",
              "47. 4600\n",
              "48. 4700\n",
              "49. 4800\n",
              "50. 4900\n",
              "51. 5000\n",
              "52. 5100\n",
              "53. 5200\n",
              "54. 5300\n",
              "55. 5400\n",
              "56. 5500\n",
              "57. 5600\n",
              "58. 5700\n",
              "59. 5800\n",
              "60. 5900\n",
              "61. 6000\n",
              "62. 6100\n",
              "63. 6200\n",
              "64. 6300\n",
              "65. 6400\n",
              "66. 6500\n",
              "67. 6600\n",
              "68. 6700\n",
              "69. 6800\n",
              "70. 6900\n",
              "71. 7000\n",
              "72. 7100\n",
              "73. 7200\n",
              "74. 7300\n",
              "75. 7400\n",
              "76. 7500\n",
              "77. 7600\n",
              "78. 7700\n",
              "79. 7800\n",
              "80. 7900\n",
              "81. 8000\n",
              "82. 8100\n",
              "83. 8200\n",
              "84. 8300\n",
              "85. 8400\n",
              "86. 8500\n",
              "87. 8600\n",
              "88. 8700\n",
              "89. 8800\n",
              "90. 8900\n",
              "91. 9000\n",
              "92. 9100\n",
              "93. 9200\n",
              "94. 9300\n",
              "95. 9400\n",
              "96. 9500\n",
              "97. 9600\n",
              "98. 9700\n",
              "99. 9800\n",
              "100. 9900\n",
              "101. 10000\n",
              "102. 10100\n",
              "103. 10200\n",
              "104. 10300\n",
              "105. 10400\n",
              "106. 10500\n",
              "107. 10600\n",
              "108. 10700\n",
              "109. 10800\n",
              "110. 10900\n",
              "111. 11000\n",
              "112. 11100\n",
              "113. 11200\n",
              "114. 11300\n",
              "115. 11400\n",
              "116. 11500\n",
              "117. 11600\n",
              "118. 11700\n",
              "119. 11800\n",
              "120. 11900\n",
              "121. 12000\n",
              "122. 12100\n",
              "123. 12200\n",
              "124. 12300\n",
              "125. 12400\n",
              "126. 12500\n",
              "127. 12600\n",
              "128. 12700\n",
              "129. 12800\n",
              "130. 12900\n",
              "131. 13000\n",
              "132. 13100\n",
              "133. 13200\n",
              "134. 13300\n",
              "135. 13400\n",
              "136. 13500\n",
              "137. 13600\n",
              "138. 13700\n",
              "139. 13800\n",
              "140. 13900\n",
              "141. 14000\n",
              "142. 14100\n",
              "143. 14200\n",
              "144. 14300\n",
              "145. 14400\n",
              "146. 14500\n",
              "147. 14600\n",
              "148. 14700\n",
              "149. 14800\n",
              "150. 14900\n",
              "151. 15000\n",
              "152. 15100\n",
              "153. 15200\n",
              "154. 15300\n",
              "155. 15400\n",
              "156. 15500\n",
              "157. 15600\n",
              "158. 15700\n",
              "159. 15800\n",
              "160. 15900\n",
              "161. 16000\n",
              "162. 16100\n",
              "163. 16200\n",
              "164. 16300\n",
              "165. 16400\n",
              "166. 16500\n",
              "167. 16600\n",
              "168. 16700\n",
              "169. 16800\n",
              "170. 16900\n",
              "171. 17000\n",
              "172. 17100\n",
              "173. 17200\n",
              "174. 17300\n",
              "175. 17400\n",
              "176. 17500\n",
              "177. 17600\n",
              "178. 17700\n",
              "179. 17800\n",
              "180. 17900\n",
              "181. 18000\n",
              "182. 18100\n",
              "183. 18200\n",
              "184. 18300\n",
              "185. 18400\n",
              "186. 18500\n",
              "187. 18600\n",
              "188. 18700\n",
              "189. 18800\n",
              "190. 18900\n",
              "191. 19000\n",
              "\n",
              "\n"
            ],
            "text/plain": [
              "  [1]     0   100   200   300   400   500   600   700   800   900  1000  1100\n",
              " [13]  1200  1300  1400  1500  1600  1700  1800  1900  2000  2100  2200  2300\n",
              " [25]  2400  2500  2600  2700  2800  2900  3000  3100  3200  3300  3400  3500\n",
              " [37]  3600  3700  3800  3900  4000  4100  4200  4300  4400  4500  4600  4700\n",
              " [49]  4800  4900  5000  5100  5200  5300  5400  5500  5600  5700  5800  5900\n",
              " [61]  6000  6100  6200  6300  6400  6500  6600  6700  6800  6900  7000  7100\n",
              " [73]  7200  7300  7400  7500  7600  7700  7800  7900  8000  8100  8200  8300\n",
              " [85]  8400  8500  8600  8700  8800  8900  9000  9100  9200  9300  9400  9500\n",
              " [97]  9600  9700  9800  9900 10000 10100 10200 10300 10400 10500 10600 10700\n",
              "[109] 10800 10900 11000 11100 11200 11300 11400 11500 11600 11700 11800 11900\n",
              "[121] 12000 12100 12200 12300 12400 12500 12600 12700 12800 12900 13000 13100\n",
              "[133] 13200 13300 13400 13500 13600 13700 13800 13900 14000 14100 14200 14300\n",
              "[145] 14400 14500 14600 14700 14800 14900 15000 15100 15200 15300 15400 15500\n",
              "[157] 15600 15700 15800 15900 16000 16100 16200 16300 16400 16500 16600 16700\n",
              "[169] 16800 16900 17000 17100 17200 17300 17400 17500 17600 17700 17800 17900\n",
              "[181] 18000 18100 18200 18300 18400 18500 18600 18700 18800 18900 19000"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "PARAM$cortes"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 47,
      "metadata": {
        "id": "gWW3tatE12je",
        "vscode": {
          "languageId": "r"
        }
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Warning message in dir.create(\"kaggle\"):\n",
            "\"'kaggle' already exists\"\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Envios=0\t TOTAL=-20000  Public=0 Private=-28571.43\n",
            "Envios=100\t TOTAL=18000000  Public=16666667 Private=18571429\n",
            "Envios=200\t TOTAL=36800000  Public=36400000 Private=36971429\n",
            "Envios=300\t TOTAL=45200000  Public=45066667 Private=45257143\n",
            "Envios=400\t TOTAL=63200000  Public=56333333 Private=66142857\n",
            "Envios=500\t TOTAL=74000000  Public=57200000 Private=81200000\n",
            "Envios=600\t TOTAL=85600000  Public=55000000 Private=98714286\n",
            "Envios=700\t TOTAL=101200000  Public=69000000 Private=115000000\n",
            "Envios=800\t TOTAL=110400000  Public=74666667 Private=125714286\n",
            "Envios=900\t TOTAL=122000000  Public=83266667 Private=138600000\n",
            "Envios=1000\t TOTAL=132800000  Public=96733333 Private=148257143\n",
            "Envios=1100\t TOTAL=140400000  Public=98000000 Private=158571429\n",
            "Envios=1200\t TOTAL=152800000  Public=111933333 Private=170314286\n",
            "Envios=1300\t TOTAL=161200000  Public=123133333 Private=177514286\n",
            "Envios=1400\t TOTAL=171200000  Public=141733333 Private=183828571\n",
            "Envios=1500\t TOTAL=176400000  Public=144666667 Private=190000000\n",
            "Envios=1600\t TOTAL=187200000  Public=153200000 Private=201771429\n",
            "Envios=1700\t TOTAL=195600000  Public=158933333 Private=211314286\n",
            "Envios=1800\t TOTAL=204800000  Public=164933333 Private=221885714\n",
            "Envios=1900\t TOTAL=208400000  Public=173533333 Private=223342857\n",
            "Envios=2000\t TOTAL=212800000  Public=171733333 Private=230400000\n",
            "Envios=2100\t TOTAL=218000000  Public=177933333 Private=235171429\n",
            "Envios=2200\t TOTAL=224800000  Public=183866667 Private=242342857\n",
            "Envios=2300\t TOTAL=232400000  Public=192800000 Private=249371429\n",
            "Envios=2400\t TOTAL=239200000  Public=195866667 Private=257771429\n",
            "Envios=2500\t TOTAL=245200000  Public=204666667 Private=262571429\n",
            "Envios=2600\t TOTAL=249600000  Public=210733333 Private=266257143\n",
            "Envios=2700\t TOTAL=254800000  Public=218733333 Private=270257143\n",
            "Envios=2800\t TOTAL=256800000  Public=216866667 Private=273914286\n",
            "Envios=2900\t TOTAL=259600000  Public=220133333 Private=276514286\n",
            "Envios=3000\t TOTAL=263200000  Public=220933333 Private=281314286\n",
            "Envios=3100\t TOTAL=267600000  Public=227066667 Private=284971429\n",
            "Envios=3200\t TOTAL=268000000  Public=230333333 Private=284142857\n",
            "Envios=3300\t TOTAL=270800000  Public=233533333 Private=286771429\n",
            "Envios=3400\t TOTAL=275200000  Public=233800000 Private=292942857\n",
            "Envios=3500\t TOTAL=278000000  Public=237000000 Private=295571429\n",
            "Envios=3600\t TOTAL=278400000  Public=237533333 Private=295914286\n",
            "Envios=3700\t TOTAL=279600000  Public=240800000 Private=296228571\n",
            "Envios=3800\t TOTAL=282400000  Public=244200000 Private=298771429\n",
            "Envios=3900\t TOTAL=286000000  Public=247933333 Private=302314286\n",
            "Envios=4000\t TOTAL=287200000  Public=253466667 Private=301657143\n",
            "Envios=4100\t TOTAL=289200000  Public=254133333 Private=304228571\n",
            "Envios=4200\t TOTAL=294400000  Public=267933333 Private=305742857\n",
            "Envios=4300\t TOTAL=298800000  Public=268466667 Private=311800000\n",
            "Envios=4400\t TOTAL=300000000  Public=268933333 Private=313314286\n",
            "Envios=4500\t TOTAL=302800000  Public=267400000 Private=317971429\n",
            "Envios=4600\t TOTAL=301600000  Public=265466667 Private=317085714\n",
            "Envios=4700\t TOTAL=300400000  Public=263666667 Private=316142857\n",
            "Envios=4800\t TOTAL=302400000  Public=264400000 Private=318685714\n",
            "Envios=4900\t TOTAL=304400000  Public=265066667 Private=321257143\n",
            "Envios=5000\t TOTAL=305600000  Public=266066667 Private=322542857\n",
            "Envios=5100\t TOTAL=310000000  Public=271866667 Private=326342857\n",
            "Envios=5200\t TOTAL=312000000  Public=269733333 Private=330114286\n",
            "Envios=5300\t TOTAL=313200000  Public=270266667 Private=331600000\n",
            "Envios=5400\t TOTAL=313600000  Public=271400000 Private=331685714\n",
            "Envios=5500\t TOTAL=312400000  Public=269400000 Private=330828571\n",
            "Envios=5600\t TOTAL=313600000  Public=270133333 Private=332228571\n",
            "Envios=5700\t TOTAL=314800000  Public=268000000 Private=334857143\n",
            "Envios=5800\t TOTAL=316800000  Public=268733333 Private=337400000\n",
            "Envios=5900\t TOTAL=318800000  Public=269600000 Private=339885714\n",
            "Envios=6000\t TOTAL=321600000  Public=278600000 Private=340028571\n",
            "Envios=6100\t TOTAL=320400000  Public=279066667 Private=338114286\n",
            "Envios=6200\t TOTAL=320000000  Public=276866667 Private=338485714\n",
            "Envios=6300\t TOTAL=323600000  Public=279466667 Private=342514286\n",
            "Envios=6400\t TOTAL=324000000  Public=285600000 Private=340457143\n",
            "Envios=6500\t TOTAL=326000000  Public=289200000 Private=341771429\n",
            "Envios=6600\t TOTAL=327200000  Public=287333333 Private=344285714\n",
            "Envios=6700\t TOTAL=327600000  Public=285733333 Private=345542857\n",
            "Envios=6800\t TOTAL=328000000  Public=283600000 Private=347028571\n",
            "Envios=6900\t TOTAL=326800000  Public=281133333 Private=346371429\n",
            "Envios=7000\t TOTAL=328800000  Public=278866667 Private=350200000\n",
            "Envios=7100\t TOTAL=327600000  Public=276933333 Private=349314286\n",
            "Envios=7200\t TOTAL=326400000  Public=277800000 Private=347228571\n",
            "Envios=7300\t TOTAL=329200000  Public=281466667 Private=349657143\n",
            "Envios=7400\t TOTAL=331200000  Public=285000000 Private=351000000\n",
            "Envios=7500\t TOTAL=332400000  Public=285733333 Private=352400000\n",
            "Envios=7600\t TOTAL=332800000  Public=289266667 Private=351457143\n",
            "Envios=7700\t TOTAL=334800000  Public=294533333 Private=352057143\n",
            "Envios=7800\t TOTAL=335200000  Public=292400000 Private=353542857\n",
            "Envios=7900\t TOTAL=335600000  Public=290733333 Private=354828571\n",
            "Envios=8000\t TOTAL=336800000  Public=288266667 Private=357600000\n",
            "Envios=8100\t TOTAL=339600000  Public=291133333 Private=360371429\n",
            "Envios=8200\t TOTAL=340000000  Public=294466667 Private=359514286\n",
            "Envios=8300\t TOTAL=340400000  Public=295266667 Private=359742857\n",
            "Envios=8400\t TOTAL=340800000  Public=292800000 Private=361371429\n",
            "Envios=8500\t TOTAL=341200000  Public=295466667 Private=360800000\n",
            "Envios=8600\t TOTAL=344000000  Public=301133333 Private=362371429\n",
            "Envios=8700\t TOTAL=344400000  Public=299866667 Private=363485714\n",
            "Envios=8800\t TOTAL=344000000  Public=303400000 Private=361400000\n",
            "Envios=8900\t TOTAL=343600000  Public=306666667 Private=359428571\n",
            "Envios=9000\t TOTAL=343200000  Public=304866667 Private=359628571\n",
            "Envios=9100\t TOTAL=342800000  Public=302866667 Private=359914286\n",
            "Envios=9200\t TOTAL=344000000  Public=304000000 Private=361142857\n",
            "Envios=9300\t TOTAL=343600000  Public=302200000 Private=361342857\n",
            "Envios=9400\t TOTAL=344000000  Public=303000000 Private=361571429\n",
            "Envios=9500\t TOTAL=344400000  Public=300666667 Private=363142857\n",
            "Envios=9600\t TOTAL=344000000  Public=301800000 Private=362085714\n",
            "Envios=9700\t TOTAL=345200000  Public=304733333 Private=362542857\n",
            "Envios=9800\t TOTAL=344800000  Public=308066667 Private=360542857\n",
            "Envios=9900\t TOTAL=344400000  Public=306066667 Private=360828571\n",
            "Envios=10000\t TOTAL=346400000  Public=307266667 Private=363171429\n",
            "Envios=10100\t TOTAL=345200000  Public=305200000 Private=362342857\n",
            "Envios=10200\t TOTAL=344000000  Public=305866667 Private=360342857\n",
            "Envios=10300\t TOTAL=344400000  Public=304133333 Private=361657143\n",
            "Envios=10400\t TOTAL=343200000  Public=301933333 Private=360885714\n",
            "Envios=10500\t TOTAL=343600000  Public=300000000 Private=362285714\n",
            "Envios=10600\t TOTAL=344800000  Public=298000000 Private=364857143\n",
            "Envios=10700\t TOTAL=345200000  Public=298266667 Private=365314286\n",
            "Envios=10800\t TOTAL=345600000  Public=299000000 Private=365571429\n",
            "Envios=10900\t TOTAL=346800000  Public=299466667 Private=367085714\n",
            "Envios=11000\t TOTAL=345600000  Public=297466667 Private=366228571\n",
            "Envios=11100\t TOTAL=345200000  Public=301133333 Private=364085714\n",
            "Envios=11200\t TOTAL=344000000  Public=299066667 Private=363257143\n",
            "Envios=11300\t TOTAL=342800000  Public=297066667 Private=362400000\n",
            "Envios=11400\t TOTAL=344000000  Public=298266667 Private=363600000\n",
            "Envios=11500\t TOTAL=342800000  Public=295933333 Private=362885714\n",
            "Envios=11600\t TOTAL=341600000  Public=296533333 Private=360914286\n",
            "Envios=11700\t TOTAL=341200000  Public=294733333 Private=361114286\n",
            "Envios=11800\t TOTAL=340800000  Public=293266667 Private=361171429\n",
            "Envios=11900\t TOTAL=340400000  Public=293800000 Private=360371429\n",
            "Envios=12000\t TOTAL=339200000  Public=294266667 Private=358457143\n",
            "Envios=12100\t TOTAL=338800000  Public=292666667 Private=358571429\n",
            "Envios=12200\t TOTAL=338400000  Public=293266667 Private=357742857\n",
            "Envios=12300\t TOTAL=337200000  Public=290733333 Private=357114286\n",
            "Envios=12400\t TOTAL=336000000  Public=288733333 Private=356257143\n",
            "Envios=12500\t TOTAL=334000000  Public=286600000 Private=354314286\n",
            "Envios=12600\t TOTAL=332800000  Public=287666667 Private=352142857\n",
            "Envios=12700\t TOTAL=331600000  Public=288200000 Private=350200000\n",
            "Envios=12800\t TOTAL=332000000  Public=289133333 Private=350371429\n",
            "Envios=12900\t TOTAL=330000000  Public=287066667 Private=348400000\n",
            "Envios=13000\t TOTAL=330400000  Public=285000000 Private=349857143\n",
            "Envios=13100\t TOTAL=330800000  Public=282800000 Private=351371429\n",
            "Envios=13200\t TOTAL=330400000  Public=283733333 Private=350400000\n",
            "Envios=13300\t TOTAL=329200000  Public=284266667 Private=348457143\n",
            "Envios=13400\t TOTAL=328000000  Public=282666667 Private=347428571\n",
            "Envios=13500\t TOTAL=327600000  Public=280466667 Private=347800000\n",
            "Envios=13600\t TOTAL=326400000  Public=281000000 Private=345857143\n",
            "Envios=13700\t TOTAL=326800000  Public=286466667 Private=344085714\n",
            "Envios=13800\t TOTAL=324800000  Public=283800000 Private=342371429\n",
            "Envios=13900\t TOTAL=326000000  Public=286866667 Private=342771429\n",
            "Envios=14000\t TOTAL=324800000  Public=287800000 Private=340657143\n",
            "Envios=14100\t TOTAL=324400000  Public=288600000 Private=339742857\n",
            "Envios=14200\t TOTAL=323200000  Public=286666667 Private=338857143\n",
            "Envios=14300\t TOTAL=322800000  Public=284466667 Private=339228571\n",
            "Envios=14400\t TOTAL=324000000  Public=284866667 Private=340771429\n",
            "Envios=14500\t TOTAL=323600000  Public=283133333 Private=340942857\n",
            "Envios=14600\t TOTAL=324000000  Public=284133333 Private=341085714\n",
            "Envios=14700\t TOTAL=323600000  Public=285200000 Private=340057143\n",
            "Envios=14800\t TOTAL=322400000  Public=286133333 Private=337942857\n",
            "Envios=14900\t TOTAL=320400000  Public=283866667 Private=336057143\n",
            "Envios=15000\t TOTAL=318400000  Public=281933333 Private=334028571\n",
            "Envios=15100\t TOTAL=317200000  Public=283333333 Private=331714286\n",
            "Envios=15200\t TOTAL=316000000  Public=281666667 Private=330714286\n",
            "Envios=15300\t TOTAL=315600000  Public=284866667 Private=328771429\n",
            "Envios=15400\t TOTAL=315200000  Public=282466667 Private=329228571\n",
            "Envios=15500\t TOTAL=314000000  Public=280533333 Private=328342857\n",
            "Envios=15600\t TOTAL=313600000  Public=281266667 Private=327457143\n",
            "Envios=15700\t TOTAL=312400000  Public=279266667 Private=326600000\n",
            "Envios=15800\t TOTAL=312000000  Public=279866667 Private=325771429\n",
            "Envios=15900\t TOTAL=310800000  Public=279733333 Private=324114286\n",
            "Envios=16000\t TOTAL=312000000  Public=282266667 Private=324742857\n",
            "Envios=16100\t TOTAL=310800000  Public=280266667 Private=323885714\n",
            "Envios=16200\t TOTAL=309600000  Public=278066667 Private=323114286\n",
            "Envios=16300\t TOTAL=310000000  Public=276066667 Private=324542857\n",
            "Envios=16400\t TOTAL=308000000  Public=274133333 Private=322514286\n",
            "Envios=16500\t TOTAL=307600000  Public=271400000 Private=323114286\n",
            "Envios=16600\t TOTAL=306400000  Public=269466667 Private=322228571\n",
            "Envios=16700\t TOTAL=306000000  Public=267133333 Private=322657143\n",
            "Envios=16800\t TOTAL=307200000  Public=265266667 Private=325171429\n",
            "Envios=16900\t TOTAL=306000000  Public=263466667 Private=324228571\n",
            "Envios=17000\t TOTAL=304000000  Public=261466667 Private=322228571\n",
            "Envios=17100\t TOTAL=302000000  Public=259200000 Private=320342857\n",
            "Envios=17200\t TOTAL=300800000  Public=257200000 Private=319485714\n",
            "Envios=17300\t TOTAL=299600000  Public=255266667 Private=318600000\n",
            "Envios=17400\t TOTAL=298400000  Public=252866667 Private=317914286\n",
            "Envios=17500\t TOTAL=297200000  Public=250800000 Private=317085714\n",
            "Envios=17600\t TOTAL=296000000  Public=248933333 Private=316171429\n",
            "Envios=17700\t TOTAL=295600000  Public=251466667 Private=314514286\n",
            "Envios=17800\t TOTAL=293600000  Public=249400000 Private=312542857\n",
            "Envios=17900\t TOTAL=291600000  Public=247666667 Private=310428571\n",
            "Envios=18000\t TOTAL=290400000  Public=248266667 Private=308457143\n",
            "Envios=18100\t TOTAL=291600000  Public=246333333 Private=311000000\n",
            "Envios=18200\t TOTAL=289600000  Public=244600000 Private=308885714\n",
            "Envios=18300\t TOTAL=288400000  Public=243200000 Private=307771429\n",
            "Envios=18400\t TOTAL=286400000  Public=241066667 Private=305828571\n",
            "Envios=18500\t TOTAL=286000000  Public=244400000 Private=303828571\n",
            "Envios=18600\t TOTAL=285600000  Public=245600000 Private=302742857\n",
            "Envios=18700\t TOTAL=283600000  Public=243533333 Private=300771429\n",
            "Envios=18800\t TOTAL=284000000  Public=244266667 Private=301028571\n",
            "Envios=18900\t TOTAL=284400000  Public=247466667 Private=300228571\n",
            "Envios=19000\t TOTAL=282400000  Public=245600000 Private=298171429\n"
          ]
        }
      ],
      "source": [
        "# genero archivos con los  \"envios\" mejores\n",
        "# suba TODOS los archivos a Kaggle\n",
        "\n",
        "# ordeno por probabilidad descendente\n",
        "setorder(tb_prediccion, -prob)\n",
        "\n",
        "dir.create(\"kaggle\")\n",
        "resultados <- data.table()\n",
        "\n",
        "for (envios in PARAM$cortes) {\n",
        "\n",
        "  tb_prediccion[, Predicted := 0L] # seteo inicial a 0\n",
        "  tb_prediccion[1:envios, Predicted := 1L] # marco los primeros\n",
        "\n",
        "  archivo_kaggle <- paste0(\"./kaggle/KA\", PARAM$experimento, \"_\", envios, \".csv\")\n",
        "\n",
        "  # grabo el archivo\n",
        "  fwrite(tb_prediccion[, list(numero_de_cliente, Predicted)],\n",
        "    file= archivo_kaggle,\n",
        "    sep= \",\"\n",
        "  )\n",
        "\n",
        "  res <- realidad_evaluar( drealidad, tb_prediccion)\n",
        "  \n",
        "  resultados <- rbind(\n",
        "    resultados,\n",
        "    data.table(\n",
        "      clientes = envios,\n",
        "      ganancia_total = res$total,\n",
        "      ganancia_public = res$public,\n",
        "      ganancia_private = res$private\n",
        "    )\n",
        "  )\n",
        "\n",
        "  options(scipen = 999)\n",
        "  cat( \"Envios=\", envios, \"\\t\",\n",
        "    \" TOTAL=\", res$total,\n",
        "    \"  Public=\", res$public,\n",
        "    \" Private=\", res$private,\n",
        "    \"\\n\",\n",
        "    sep= \"\"\n",
        "  )\n",
        "\n",
        "}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 51,
      "metadata": {
        "vscode": {
          "languageId": "r"
        }
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Warning message:\n",
            "\"\u001b[1m\u001b[22mUsing `size` aesthetic for lines was deprecated in ggplot2 3.4.0.\n",
            "\u001b[36mℹ\u001b[39m Please use `linewidth` instead.\"\n"
          ]
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "plot without title"
            ]
          },
          "metadata": {
            "image/png": {
              "height": 420,
              "width": 420
            }
          },
          "output_type": "display_data"
        }
      ],
      "source": [
        "# pasamos a formato largo\n",
        "resultados_long <- melt(\n",
        "  resultados,\n",
        "  id.vars = \"clientes\",\n",
        "  measure.vars = c(\"ganancia_total\", \"ganancia_public\", \"ganancia_private\"),\n",
        "  variable.name = \"tipo\",\n",
        "  value.name = \"ganancia\"\n",
        ")\n",
        "\n",
        "# calcular máximos por tipo\n",
        "maximos <- resultados_long[, .SD[which.max(ganancia)], by = tipo]\n",
        "\n",
        "# crear etiquetas personalizadas para la leyenda\n",
        "etiquetas <- paste0(\n",
        "  maximos$tipo,\n",
        "  \" (envíos = \", maximos$clientes, \", máx = \", format(maximos$ganancia, big.mark = \",\"), \")\"\n",
        ")\n",
        "names(etiquetas) <- maximos$tipo\n",
        "\n",
        "# gráfico\n",
        "ggplot(resultados_long, aes(x = clientes, y = ganancia, color = tipo)) +\n",
        "  geom_line(size = 1) +\n",
        "  # agregar puntos en los máximos\n",
        "  geom_point(data = maximos, aes(x = clientes, y = ganancia, color = tipo), size = 3) +\n",
        "  labs(\n",
        "    title = \"Curvas de Ganancia\",\n",
        "    x = \"Clientes\",\n",
        "    y = \"Ganancia\",\n",
        "    color = \"Máximos\"\n",
        "  ) +\n",
        "  scale_color_manual(values = c(\"ganancia_total\" = \"steelblue\",\n",
        "                                \"ganancia_public\" = \"forestgreen\",\n",
        "                                \"ganancia_private\" = \"firebrick\"),\n",
        "                     labels = etiquetas) +\n",
        "  theme_minimal() +\n",
        "  theme(\n",
        "    plot.margin = margin(10, 10, 10, 10),  # top, right, bottom, left\n",
        "    legend.position = \"bottom\")+\n",
        "  guides(color = guide_legend(nrow = 3, byrow = TRUE))\n",
        "  #+ ggsave(\"curvas.png\", width = 10, height = 6)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {
        "id": "B9tB2X4439Hg",
        "vscode": {
          "languageId": "r"
        }
      },
      "outputs": [],
      "source": [
        "write_yaml( PARAM, file=\"PARAM.yml\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {
        "id": "9zA_W25c15DP",
        "vscode": {
          "languageId": "r"
        }
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "'lun sept 29 17:24:31 2025'"
            ],
            "text/latex": [
              "'lun sept 29 17:24:31 2025'"
            ],
            "text/markdown": [
              "'lun sept 29 17:24:31 2025'"
            ],
            "text/plain": [
              "[1] \"lun sept 29 17:24:31 2025\""
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "\n",
        "format(Sys.time(), \"%a %b %d %X %Y\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UdVZucdLHzZ0"
      },
      "source": [
        "Finalmente usted deberá cargar el resultado de su corrida en la Google Sheet Colaborativa,  hoja **TareaHogar04**\n",
        "<br> Siéntase libre de agregar las columnas que hagan falta a la planilla"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "vscode": {
          "languageId": "r"
        }
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Warning message in dir.create(\"kaggle_promediado\"):\n",
            "\"'kaggle_promediado' already exists\"\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Envios=0\t TOTAL=-20000  Public=0 Private=-28571.43\n",
            "Envios=100\t TOTAL=16400000  Public=19400000 Private=15114286\n",
            "Envios=200\t TOTAL=34400000  Public=36133333 Private=33657143\n",
            "Envios=300\t TOTAL=46800000  Public=42466667 Private=48657143\n",
            "Envios=400\t TOTAL=60800000  Public=51000000 Private=65000000\n",
            "Envios=500\t TOTAL=76400000  Public=59933333 Private=83457143\n",
            "Envios=600\t TOTAL=86400000  Public=60600000 Private=97457143\n",
            "Envios=700\t TOTAL=95600000  Public=66466667 Private=108085714\n",
            "Envios=800\t TOTAL=113600000  Public=77666667 Private=129000000\n",
            "Envios=900\t TOTAL=123600000  Public=88466667 Private=138657143\n",
            "Envios=1000\t TOTAL=140800000  Public=99733333 Private=158400000\n",
            "Envios=1100\t TOTAL=148400000  Public=102666667 Private=168000000\n",
            "Envios=1200\t TOTAL=158400000  Public=111333333 Private=178571429\n",
            "Envios=1300\t TOTAL=162000000  Public=119866667 Private=180057143\n",
            "Envios=1400\t TOTAL=172800000  Public=141466667 Private=186228571\n",
            "Envios=1500\t TOTAL=182000000  Public=152933333 Private=194457143\n",
            "Envios=1600\t TOTAL=192800000  Public=161133333 Private=206371429\n",
            "Envios=1700\t TOTAL=200400000  Public=159533333 Private=217914286\n",
            "Envios=1800\t TOTAL=208800000  Public=165466667 Private=227371429\n",
            "Envios=1900\t TOTAL=212400000  Public=168800000 Private=231085714\n",
            "Envios=2000\t TOTAL=217600000  Public=176933333 Private=235028571\n",
            "Envios=2100\t TOTAL=222000000  Public=183266667 Private=238600000\n",
            "Envios=2200\t TOTAL=228000000  Public=183666667 Private=247000000\n",
            "Envios=2300\t TOTAL=233200000  Public=186866667 Private=253057143\n",
            "Envios=2400\t TOTAL=236800000  Public=198200000 Private=253342857\n",
            "Envios=2500\t TOTAL=242000000  Public=201400000 Private=259400000\n",
            "Envios=2600\t TOTAL=244800000  Public=207400000 Private=260828571\n",
            "Envios=2700\t TOTAL=247600000  Public=208066667 Private=264542857\n",
            "Envios=2800\t TOTAL=253600000  Public=214266667 Private=270457143\n",
            "Envios=2900\t TOTAL=255600000  Public=215066667 Private=272971429\n",
            "Envios=3000\t TOTAL=259200000  Public=215666667 Private=277857143\n",
            "Envios=3100\t TOTAL=263600000  Public=226733333 Private=279400000\n",
            "Envios=3200\t TOTAL=271200000  Public=229866667 Private=288914286\n",
            "Envios=3300\t TOTAL=273200000  Public=232733333 Private=290542857\n",
            "Envios=3400\t TOTAL=275200000  Public=238533333 Private=290914286\n",
            "Envios=3500\t TOTAL=278000000  Public=238866667 Private=294771429\n",
            "Envios=3600\t TOTAL=287200000  Public=244666667 Private=305428571\n",
            "Envios=3700\t TOTAL=292400000  Public=245533333 Private=312485714\n",
            "Envios=3800\t TOTAL=292800000  Public=248533333 Private=311771429\n",
            "Envios=3900\t TOTAL=295600000  Public=246933333 Private=316457143\n",
            "Envios=4000\t TOTAL=295200000  Public=248000000 Private=315428571\n",
            "Envios=4100\t TOTAL=298800000  Public=251266667 Private=319171429\n",
            "Envios=4200\t TOTAL=299200000  Public=256733333 Private=317400000\n",
            "Envios=4300\t TOTAL=298800000  Public=254733333 Private=317685714\n",
            "Envios=4400\t TOTAL=297600000  Public=252866667 Private=316771429\n",
            "Envios=4500\t TOTAL=298800000  Public=253533333 Private=318200000\n",
            "Envios=4600\t TOTAL=299200000  Public=252066667 Private=319400000\n",
            "Envios=4700\t TOTAL=301200000  Public=253266667 Private=321742857\n",
            "Envios=4800\t TOTAL=304000000  Public=259266667 Private=323171429\n",
            "Envios=4900\t TOTAL=306800000  Public=265133333 Private=324657143\n",
            "Envios=5000\t TOTAL=308000000  Public=268200000 Private=325057143\n",
            "Envios=5100\t TOTAL=311600000  Public=271333333 Private=328857143\n",
            "Envios=5200\t TOTAL=314400000  Public=268800000 Private=333942857\n",
            "Envios=5300\t TOTAL=314000000  Public=266866667 Private=334200000\n",
            "Envios=5400\t TOTAL=317600000  Public=268200000 Private=338771429\n",
            "Envios=5500\t TOTAL=317200000  Public=267000000 Private=338714286\n",
            "Envios=5600\t TOTAL=316800000  Public=265000000 Private=339000000\n",
            "Envios=5700\t TOTAL=317200000  Public=265866667 Private=339200000\n",
            "Envios=5800\t TOTAL=317600000  Public=263666667 Private=340714286\n",
            "Envios=5900\t TOTAL=318800000  Public=267200000 Private=340914286\n",
            "Envios=6000\t TOTAL=317600000  Public=268066667 Private=338828571\n",
            "Envios=6100\t TOTAL=318000000  Public=269333333 Private=338857143\n",
            "Envios=6200\t TOTAL=320800000  Public=275533333 Private=340200000\n",
            "Envios=6300\t TOTAL=322000000  Public=273333333 Private=342857143\n",
            "Envios=6400\t TOTAL=322400000  Public=271266667 Private=344314286\n",
            "Envios=6500\t TOTAL=326000000  Public=274466667 Private=348085714\n",
            "Envios=6600\t TOTAL=329600000  Public=280466667 Private=350657143\n",
            "Envios=6700\t TOTAL=332400000  Public=286133333 Private=352228571\n",
            "Envios=6800\t TOTAL=334400000  Public=288733333 Private=353971429\n",
            "Envios=6900\t TOTAL=335600000  Public=286733333 Private=356542857\n",
            "Envios=7000\t TOTAL=336800000  Public=284933333 Private=359028571\n",
            "Envios=7100\t TOTAL=337200000  Public=285600000 Private=359314286\n",
            "Envios=7200\t TOTAL=338400000  Public=286333333 Private=360714286\n",
            "Envios=7300\t TOTAL=338000000  Public=286933333 Private=359885714\n",
            "Envios=7400\t TOTAL=339200000  Public=284400000 Private=362685714\n",
            "Envios=7500\t TOTAL=339600000  Public=284933333 Private=363028571\n",
            "Envios=7600\t TOTAL=339200000  Public=283200000 Private=363200000\n",
            "Envios=7700\t TOTAL=342000000  Public=286533333 Private=365771429\n",
            "Envios=7800\t TOTAL=341600000  Public=290000000 Private=363714286\n",
            "Envios=7900\t TOTAL=341200000  Public=287933333 Private=364028571\n",
            "Envios=8000\t TOTAL=340800000  Public=288666667 Private=363142857\n",
            "Envios=8100\t TOTAL=339600000  Public=289533333 Private=361057143\n",
            "Envios=8200\t TOTAL=339200000  Public=287533333 Private=361342857\n",
            "Envios=8300\t TOTAL=337200000  Public=285600000 Private=359314286\n",
            "Envios=8400\t TOTAL=337600000  Public=288866667 Private=358485714\n",
            "Envios=8500\t TOTAL=338000000  Public=289200000 Private=358914286\n",
            "Envios=8600\t TOTAL=340000000  Public=292866667 Private=360200000\n",
            "Envios=8700\t TOTAL=338800000  Public=290800000 Private=359371429\n",
            "Envios=8800\t TOTAL=340800000  Public=297133333 Private=359514286\n",
            "Envios=8900\t TOTAL=342000000  Public=300800000 Private=359657143\n",
            "Envios=9000\t TOTAL=341600000  Public=304066667 Private=357685714\n",
            "Envios=9100\t TOTAL=342000000  Public=309600000 Private=355885714\n",
            "Envios=9200\t TOTAL=344800000  Public=310000000 Private=359714286\n",
            "Envios=9300\t TOTAL=344400000  Public=308600000 Private=359742857\n",
            "Envios=9400\t TOTAL=344000000  Public=309200000 Private=358914286\n",
            "Envios=9500\t TOTAL=343600000  Public=307133333 Private=359228571\n",
            "Envios=9600\t TOTAL=342400000  Public=307266667 Private=357457143\n",
            "Envios=9700\t TOTAL=343600000  Public=308333333 Private=358714286\n",
            "Envios=9800\t TOTAL=344800000  Public=306266667 Private=361314286\n",
            "Envios=9900\t TOTAL=344400000  Public=309400000 Private=359400000\n",
            "Envios=10000\t TOTAL=343200000  Public=307600000 Private=358457143\n",
            "Envios=10100\t TOTAL=346000000  Public=308000000 Private=362285714\n",
            "Envios=10200\t TOTAL=344800000  Public=305933333 Private=361457143\n",
            "Envios=10300\t TOTAL=345200000  Public=306733333 Private=361685714\n",
            "Envios=10400\t TOTAL=347200000  Public=304533333 Private=365485714\n",
            "Envios=10500\t TOTAL=346800000  Public=304933333 Private=364742857\n",
            "Envios=10600\t TOTAL=346400000  Public=303000000 Private=365000000\n",
            "Envios=10700\t TOTAL=345200000  Public=301266667 Private=364028571\n",
            "Envios=10800\t TOTAL=345600000  Public=302466667 Private=364085714\n",
            "Envios=10900\t TOTAL=344400000  Public=300466667 Private=363228571\n",
            "Envios=11000\t TOTAL=344800000  Public=303866667 Private=362342857\n",
            "Envios=11100\t TOTAL=346800000  Public=301866667 Private=366057143\n",
            "Envios=11200\t TOTAL=348000000  Public=307933333 Private=365171429\n",
            "Envios=11300\t TOTAL=349200000  Public=306000000 Private=367714286\n",
            "Envios=11400\t TOTAL=348000000  Public=304133333 Private=366800000\n",
            "Envios=11500\t TOTAL=348400000  Public=307400000 Private=365971429\n",
            "Envios=11600\t TOTAL=346400000  Public=305666667 Private=363857143\n",
            "Envios=11700\t TOTAL=345200000  Public=306266667 Private=361885714\n",
            "Envios=11800\t TOTAL=344000000  Public=304466667 Private=360942857\n",
            "Envios=11900\t TOTAL=342000000  Public=302600000 Private=358885714\n",
            "Envios=12000\t TOTAL=344000000  Public=305866667 Private=360342857\n",
            "Envios=12100\t TOTAL=344400000  Public=309200000 Private=359485714\n",
            "Envios=12200\t TOTAL=344800000  Public=312333333 Private=358714286\n",
            "Envios=12300\t TOTAL=347600000  Public=317866667 Private=360342857\n",
            "Envios=12400\t TOTAL=345600000  Public=315866667 Private=358342857\n",
            "Envios=12500\t TOTAL=344400000  Public=314200000 Private=357342857\n",
            "Envios=12600\t TOTAL=344800000  Public=314466667 Private=357800000\n",
            "Envios=12700\t TOTAL=345200000  Public=314466667 Private=358371429\n",
            "Envios=12800\t TOTAL=347200000  Public=317866667 Private=359771429\n",
            "Envios=12900\t TOTAL=346000000  Public=316200000 Private=358771429\n",
            "Envios=13000\t TOTAL=344800000  Public=316600000 Private=356885714\n",
            "Envios=13100\t TOTAL=343600000  Public=314533333 Private=356057143\n",
            "Envios=13200\t TOTAL=342400000  Public=312466667 Private=355228571\n",
            "Envios=13300\t TOTAL=341200000  Public=310733333 Private=354257143\n",
            "Envios=13400\t TOTAL=341600000  Public=311000000 Private=354714286\n",
            "Envios=13500\t TOTAL=341200000  Public=314333333 Private=352714286\n",
            "Envios=13600\t TOTAL=340800000  Public=315133333 Private=351800000\n",
            "Envios=13700\t TOTAL=339600000  Public=316066667 Private=349685714\n",
            "Envios=13800\t TOTAL=340000000  Public=316600000 Private=350028571\n",
            "Envios=13900\t TOTAL=338800000  Public=314800000 Private=349085714\n",
            "Envios=14000\t TOTAL=336800000  Public=312733333 Private=347114286\n",
            "Envios=14100\t TOTAL=336400000  Public=313733333 Private=346114286\n",
            "Envios=14200\t TOTAL=336800000  Public=311400000 Private=347685714\n",
            "Envios=14300\t TOTAL=337200000  Public=314800000 Private=346800000\n",
            "Envios=14400\t TOTAL=336800000  Public=312800000 Private=347085714\n",
            "Envios=14500\t TOTAL=336400000  Public=313200000 Private=346342857\n",
            "Envios=14600\t TOTAL=335200000  Public=311066667 Private=345542857\n",
            "Envios=14700\t TOTAL=334000000  Public=309066667 Private=344685714\n",
            "Envios=14800\t TOTAL=332000000  Public=307266667 Private=342600000\n",
            "Envios=14900\t TOTAL=330800000  Public=307600000 Private=340742857\n",
            "Envios=15000\t TOTAL=328800000  Public=305200000 Private=338914286\n",
            "Envios=15100\t TOTAL=328400000  Public=303666667 Private=339000000\n",
            "Envios=15200\t TOTAL=327200000  Public=304400000 Private=336971429\n",
            "Envios=15300\t TOTAL=326800000  Public=304933333 Private=336171429\n",
            "Envios=15400\t TOTAL=324800000  Public=303133333 Private=334085714\n",
            "Envios=15500\t TOTAL=322800000  Public=301066667 Private=332114286\n",
            "Envios=15600\t TOTAL=321600000  Public=301933333 Private=330028571\n",
            "Envios=15700\t TOTAL=322000000  Public=302666667 Private=330285714\n",
            "Envios=15800\t TOTAL=320000000  Public=300933333 Private=328171429\n",
            "Envios=15900\t TOTAL=321200000  Public=301866667 Private=329485714\n",
            "Envios=16000\t TOTAL=320000000  Public=299400000 Private=328828571\n",
            "Envios=16100\t TOTAL=318000000  Public=297066667 Private=326971429\n",
            "Envios=16200\t TOTAL=318400000  Public=297600000 Private=327314286\n",
            "Envios=16300\t TOTAL=316400000  Public=296000000 Private=325142857\n",
            "Envios=16400\t TOTAL=315200000  Public=294200000 Private=324200000\n",
            "Envios=16500\t TOTAL=314800000  Public=292266667 Private=324457143\n",
            "Envios=16600\t TOTAL=312800000  Public=290133333 Private=322514286\n",
            "Envios=16700\t TOTAL=312400000  Public=288066667 Private=322828571\n",
            "Envios=16800\t TOTAL=310400000  Public=286133333 Private=320800000\n",
            "Envios=16900\t TOTAL=308400000  Public=284066667 Private=318828571\n",
            "Envios=17000\t TOTAL=307200000  Public=281666667 Private=318142857\n",
            "Envios=17100\t TOTAL=307600000  Public=281600000 Private=318742857\n",
            "Envios=17200\t TOTAL=306400000  Public=279866667 Private=317771429\n",
            "Envios=17300\t TOTAL=305200000  Public=277266667 Private=317171429\n",
            "Envios=17400\t TOTAL=304800000  Public=275933333 Private=317171429\n",
            "Envios=17500\t TOTAL=305200000  Public=276800000 Private=317371429\n",
            "Envios=17600\t TOTAL=304000000  Public=274733333 Private=316542857\n",
            "Envios=17700\t TOTAL=303600000  Public=275533333 Private=315628571\n",
            "Envios=17800\t TOTAL=302400000  Public=273733333 Private=314685714\n",
            "Envios=17900\t TOTAL=302800000  Public=274133333 Private=315085714\n",
            "Envios=18000\t TOTAL=301600000  Public=272200000 Private=314200000\n",
            "Envios=18100\t TOTAL=300400000  Public=270400000 Private=313257143\n",
            "Envios=18200\t TOTAL=300800000  Public=270400000 Private=313828571\n",
            "Envios=18300\t TOTAL=298800000  Public=268666667 Private=311714286\n",
            "Envios=18400\t TOTAL=296800000  Public=266466667 Private=309800000\n",
            "Envios=18500\t TOTAL=295600000  Public=263933333 Private=309171429\n",
            "Envios=18600\t TOTAL=293600000  Public=262000000 Private=307142857\n",
            "Envios=18700\t TOTAL=291600000  Public=260133333 Private=305085714\n",
            "Envios=18800\t TOTAL=290400000  Public=258333333 Private=304142857\n",
            "Envios=18900\t TOTAL=289200000  Public=256133333 Private=303371429\n",
            "Envios=19000\t TOTAL=290400000  Public=254000000 Private=306000000\n"
          ]
        }
      ],
      "source": [
        "# Definir las 5 semillas fijas para el ensemble\n",
        "semillas_fijas <- c(200003,300007,400009,500009,600011)\n",
        "\n",
        "# Inicializar una lista para almacenar las predicciones de cada modelo\n",
        "list_predicciones <- list()\n",
        "\n",
        "# Iniciar el bucle para entrenar y predecir con cada una de las semillas\n",
        "for (semilla in semillas_fijas) {\n",
        "\n",
        "  # Asignar la semilla actual a los parámetros del modelo\n",
        "  param_normalizado$seed <- semilla\n",
        "  \n",
        "  # Entrenar el modelo LightGBM\n",
        "  modelo_temp <- lgb.train(\n",
        "    data = dtrain_final,\n",
        "    param = param_normalizado\n",
        "  )\n",
        "  \n",
        "  # Preparar los datos sin clase para la predicción\n",
        "  dfuture <- dataset[foto_mes %in% PARAM$future]\n",
        "  \n",
        "  # Realizar la predicción con el modelo actual\n",
        "  prediccion_temp <- predict(\n",
        "    modelo_temp,\n",
        "    data.matrix(dfuture[, campos_buenos, with = FALSE])\n",
        "  )\n",
        "  \n",
        "  # Guardar la predicción en la lista\n",
        "  list_predicciones[[length(list_predicciones) + 1]] <- prediccion_temp\n",
        "}\n",
        "\n",
        "# Unir las predicciones de todos los modelos en una sola matriz\n",
        "matriz_predicciones <- do.call(cbind, list_predicciones)\n",
        "\n",
        "# Calcular el promedio de las predicciones para obtener el resultado final del ensemble\n",
        "prediccion_ensemble <- rowMeans(matriz_predicciones)\n",
        "\n",
        "# Ahora, la variable 'prediccion_ensemble' contiene el resultado final del ensemble.\n",
        "# A partir de aquí, el código continúa usando esta nueva variable.\n",
        "\n",
        "# Inicilizo el dataset drealidad\n",
        "drealidad <- realidad_inicializar( dfuture, PARAM)\n",
        "\n",
        "# Crear la tabla de predicción\n",
        "tb_prediccion <- dfuture[, list(numero_de_cliente, foto_mes)]\n",
        "tb_prediccion[, prob := prediccion_ensemble ]\n",
        "\n",
        "# Generar los \"envios\" para los mejores resultados\n",
        "# Ordenar por probabilidad descendente\n",
        "setorder(tb_prediccion, -prob)\n",
        "\n",
        "# Crear el directorio 'kaggle' si no existe\n",
        "dir.create(\"kaggle_promediado\")\n",
        "\n",
        "for (envios in PARAM$cortes) {\n",
        "\n",
        "  tb_prediccion[, Predicted := 0L] # seteo inicial a 0\n",
        "  tb_prediccion[1:envios, Predicted := 1L] # marcar los primeros envíos\n",
        "  \n",
        "  # Nombre del archivo para Kaggle\n",
        "  archivo_kaggle <- paste0(\"./kaggle_promediado/KA\", PARAM$experimento, \"_\", envios, \".csv\")\n",
        "  \n",
        "  # Guardar el archivo CSV\n",
        "  fwrite(tb_prediccion[, list(numero_de_cliente, Predicted)],\n",
        "         file = archivo_kaggle,\n",
        "         sep = \",\"\n",
        "  )\n",
        "  \n",
        "  # Evaluar el resultado\n",
        "  res <- realidad_evaluar( drealidad, tb_prediccion)\n",
        "  \n",
        "  # Imprimir los resultados en la consola\n",
        "  options(scipen = 999)\n",
        "  cat( \"Envios=\", envios, \"\\t\",\n",
        "       \" TOTAL=\", res$total,\n",
        "       \"  Public=\", res$public,\n",
        "       \" Private=\", res$private,\n",
        "       \"\\n\",\n",
        "       sep= \"\"\n",
        "  )\n",
        "}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 53,
      "metadata": {
        "vscode": {
          "languageId": "r"
        }
      },
      "outputs": [
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "plot without title"
            ]
          },
          "metadata": {
            "image/png": {
              "height": 420,
              "width": 420
            }
          },
          "output_type": "display_data"
        }
      ],
      "source": [
        "# pasamos a formato largo\n",
        "resultados_long <- melt(\n",
        "  resultados,\n",
        "  id.vars = \"clientes\",\n",
        "  measure.vars = c(\"ganancia_total\", \"ganancia_public\", \"ganancia_private\"),\n",
        "  variable.name = \"tipo\",\n",
        "  value.name = \"ganancia\"\n",
        ")\n",
        "\n",
        "# calcular máximos por tipo\n",
        "maximos <- resultados_long[, .SD[which.max(ganancia)], by = tipo]\n",
        "\n",
        "# crear etiquetas personalizadas para la leyenda\n",
        "etiquetas <- paste0(\n",
        "  maximos$tipo,\n",
        "  \" (envíos = \", maximos$clientes, \", máx = \", format(maximos$ganancia, big.mark = \",\"), \")\"\n",
        ")\n",
        "names(etiquetas) <- maximos$tipo\n",
        "\n",
        "# gráfico\n",
        "ggplot(resultados_long, aes(x = clientes, y = ganancia, color = tipo)) +\n",
        "  geom_line(size = 1) +\n",
        "  # agregar puntos en los máximos\n",
        "  geom_point(data = maximos, aes(x = clientes, y = ganancia, color = tipo), size = 3) +\n",
        "  labs(\n",
        "    title = \"Curvas de Ganancia\",\n",
        "    x = \"Clientes\",\n",
        "    y = \"Ganancia\",\n",
        "    color = \"Máximos\"\n",
        "  ) +\n",
        "  scale_color_manual(values = c(\"ganancia_total\" = \"steelblue\",\n",
        "                                \"ganancia_public\" = \"forestgreen\",\n",
        "                                \"ganancia_private\" = \"firebrick\"),\n",
        "                     labels = etiquetas) +\n",
        "  theme_minimal() +\n",
        "  theme(\n",
        "    plot.margin = margin(10, 10, 10, 10),  # top, right, bottom, left\n",
        "    legend.position = \"bottom\")+\n",
        "  guides(color = guide_legend(nrow = 3, byrow = TRUE))\n",
        "  #+ ggsave(\"curvas.png\", width = 10, height = 6)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "R",
      "language": "R",
      "name": "ir"
    },
    "language_info": {
      "codemirror_mode": "r",
      "file_extension": ".r",
      "mimetype": "text/x-r-source",
      "name": "R",
      "pygments_lexer": "r",
      "version": "4.4.3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
