{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0cEmzeUKFkPh"
      },
      "source": [
        "# Tarea para el Hogar 04"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DenyKXkiJ5JN"
      },
      "source": [
        "##  1. Big Picture"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l-K2_ZsZGrVD"
      },
      "source": [
        "LightGBM es el algoritmo estado del arte para datasets estructurados.\n",
        "<br> La Bayesian Optimization es el estado del arte para optimización de hiperparámetros\n",
        "<br> Las soluciones a las tres competencias de la asignatura contendrán LightGBMs y Bayesian Optimizations\n",
        "<br> LightGBM ha aumentado en forma no darwiniana sus hiperparámetros en los últimos ocho años; no todos los existentes son útiles.\n",
        "<br> Es necesario lograr entender cuales son los hiperparámetros relevantes de LightGBM"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K9GkTOk5J9t3"
      },
      "source": [
        "## 2. Hiperparámetros del LightGBM"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VmEFy0ukKL5T"
      },
      "source": [
        "Los objetivos de esta tarea son:\n",
        "\n",
        "\n",
        "*   Aumentar la rentabilidad de la campaña de marketing de retención proactiva de clientes.\n",
        "*   Generar un mejor modelo optimizando sus hiperparámetros\n",
        "*   Conceptual : investigar los mas relevantes hiperparámetros de LightGBM\n",
        "*   Familiarizarse con la Bayesian Optimization, sus largos tiempos de corrida y opciones para reducirlos\n",
        "*   Familiarizarse con el uso de máquinas virtuales de Google Colab\n",
        "*   Ver un pipeline completo de optimización de hiperparámetros y puesta en producción"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5yvlS6JQLRMd"
      },
      "source": [
        "LightGBM cuenta con mas de 60 hiperparámetros, siendo posible utilizar 40 al mismo tiempo, aunque no razonable.\n",
        "<br> La documentación oficial de los hiperparámetros de LightGBM es  https://lightgbm.readthedocs.io/en/latest/Parameters.html#core-parameters\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eydI4YNAsFaf"
      },
      "source": [
        "Se lo alerta sobre que una Optimizacion Bayesiana lleva varias horas de corrida, y usted deberá correr VARIAS optimizaciones para descubrir cuales parámetros conviene optimizar.\n",
        "<br> A pesar que la próxima clase es recien en viernes 01 de agosto, inicie la tarea con tiempo, aprenda a planificar estratégicamente sus corridas como un@ científ@  de datos."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RzU4S0SeMcpp"
      },
      "source": [
        "Es necesario investigar cuales son los hiperparámetros de LightGBM que vale la pena optimizar en una Bayesian Optimization, ya que los realmente utiles son apenas un reducido subconjunto.\n",
        "<br>Usted deberá investigar cuales son los hiperparámetros mas relevantes de LightGBM, su primer alternativa es preguntándole a su amigo con capacidades especiales ChatGPT o sus endogámicos familiares Claude, DeepSeek, Gemini, Grok, etc\n",
        "<br> La segunda alternativa es la propia documentación de LightGBM  https://lightgbm.readthedocs.io/en/latest/Parameters-Tuning.html\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LNptUgI_NWWG"
      },
      "source": [
        "Adicionalmente podra buscar información como la que proveen esta diminuta muestra aleatoria de artículos ligeros:\n",
        "*  https://medium.com/@sarahzouinina/a-deep-dive-into-lightgbm-how-to-choose-and-tune-parameters-7c584945842e\n",
        "*  https://www.kaggle.com/code/somang1418/tuning-hyperparameters-under-10-minutes-lgbm\n",
        "*  https://towardsdatascience.com/beginners-guide-to-the-must-know-lightgbm-hyperparameters-a0005a812702/\n",
        "\n",
        "\n",
        "<br>  La muestra anterior se brinda a modo de ejemplo, usted deberá buscar muuuuchas  fuentes adicionales de información\n",
        "<br> Tenga presente que LightGBM es el estado del arte en modelado predictivo para datasets estructurado, que son el 90% del trabajo del 95% de los Data Scientists en Argentina."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WpUThBojODyK"
      },
      "source": [
        "El desafío de esta tarea es:\n",
        "* Qué hiperparparámetros conviene optimizar?  Las recomendaciones de los artículos ligeros es siempre sensata?  Sus autores realmente hicieron experimentos o son siemplemente escritores de entretenimiento carente de base científica?\n",
        "* Elegidos los hiperparámetros, cual es el  <desde, hasta> que se debe utilizar en la Bayesian Optimization ?\n",
        "* Realmente vale la pena optimizar 10 o 16 hiperparámetros al mismo tiempo ?  No resulta contraproducente una búsqueda en un espacio de tal alta dimensionalidad ?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PX0qg_c0yqob"
      },
      "source": [
        "#### 2.1  Seteo del ambiente en Google Colab"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NGY7H9xza7Zr"
      },
      "source": [
        "Esta parte se debe correr con el runtime en Python3\n",
        "<br>Ir al menu, Runtime -> Change Runtime Type -> Runtime type ->  **Python 3**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7PupIBNba7Zr"
      },
      "source": [
        "Conectar la virtual machine donde esta corriendo Google Colab con el  Google Drive, para poder tener persistencia de archivos"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9LpZCst5a7Zs",
        "vscode": {
          "languageId": "r"
        }
      },
      "outputs": [],
      "source": [
        "# primero establecer el Runtime de Python 3\n",
        "from google.colab import drive\n",
        "drive.mount('/content/.drive')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JYC_F-wla7Zs"
      },
      "source": [
        "Para correr la siguiente celda es fundamental en Arranque en Frio haber copiado el archivo kaggle.json al Google Drive, en la carpeta indicada en el instructivo\n",
        "\n",
        "<br>los siguientes comando estan en shell script de Linux\n",
        "*   Crear las carpetas en el Google Drive\n",
        "*   \"instalar\" el archivo kaggle.json desde el Google Drive a la virtual machine para que pueda ser utilizado por la libreria  kaggle de Python\n",
        "*   Bajar el  **dataset_pequeno**  al  Google Drive  y tambien al disco local de la virtual machine que esta corriendo Google Colab\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XWLelftXa7Zt",
        "vscode": {
          "languageId": "r"
        }
      },
      "outputs": [],
      "source": [
        "%%shell\n",
        "\n",
        "mkdir -p \"/content/.drive/My Drive/dmeyf\"\n",
        "mkdir -p \"/content/buckets\"\n",
        "ln -s \"/content/.drive/My Drive/dmeyf\" /content/buckets/b1\n",
        "\n",
        "\n",
        "mkdir -p /content/buckets/b1/exp\n",
        "mkdir -p /content/buckets/b1/datasets\n",
        "mkdir -p /content/datasets\n",
        "\n",
        "\n",
        "\n",
        "archivo_origen=\"https://storage.googleapis.com/open-courses/dmeyf2025-e4a2/competencia_01_crudo.csv\"\n",
        "archivo_destino=\"/content/datasets/competencia_01_crudo.csv\"\n",
        "archivo_destino_bucket=\"/content/buckets/b1/datasets/competencia_01_crudo.csv\"\n",
        "\n",
        "if ! test -f $archivo_destino_bucket; then\n",
        "  wget  $archivo_origen  -O $archivo_destino_bucket\n",
        "fi\n",
        "\n",
        "\n",
        "if ! test -f $archivo_destino; then\n",
        "  cp  $archivo_destino_bucket  $archivo_destino\n",
        "fi\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dseB4qb9RqUb"
      },
      "source": [
        "### Generacion de la clase_ternaria"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LCEnE_02RuIQ"
      },
      "source": [
        "Esta parte se debe correr con el runtime en lenguaje **R** Ir al menu, Runtime -> Change Runtime Tipe -> Runtime type -> R"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "P863YZB9R1Ua",
        "vscode": {
          "languageId": "r"
        }
      },
      "outputs": [],
      "source": [
        "require( \"data.table\" )\n",
        "\n",
        "# leo el dataset\n",
        "dataset <- fread(\"../../Competencia 01/competencia_01_crudo.csv\" )\n",
        "\n",
        "# calculo el periodo0 consecutivo\n",
        "dsimple <- dataset[, list(\n",
        "    \"pos\" = .I,\n",
        "    numero_de_cliente,\n",
        "    periodo0 = as.integer(foto_mes/100)*12 +  foto_mes%%100 ) ]\n",
        "\n",
        "\n",
        "# ordeno\n",
        "setorder( dsimple, numero_de_cliente, periodo0 )\n",
        "\n",
        "# calculo topes\n",
        "periodo_ultimo <- dsimple[, max(periodo0) ]\n",
        "periodo_anteultimo <- periodo_ultimo - 1\n",
        "\n",
        "\n",
        "# calculo los leads de orden 1 y 2\n",
        "dsimple[, c(\"periodo1\", \"periodo2\") :=\n",
        "    shift(periodo0, n=1:2, fill=NA, type=\"lead\"),  numero_de_cliente ]\n",
        "\n",
        "# assign most common class values = \"CONTINUA\"\n",
        "dsimple[ periodo0 < periodo_anteultimo, clase_ternaria := \"CONTINUA\" ]\n",
        "\n",
        "# calculo BAJA+1\n",
        "dsimple[ periodo0 < periodo_ultimo &\n",
        "    ( is.na(periodo1) | periodo0 + 1 < periodo1 ),\n",
        "    clase_ternaria := \"BAJA+1\" ]\n",
        "\n",
        "# calculo BAJA+2\n",
        "dsimple[ periodo0 < periodo_anteultimo & (periodo0+1 == periodo1 )\n",
        "    & ( is.na(periodo2) | periodo0 + 2 < periodo2 ),\n",
        "    clase_ternaria := \"BAJA+2\" ]\n",
        "\n",
        "\n",
        "# pego el resultado en el dataset original y grabo\n",
        "setorder( dsimple, pos )\n",
        "dataset[, clase_ternaria := dsimple$clase_ternaria ]\n",
        "\n",
        "fwrite( dataset,\n",
        "    file =  \"./competencia_01.csv.gz\",\n",
        "    sep = \",\"\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "S3hL7tv8W4rn",
        "vscode": {
          "languageId": "r"
        }
      },
      "outputs": [],
      "source": [
        "setorder( dataset, foto_mes, clase_ternaria, numero_de_cliente)\n",
        "dataset[, .N, list(foto_mes, clase_ternaria)]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oSKhZRToy2F7"
      },
      "source": [
        "### 2.2 Optimizacion Hiperparámetros"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2kwPpHAtSmix"
      },
      "source": [
        "Esta parte se debe correr con el runtime en lenguaje R Ir al menu, Runtime -> Change Runtime Type -> Runtime type -> R"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xp4-Bj3aYI8d"
      },
      "source": [
        "### 2.2.1 Inicio"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zy8YTZfESxeJ"
      },
      "source": [
        "limpio el ambiente de R"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "gBq__iAdQliq",
        "vscode": {
          "languageId": "r"
        }
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "'jue oct 02 17:46:19 2025'"
            ],
            "text/latex": [
              "'jue oct 02 17:46:19 2025'"
            ],
            "text/markdown": [
              "'jue oct 02 17:46:19 2025'"
            ],
            "text/plain": [
              "[1] \"jue oct 02 17:46:19 2025\""
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "format(Sys.time(), \"%a %b %d %X %Y\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "7rdVrBojS1IV",
        "vscode": {
          "languageId": "r"
        }
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<table class=\"dataframe\">\n",
              "<caption>A matrix: 2 × 6 of type dbl</caption>\n",
              "<thead>\n",
              "\t<tr><th></th><th scope=col>used</th><th scope=col>(Mb)</th><th scope=col>gc trigger</th><th scope=col>(Mb)</th><th scope=col>max used</th><th scope=col>(Mb)</th></tr>\n",
              "</thead>\n",
              "<tbody>\n",
              "\t<tr><th scope=row>Ncells</th><td> 650997</td><td>34.8</td><td>1431192</td><td>76.5</td><td>1431192</td><td>76.5</td></tr>\n",
              "\t<tr><th scope=row>Vcells</th><td>1204301</td><td> 9.2</td><td>8388608</td><td>64.0</td><td>2051452</td><td>15.7</td></tr>\n",
              "</tbody>\n",
              "</table>\n"
            ],
            "text/latex": [
              "A matrix: 2 × 6 of type dbl\n",
              "\\begin{tabular}{r|llllll}\n",
              "  & used & (Mb) & gc trigger & (Mb) & max used & (Mb)\\\\\n",
              "\\hline\n",
              "\tNcells &  650997 & 34.8 & 1431192 & 76.5 & 1431192 & 76.5\\\\\n",
              "\tVcells & 1204301 &  9.2 & 8388608 & 64.0 & 2051452 & 15.7\\\\\n",
              "\\end{tabular}\n"
            ],
            "text/markdown": [
              "\n",
              "A matrix: 2 × 6 of type dbl\n",
              "\n",
              "| <!--/--> | used | (Mb) | gc trigger | (Mb) | max used | (Mb) |\n",
              "|---|---|---|---|---|---|---|\n",
              "| Ncells |  650997 | 34.8 | 1431192 | 76.5 | 1431192 | 76.5 |\n",
              "| Vcells | 1204301 |  9.2 | 8388608 | 64.0 | 2051452 | 15.7 |\n",
              "\n"
            ],
            "text/plain": [
              "       used    (Mb) gc trigger (Mb) max used (Mb)\n",
              "Ncells  650997 34.8 1431192    76.5 1431192  76.5\n",
              "Vcells 1204301  9.2 8388608    64.0 2051452  15.7"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# limpio la memoria\n",
        "rm(list=ls(all.names=TRUE)) # remove all objects\n",
        "gc(full=TRUE, verbose=FALSE) # garbage collection"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kuPfQ7ksjwW3"
      },
      "source": [
        "### 2.2.2 Carga de Librerias"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B8BaSFlGfvma"
      },
      "source": [
        "Esta parte lleva varios minutos la primera vez en Google Colab"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "lVyxLaJ1j1J_",
        "vscode": {
          "languageId": "r"
        }
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Cargando paquete requerido: data.table\n",
            "\n",
            "Cargando paquete requerido: parallel\n",
            "\n",
            "Cargando paquete requerido: R.utils\n",
            "\n",
            "Cargando paquete requerido: R.oo\n",
            "\n",
            "Cargando paquete requerido: R.methodsS3\n",
            "\n",
            "R.methodsS3 v1.8.2 (2022-06-13 22:00:14 UTC) successfully loaded. See ?R.methodsS3 for help.\n",
            "\n",
            "R.oo v1.27.1 (2025-05-02 21:00:05 UTC) successfully loaded. See ?R.oo for help.\n",
            "\n",
            "\n",
            "Adjuntando el paquete: 'R.oo'\n",
            "\n",
            "\n",
            "The following object is masked from 'package:R.methodsS3':\n",
            "\n",
            "    throw\n",
            "\n",
            "\n",
            "The following objects are masked from 'package:methods':\n",
            "\n",
            "    getClasses, getMethods\n",
            "\n",
            "\n",
            "The following objects are masked from 'package:base':\n",
            "\n",
            "    attach, detach, load, save\n",
            "\n",
            "\n",
            "R.utils v2.13.0 (2025-02-24 21:20:02 UTC) successfully loaded. See ?R.utils for help.\n",
            "\n",
            "\n",
            "Adjuntando el paquete: 'R.utils'\n",
            "\n",
            "\n",
            "The following object is masked from 'package:utils':\n",
            "\n",
            "    timestamp\n",
            "\n",
            "\n",
            "The following objects are masked from 'package:base':\n",
            "\n",
            "    cat, commandArgs, getOption, isOpen, nullfile, parse, use, warnings\n",
            "\n",
            "\n",
            "Cargando paquete requerido: primes\n",
            "\n",
            "Cargando paquete requerido: rlist\n",
            "\n",
            "Cargando paquete requerido: yaml\n",
            "\n",
            "Cargando paquete requerido: lightgbm\n",
            "\n",
            "Cargando paquete requerido: DiceKriging\n",
            "\n",
            "Cargando paquete requerido: mlrMBO\n",
            "\n",
            "Cargando paquete requerido: mlr\n",
            "\n",
            "Cargando paquete requerido: ParamHelpers\n",
            "\n",
            "\n",
            "Adjuntando el paquete: 'ParamHelpers'\n",
            "\n",
            "\n",
            "The following object is masked from 'package:R.utils':\n",
            "\n",
            "    isVector\n",
            "\n",
            "\n",
            "\n",
            "Adjuntando el paquete: 'mlr'\n",
            "\n",
            "\n",
            "The following objects are masked from 'package:R.utils':\n",
            "\n",
            "    resample, setThreshold\n",
            "\n",
            "\n",
            "Cargando paquete requerido: smoof\n",
            "\n",
            "Cargando paquete requerido: checkmate\n",
            "\n",
            "\n",
            "Adjuntando el paquete: 'checkmate'\n",
            "\n",
            "\n",
            "The following object is masked from 'package:DiceKriging':\n",
            "\n",
            "    checkNames\n",
            "\n",
            "\n",
            "The following object is masked from 'package:R.utils':\n",
            "\n",
            "    asInt\n",
            "\n",
            "\n",
            "\n",
            "Adjuntando el paquete: 'smoof'\n",
            "\n",
            "\n",
            "The following objects are masked from 'package:R.oo':\n",
            "\n",
            "    getDescription, getName\n",
            "\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# cargo las librerias que necesito\n",
        "if(!require(\"data.table\")) install.packages(\"data.table\")\n",
        "require(\"data.table\")\n",
        "\n",
        "if(!require(\"parallel\")) install.packages(\"parallel\")\n",
        "require(\"parallel\")\n",
        "\n",
        "if(!require(\"R.utils\")) install.packages(\"R.utils\")\n",
        "require(\"R.utils\")\n",
        "\n",
        "if( !require(\"primes\") ) install.packages(\"primes\")\n",
        "require(\"primes\")\n",
        "\n",
        "if( !require(\"utils\") ) install.packages(\"utils\")\n",
        "require(\"utils\")\n",
        "\n",
        "if( !require(\"rlist\") ) install.packages(\"rlist\")\n",
        "require(\"rlist\")\n",
        "\n",
        "if( !require(\"yaml\")) install.packages(\"yaml\")\n",
        "require(\"yaml\")\n",
        "\n",
        "if( !require(\"lightgbm\") ) install.packages(\"lightgbm\")\n",
        "require(\"lightgbm\")\n",
        "\n",
        "if( !require(\"DiceKriging\") ) install.packages(\"DiceKriging\")\n",
        "require(\"DiceKriging\")\n",
        "\n",
        "if( !require(\"mlrMBO\") ) install.packages(\"mlrMBO\")\n",
        "require(\"mlrMBO\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Iz-6Qt6BUaA3"
      },
      "source": [
        "### 2.2.3 Definicion de Parametros"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cOdlKd7lUm2I"
      },
      "source": [
        "aqui debe cargar SU semilla primigenia\n",
        "<br>recuerde cambiar el numero de experimento en cada corrida nueva"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "ASYkebOu2mF6",
        "vscode": {
          "languageId": "r"
        }
      },
      "outputs": [],
      "source": [
        "PARAM <- list()\n",
        "PARAM$experimento <- \"4940_V5\"\n",
        "PARAM$semilla_primigenia <- 200003"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "ezOhQdbA293o",
        "vscode": {
          "languageId": "r"
        }
      },
      "outputs": [],
      "source": [
        "# training y future\n",
        "PARAM$train <- c(2021, 202102)\n",
        "PARAM$train_final <- c(2021, 202102)\n",
        "PARAM$future <- c(202104)\n",
        "PARAM$semilla_kaggle <- 314159 #Semilla para el modelo final que va a Kaggle, primeros números de pi que sean primos.\n",
        "PARAM$cortes <- seq(4000, 19000, by= 100)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "jtB0Lub42rHO",
        "vscode": {
          "languageId": "r"
        }
      },
      "outputs": [],
      "source": [
        "# un undersampling de 0.1  toma solo el 10% de los CONTINUA\n",
        "# undersampling de 1.0  implica tomar TODOS los datos\n",
        "\n",
        "PARAM$trainingstrategy$undersampling <- 0.5"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "OFxm-xiNUOJX",
        "vscode": {
          "languageId": "r"
        }
      },
      "outputs": [],
      "source": [
        "# Parametros LightGBM\n",
        "\n",
        "PARAM$hyperparametertuning$xval_folds <- 5\n",
        "\n",
        "# parametros fijos del LightGBM que se pisaran con la parte variable de la BO\n",
        "PARAM$lgbm$param_fijos <-  list(\n",
        "  boosting= \"gbdt\", # puede ir dart, ni pruebe random_forest\n",
        "  objective= \"binary\", #default regression\n",
        "  metric= \"auc\", # default \"\" \n",
        "  first_metric_only= FALSE, # default FALSE\n",
        "  boost_from_average= TRUE, # default TRUE\n",
        "  feature_pre_filter= FALSE, # default TRUE\n",
        "  force_row_wise= TRUE, # para reducir warnings\n",
        "  verbosity= -100,\n",
        "\n",
        "  seed= PARAM$semilla_primigenia\n",
        ")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D5Yj-JV4yvOt"
      },
      "source": [
        "Aqui se definen los hiperparámetros de LightGBM que participan de la Bayesian Optimization\n",
        "- si es un numero entero debe ir makeIntegerParam\n",
        "- si es un numero real (con decimales) debe ir makeNumericParam\n",
        "\n",
        "Es muy importante leer cuales son un lower y upper permitidos y además razonables"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "jENpR26ZyuS8",
        "vscode": {
          "languageId": "r"
        }
      },
      "outputs": [],
      "source": [
        "# Aqui se cargan los bordes de los hiperparametros de la BO\n",
        "PARAM$hypeparametertuning$hs <- makeParamSet(\n",
        "  makeIntegerParam(\"num_iterations\", lower= 50L, upper= 3000L),\n",
        "  makeNumericParam(\"learning_rate\", lower= 0.005, upper= 0.1),\n",
        "  makeNumericParam(\"feature_fraction\", lower= 0.1, upper= 1.0),\n",
        "  makeIntegerParam(\"num_leaves\", lower= 1L, upper= 2048L),\n",
        "  makeIntegerParam(\"min_data_in_leaf\", lower= 1L, upper= 8000L)\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-_RPFUb3zMoW"
      },
      "source": [
        "A mayor cantidad de hiperparámetros, se debe aumentar las iteraciones de la Bayesian Optimization: 30 es un valor muy tacaño, pero corre rápido deberia partir de 50, alcanzando los 100 si se dispone de tiempo."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "q5Rd3pnbzSiG",
        "vscode": {
          "languageId": "r"
        }
      },
      "outputs": [],
      "source": [
        "PARAM$hyperparametertuning$iteraciones <- 100 # iteraciones bayesianas"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "or53-q3bmE5d",
        "vscode": {
          "languageId": "r"
        }
      },
      "outputs": [],
      "source": [
        "# particionar agrega una columna llamada fold a un dataset\n",
        "#   que consiste en una particion estratificada segun agrupa\n",
        "# particionar( data=dataset, division=c(70,30),\n",
        "#  agrupa=clase_ternaria, seed=semilla)   crea una particion 70, 30\n",
        "\n",
        "particionar <- function(data, division, agrupa= \"\", campo= \"fold\", start= 1, seed= NA) {\n",
        "  if (!is.na(seed)) set.seed(seed, \"L'Ecuyer-CMRG\")\n",
        "\n",
        "  bloque <- unlist(mapply(\n",
        "    function(x, y) {rep(y, x)},division, seq(from= start, length.out= length(division))))\n",
        "\n",
        "  data[, (campo) := sample(rep(bloque,ceiling(.N / length(bloque))))[1:.N],by= agrupa]\n",
        "}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "CGKOZ9aMmKxi",
        "vscode": {
          "languageId": "r"
        }
      },
      "outputs": [],
      "source": [
        "# iniciliazo el dataset de realidad, para medir ganancia\n",
        "realidad_inicializar <- function( pfuture, pparam) {\n",
        "\n",
        "  # datos para verificar la ganancia\n",
        "  drealidad <- pfuture[, list(numero_de_cliente, foto_mes, clase_ternaria)]\n",
        "\n",
        "  particionar(drealidad,\n",
        "    division= c(3, 7),\n",
        "    agrupa= \"clase_ternaria\",\n",
        "    seed= PARAM$semilla_kaggle\n",
        "  )\n",
        "\n",
        "  return( drealidad )\n",
        "}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "6aVLFlEbmM3s",
        "vscode": {
          "languageId": "r"
        }
      },
      "outputs": [],
      "source": [
        "# evaluo ganancia en los datos de la realidad\n",
        "\n",
        "realidad_evaluar <- function( prealidad, pprediccion) {\n",
        "\n",
        "  prealidad[ pprediccion,\n",
        "    on= c(\"numero_de_cliente\", \"foto_mes\"),\n",
        "    predicted:= i.Predicted\n",
        "  ]\n",
        "\n",
        "  tbl <- prealidad[, list(\"qty\"=.N), list(fold, predicted, clase_ternaria)]\n",
        "\n",
        "  res <- list()\n",
        "  res$public  <- tbl[fold==1 & predicted==1L, sum(qty*ifelse(clase_ternaria==\"BAJA+2\", 780000, -20000))]/0.3\n",
        "  res$private <- tbl[fold==2 & predicted==1L, sum(qty*ifelse(clase_ternaria==\"BAJA+2\", 780000, -20000))]/0.7\n",
        "  res$total <- tbl[predicted==1L, sum(qty*ifelse(clase_ternaria==\"BAJA+2\", 780000, -20000))]\n",
        "\n",
        "  prealidad[, predicted:=NULL]\n",
        "  return( res )\n",
        "}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4RWZXL1VZjMI"
      },
      "source": [
        "### 2.2.4  Preprocesamiento"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "FM3lxKoLZ643",
        "vscode": {
          "languageId": "r"
        }
      },
      "outputs": [],
      "source": [
        "# lectura del dataset\n",
        "dataset <- fread(\"./competencia_01.csv.gz\", stringsAsFactors= TRUE)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "OsJ-91UeZ-I_",
        "vscode": {
          "languageId": "r"
        }
      },
      "outputs": [],
      "source": [
        "dataset_train <- dataset[foto_mes %in% PARAM$train]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "vrWE7BE0aB2J",
        "vscode": {
          "languageId": "r"
        }
      },
      "outputs": [],
      "source": [
        "# paso la clase a binaria que tome valores {0,1}  enteros\n",
        "#  BAJA+1 y BAJA+2  son  1,   CONTINUA es 0\n",
        "#  a partir de ahora ya NO puedo cortar  por prob(BAJA+2) > 1/40\n",
        "\n",
        "dataset_train[,\n",
        "  clase01 := ifelse(clase_ternaria %in% c(\"BAJA+2\",\"BAJA+1\"), 1L, 0L)\n",
        "]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "jP7YlQBnaW6W",
        "vscode": {
          "languageId": "r"
        }
      },
      "outputs": [],
      "source": [
        "# defino los datos que forma parte del training\n",
        "# aqui se hace el undersampling de los CONTINUA\n",
        "# notar que para esto utilizo la SEGUNDA semilla\n",
        "\n",
        "set.seed(PARAM$semilla_primigenia, kind = \"L'Ecuyer-CMRG\")\n",
        "dataset_train[, azar := runif(nrow(dataset_train))]\n",
        "dataset_train[, training := 0L]\n",
        "\n",
        "dataset_train[\n",
        "  foto_mes %in%  PARAM$train &\n",
        "    (azar <= PARAM$trainingstrategy$undersampling | clase_ternaria %in% c(\"BAJA+1\", \"BAJA+2\")),\n",
        "  training := 1L\n",
        "]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "xElu4s5W4rX7",
        "vscode": {
          "languageId": "r"
        }
      },
      "outputs": [],
      "source": [
        "# los campos que se van a utilizar\n",
        "\n",
        "campos_buenos <- setdiff(\n",
        "  colnames(dataset_train),\n",
        "  c(\"clase_ternaria\", \"clase01\", \"azar\", \"training\")\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "PppMHcGYaaol",
        "vscode": {
          "languageId": "r"
        }
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "82338"
            ],
            "text/latex": [
              "82338"
            ],
            "text/markdown": [
              "82338"
            ],
            "text/plain": [
              "[1] 82338"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "154"
            ],
            "text/latex": [
              "154"
            ],
            "text/markdown": [
              "154"
            ],
            "text/plain": [
              "[1] 154"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# dejo los datos en el formato que necesita LightGBM\n",
        "\n",
        "dtrain <- lgb.Dataset(\n",
        "  data= data.matrix(dataset_train[training == 1L, campos_buenos, with= FALSE]),\n",
        "  label= dataset_train[training == 1L, clase01],\n",
        "  free_raw_data= FALSE\n",
        ")\n",
        "\n",
        "nrow(dtrain)\n",
        "ncol(dtrain)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ta-EkOu3cphF"
      },
      "source": [
        "2.2.5 Configuracion Bayesian Optimization"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "cjgfurjdfiXb",
        "vscode": {
          "languageId": "r"
        }
      },
      "outputs": [],
      "source": [
        "# En el argumento x llegan los parmaetros de la bayesiana\n",
        "#  devuelve la AUC en cross validation del modelo entrenado\n",
        "\n",
        "EstimarGanancia_AUC_lightgbm <- function(x) {\n",
        "\n",
        "  # x pisa (o agrega) a param_fijos\n",
        "  param_completo <- modifyList(PARAM$lgbm$param_fijos, x)\n",
        "\n",
        "  # entreno LightGBM\n",
        "  modelocv <- lgb.cv(\n",
        "    data= dtrain,\n",
        "    nfold= PARAM$hyperparametertuning$xval_folds,\n",
        "    stratified= TRUE,\n",
        "    param= param_completo\n",
        "  )\n",
        "\n",
        "  # obtengo la ganancia\n",
        "  AUC <- modelocv$best_score\n",
        "\n",
        "  # hago espacio en la memoria\n",
        "  rm(modelocv)\n",
        "  gc(full= TRUE, verbose= FALSE)\n",
        "\n",
        "  message(format(Sys.time(), \"%a %b %d %X %Y\"), \" AUC \", AUC)\n",
        "\n",
        "  return(AUC)\n",
        "}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "WLi_o1hocvN-",
        "vscode": {
          "languageId": "r"
        }
      },
      "outputs": [],
      "source": [
        "# Aqui comienza la configuracion de la Bayesian Optimization\n",
        "\n",
        "# en este archivo quedan la evolucion binaria de la BO\n",
        "kbayesiana <- \"bayesiana.RDATA\"\n",
        "\n",
        "funcion_optimizar <- EstimarGanancia_AUC_lightgbm # la funcion que voy a maximizar\n",
        "\n",
        "configureMlr(show.learner.output= FALSE)\n",
        "\n",
        "# configuro la busqueda bayesiana,  los hiperparametros que se van a optimizar\n",
        "# por favor, no desesperarse por lo complejo\n",
        "\n",
        "obj.fun <- makeSingleObjectiveFunction(\n",
        "  fn= funcion_optimizar, # la funcion que voy a maximizar\n",
        "  minimize= FALSE, # estoy Maximizando la ganancia\n",
        "  noisy= TRUE,\n",
        "  par.set= PARAM$hypeparametertuning$hs, # definido al comienzo del programa\n",
        "  has.simple.signature= FALSE # paso los parametros en una lista\n",
        ")\n",
        "\n",
        "# cada 600 segundos guardo el resultado intermedio\n",
        "ctrl <- makeMBOControl(\n",
        "  save.on.disk.at.time= 600, # se graba cada 600 segundos\n",
        "  save.file.path= kbayesiana\n",
        ") # se graba cada 600 segundos\n",
        "\n",
        "# indico la cantidad de iteraciones que va a tener la Bayesian Optimization\n",
        "ctrl <- setMBOControlTermination(\n",
        "  ctrl,\n",
        "  iters= PARAM$hyperparametertuning$iteraciones\n",
        ") # cantidad de iteraciones\n",
        "\n",
        "# defino el método estandar para la creacion de los puntos iniciales,\n",
        "# los \"No Inteligentes\"\n",
        "ctrl <- setMBOControlInfill(ctrl, crit= makeMBOInfillCritEI())\n",
        "\n",
        "# establezco la funcion que busca el maximo\n",
        "surr.km <- makeLearner(\n",
        "  \"regr.km\",\n",
        "  predict.type= \"se\",\n",
        "  covtype= \"matern3_2\",\n",
        "  control= list(trace= TRUE)\n",
        ")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_uUeVo5pc4zc"
      },
      "source": [
        "2.2.6 Corrida Bayesian Optimization"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "RcABNaKGciaz",
        "vscode": {
          "languageId": "r"
        }
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Computing y column(s) for design. Not provided.\n",
            "\n",
            "jue oct 02 17:49:12 2025 AUC 0.921669036705487\n",
            "\n",
            "jue oct 02 17:50:46 2025 AUC 0.920979889907246\n",
            "\n",
            "jue oct 02 17:52:36 2025 AUC 0.921266536772986\n",
            "\n",
            "jue oct 02 17:53:44 2025 AUC 0.923214449599131\n",
            "\n",
            "jue oct 02 17:54:31 2025 AUC 0.921867326049701\n",
            "\n",
            "jue oct 02 17:57:36 2025 AUC 0.922440475628762\n",
            "\n",
            "jue oct 02 17:58:53 2025 AUC 0.924327683296336\n",
            "\n",
            "jue oct 02 18:00:00 2025 AUC 0.923270999173678\n",
            "\n",
            "jue oct 02 18:01:18 2025 AUC 0.91998991876811\n",
            "\n",
            "jue oct 02 18:06:22 2025 AUC 0.920374430632268\n",
            "\n",
            "jue oct 02 18:09:02 2025 AUC 0.922391590953989\n",
            "\n",
            "jue oct 02 18:09:58 2025 AUC 0.919755225311443\n",
            "\n",
            "jue oct 02 18:12:56 2025 AUC 0.92351008061476\n",
            "\n",
            "jue oct 02 18:15:18 2025 AUC 0.922252513825585\n",
            "\n",
            "jue oct 02 18:21:25 2025 AUC 0.915554825892606\n",
            "\n",
            "jue oct 02 18:23:51 2025 AUC 0.922711988591787\n",
            "\n",
            "jue oct 02 18:24:15 2025 AUC 0.918923586339892\n",
            "\n",
            "jue oct 02 18:25:52 2025 AUC 0.919408270319285\n",
            "\n",
            "jue oct 02 18:25:59 2025 AUC 0.915393753315713\n",
            "\n",
            "jue oct 02 18:28:27 2025 AUC 0.923827968843094\n",
            "\n",
            "[mbo] 0: num_iterations=2813; learning_rate=0.0192; feature_fraction=0.522; num_leaves=770; min_data_in_leaf=5993 : y = 0.922 : 152.0 secs : initdesign\n",
            "\n",
            "[mbo] 0: num_iterations=1931; learning_rate=0.0546; feature_fraction=0.745; num_leaves=1326; min_data_in_leaf=5592 : y = 0.921 : 94.1 secs : initdesign\n",
            "\n",
            "[mbo] 0: num_iterations=2083; learning_rate=0.0277; feature_fraction=0.307; num_leaves=1680; min_data_in_leaf=6034 : y = 0.921 : 110.4 secs : initdesign\n",
            "\n",
            "[mbo] 0: num_iterations=425; learning_rate=0.064; feature_fraction=0.415; num_leaves=1843; min_data_in_leaf=1458 : y = 0.923 : 67.8 secs : initdesign\n",
            "\n",
            "[mbo] 0: num_iterations=721; learning_rate=0.0493; feature_fraction=0.686; num_leaves=1058; min_data_in_leaf=4614 : y = 0.922 : 46.4 secs : initdesign\n",
            "\n",
            "[mbo] 0: num_iterations=2613; learning_rate=0.0782; feature_fraction=0.583; num_leaves=482; min_data_in_leaf=3546 : y = 0.922 : 185.8 secs : initdesign\n",
            "\n",
            "[mbo] 0: num_iterations=880; learning_rate=0.0226; feature_fraction=0.651; num_leaves=870; min_data_in_leaf=2226 : y = 0.924 : 76.3 secs : initdesign\n",
            "\n",
            "[mbo] 0: num_iterations=1067; learning_rate=0.0128; feature_fraction=0.176; num_leaves=989; min_data_in_leaf=2910 : y = 0.923 : 67.3 secs : initdesign\n",
            "\n",
            "[mbo] 0: num_iterations=1684; learning_rate=0.081; feature_fraction=0.613; num_leaves=1556; min_data_in_leaf=6472 : y = 0.92 : 78.3 secs : initdesign\n",
            "\n",
            "[mbo] 0: num_iterations=1521; learning_rate=0.0684; feature_fraction=1; num_leaves=64; min_data_in_leaf=701 : y = 0.92 : 303.5 secs : initdesign\n",
            "\n",
            "[mbo] 0: num_iterations=2857; learning_rate=0.059; feature_fraction=0.211; num_leaves=1851; min_data_in_leaf=4801 : y = 0.922 : 160.3 secs : initdesign\n",
            "\n",
            "[mbo] 0: num_iterations=1098; learning_rate=0.0369; feature_fraction=0.48; num_leaves=1132; min_data_in_leaf=7263 : y = 0.92 : 56.3 secs : initdesign\n",
            "\n",
            "[mbo] 0: num_iterations=1350; learning_rate=0.0982; feature_fraction=0.777; num_leaves=1373; min_data_in_leaf=1816 : y = 0.924 : 177.8 secs : initdesign\n",
            "\n",
            "[mbo] 0: num_iterations=242; learning_rate=0.0437; feature_fraction=0.278; num_leaves=219; min_data_in_leaf=148 : y = 0.922 : 141.4 secs : initdesign\n",
            "\n",
            "[mbo] 0: num_iterations=2268; learning_rate=0.0718; feature_fraction=0.11; num_leaves=553; min_data_in_leaf=1017 : y = 0.916 : 367.7 secs : initdesign\n",
            "\n",
            "[mbo] 0: num_iterations=2507; learning_rate=0.00725; feature_fraction=0.876; num_leaves=655; min_data_in_leaf=3875 : y = 0.923 : 145.4 secs : initdesign\n",
            "\n",
            "[mbo] 0: num_iterations=584; learning_rate=0.0924; feature_fraction=0.91; num_leaves=1484; min_data_in_leaf=7652 : y = 0.919 : 24.6 secs : initdesign\n",
            "\n",
            "[mbo] 0: num_iterations=2124; learning_rate=0.0896; feature_fraction=0.436; num_leaves=374; min_data_in_leaf=7103 : y = 0.919 : 97.1 secs : initdesign\n",
            "\n",
            "[mbo] 0: num_iterations=117; learning_rate=0.0296; feature_fraction=0.857; num_leaves=175; min_data_in_leaf=4114 : y = 0.915 : 7.0 secs : initdesign\n",
            "\n",
            "[mbo] 0: num_iterations=1652; learning_rate=0.04; feature_fraction=0.345; num_leaves=2016; min_data_in_leaf=2611 : y = 0.924 : 147.6 secs : initdesign\n",
            "\n",
            "Saved the current state after iteration 1 in the file bayesiana.RDATA.\n",
            "\n",
            "jue oct 02 18:30:07 2025 AUC 0.923473577765669\n",
            "\n",
            "[mbo] 1: num_iterations=1286; learning_rate=0.0248; feature_fraction=0.264; num_leaves=863; min_data_in_leaf=2766 : y = 0.923 : 94.7 secs : infill_ei\n",
            "\n",
            "jue oct 02 18:31:44 2025 AUC 0.923557873182988\n",
            "\n",
            "[mbo] 2: num_iterations=974; learning_rate=0.0536; feature_fraction=0.677; num_leaves=2032; min_data_in_leaf=2258 : y = 0.924 : 96.9 secs : infill_ei\n",
            "\n",
            "jue oct 02 18:34:20 2025 AUC 0.923070432970425\n",
            "\n",
            "[mbo] 3: num_iterations=1878; learning_rate=0.025; feature_fraction=0.666; num_leaves=1241; min_data_in_leaf=2793 : y = 0.923 : 154.8 secs : infill_ei\n",
            "\n",
            "jue oct 02 18:36:07 2025 AUC 0.924508292512824\n",
            "\n",
            "[mbo] 4: num_iterations=854; learning_rate=0.0271; feature_fraction=0.509; num_leaves=1176; min_data_in_leaf=1733 : y = 0.925 : 106.9 secs : infill_ei\n",
            "\n",
            "jue oct 02 18:37:35 2025 AUC 0.922506922394337\n",
            "\n",
            "[mbo] 5: num_iterations=793; learning_rate=0.0902; feature_fraction=0.471; num_leaves=860; min_data_in_leaf=1868 : y = 0.923 : 87.6 secs : infill_ei\n",
            "\n",
            "jue oct 02 19:19:38 2025 AUC 0.917146755791274\n",
            "\n",
            "[mbo] 6: num_iterations=922; learning_rate=0.00507; feature_fraction=0.589; num_leaves=961; min_data_in_leaf=1 : y = 0.917 : 2522.9 secs : infill_ei\n",
            "\n",
            "Saved the current state after iteration 7 in the file bayesiana.RDATA.\n",
            "\n",
            "jue oct 02 19:21:07 2025 AUC 0.924475119027319\n",
            "\n",
            "[mbo] 7: num_iterations=795; learning_rate=0.0202; feature_fraction=0.553; num_leaves=1317; min_data_in_leaf=2143 : y = 0.924 : 88.3 secs : infill_ei\n",
            "\n",
            "jue oct 02 19:22:35 2025 AUC 0.923675937282775\n",
            "\n",
            "[mbo] 8: num_iterations=822; learning_rate=0.0335; feature_fraction=0.386; num_leaves=1654; min_data_in_leaf=2038 : y = 0.924 : 87.4 secs : infill_ei\n",
            "\n",
            "jue oct 02 19:24:07 2025 AUC 0.921091546046009\n",
            "\n",
            "[mbo] 9: num_iterations=737; learning_rate=0.00553; feature_fraction=0.964; num_leaves=1256; min_data_in_leaf=1749 : y = 0.921 : 92.2 secs : infill_ei\n",
            "\n",
            "jue oct 02 19:26:15 2025 AUC 0.923123463463296\n",
            "\n",
            "[mbo] 10: num_iterations=1209; learning_rate=0.0172; feature_fraction=0.556; num_leaves=1305; min_data_in_leaf=2183 : y = 0.923 : 127.7 secs : infill_ei\n",
            "\n",
            "jue oct 02 19:26:43 2025 AUC 0.922953696510727\n",
            "\n",
            "[mbo] 11: num_iterations=238; learning_rate=0.0238; feature_fraction=0.449; num_leaves=1193; min_data_in_leaf=1997 : y = 0.923 : 27.1 secs : infill_ei\n",
            "\n",
            "jue oct 02 19:28:04 2025 AUC 0.92273685941202\n",
            "\n",
            "[mbo] 12: num_iterations=857; learning_rate=0.0394; feature_fraction=0.544; num_leaves=1105; min_data_in_leaf=2573 : y = 0.923 : 81.1 secs : infill_ei\n",
            "\n",
            "jue oct 02 19:29:33 2025 AUC 0.924051198469924\n",
            "\n",
            "[mbo] 13: num_iterations=777; learning_rate=0.0242; feature_fraction=0.628; num_leaves=1497; min_data_in_leaf=1868 : y = 0.924 : 88.6 secs : infill_ei\n",
            "\n",
            "jue oct 02 19:30:44 2025 AUC 0.923829656291876\n",
            "\n",
            "[mbo] 14: num_iterations=830; learning_rate=0.0222; feature_fraction=0.147; num_leaves=900; min_data_in_leaf=2026 : y = 0.924 : 70.5 secs : infill_ei\n",
            "\n",
            "Saved the current state after iteration 15 in the file bayesiana.RDATA.\n",
            "\n",
            "jue oct 02 19:34:04 2025 AUC 0.923763933815797\n",
            "\n",
            "[mbo] 15: num_iterations=1295; learning_rate=0.0427; feature_fraction=0.57; num_leaves=1880; min_data_in_leaf=1488 : y = 0.924 : 199.1 secs : infill_ei\n",
            "\n",
            "jue oct 02 19:38:15 2025 AUC 0.923446981549896\n",
            "\n",
            "[mbo] 16: num_iterations=2932; learning_rate=0.0439; feature_fraction=0.468; num_leaves=2047; min_data_in_leaf=3200 : y = 0.923 : 250.3 secs : infill_ei\n",
            "\n",
            "jue oct 02 19:40:08 2025 AUC 0.923230007711906\n",
            "\n",
            "[mbo] 17: num_iterations=1464; learning_rate=0.0575; feature_fraction=0.605; num_leaves=2019; min_data_in_leaf=3324 : y = 0.923 : 113.1 secs : infill_ei\n",
            "\n",
            "jue oct 02 19:44:11 2025 AUC 0.924703893862355\n",
            "\n",
            "[mbo] 18: num_iterations=1559; learning_rate=0.0298; feature_fraction=0.496; num_leaves=1152; min_data_in_leaf=1407 : y = 0.925 : 241.9 secs : infill_ei\n",
            "\n",
            "Saved the current state after iteration 19 in the file bayesiana.RDATA.\n",
            "\n",
            "jue oct 02 19:46:49 2025 AUC 0.925124532217929\n",
            "\n",
            "[mbo] 19: num_iterations=1103; learning_rate=0.0507; feature_fraction=0.417; num_leaves=1955; min_data_in_leaf=1546 : y = 0.925 : 157.7 secs : infill_ei\n",
            "\n",
            "jue oct 02 20:21:00 2025 AUC 0.921305293165315\n",
            "\n",
            "[mbo] 20: num_iterations=1710; learning_rate=0.0231; feature_fraction=0.563; num_leaves=785; min_data_in_leaf=76 : y = 0.921 : 2050.4 secs : infill_ei\n",
            "\n",
            "Saved the current state after iteration 21 in the file bayesiana.RDATA.\n",
            "\n",
            "jue oct 02 20:22:48 2025 AUC 0.924097031019121\n",
            "\n",
            "[mbo] 21: num_iterations=1031; learning_rate=0.0491; feature_fraction=0.232; num_leaves=1671; min_data_in_leaf=2038 : y = 0.924 : 107.5 secs : infill_ei\n",
            "\n",
            "jue oct 02 20:29:20 2025 AUC 0.923558789641536\n",
            "\n",
            "[mbo] 22: num_iterations=1940; learning_rate=0.0518; feature_fraction=0.492; num_leaves=1617; min_data_in_leaf=1153 : y = 0.924 : 391.3 secs : infill_ei\n",
            "\n",
            "jue oct 02 20:32:01 2025 AUC 0.923753612171785\n",
            "\n",
            "[mbo] 23: num_iterations=1116; learning_rate=0.0632; feature_fraction=0.395; num_leaves=1852; min_data_in_leaf=1537 : y = 0.924 : 160.7 secs : infill_ei\n",
            "\n",
            "Saved the current state after iteration 24 in the file bayesiana.RDATA.\n",
            "\n",
            "jue oct 02 20:38:28 2025 AUC 0.924774777365879\n",
            "\n",
            "[mbo] 24: num_iterations=2767; learning_rate=0.0321; feature_fraction=0.406; num_leaves=1346; min_data_in_leaf=1638 : y = 0.925 : 386.7 secs : infill_ei\n",
            "\n",
            "jue oct 02 20:42:23 2025 AUC 0.924158927083551\n",
            "\n",
            "[mbo] 25: num_iterations=1505; learning_rate=0.0339; feature_fraction=0.575; num_leaves=1340; min_data_in_leaf=1430 : y = 0.924 : 234.3 secs : infill_ei\n",
            "\n",
            "Saved the current state after iteration 26 in the file bayesiana.RDATA.\n",
            "\n",
            "jue oct 02 20:46:03 2025 AUC 0.922074569049511\n",
            "\n",
            "[mbo] 26: num_iterations=1360; learning_rate=0.051; feature_fraction=0.222; num_leaves=2046; min_data_in_leaf=1249 : y = 0.922 : 219.8 secs : infill_ei\n",
            "\n",
            "jue oct 02 20:48:49 2025 AUC 0.924080381929588\n",
            "\n",
            "[mbo] 27: num_iterations=1229; learning_rate=0.0505; feature_fraction=0.433; num_leaves=1620; min_data_in_leaf=1673 : y = 0.924 : 165.0 secs : infill_ei\n",
            "\n",
            "jue oct 02 20:54:26 2025 AUC 0.92363412572651\n",
            "\n",
            "[mbo] 28: num_iterations=2084; learning_rate=0.0389; feature_fraction=0.4; num_leaves=2048; min_data_in_leaf=1380 : y = 0.924 : 337.0 secs : infill_ei\n",
            "\n",
            "Saved the current state after iteration 29 in the file bayesiana.RDATA.\n",
            "\n",
            "jue oct 02 20:56:25 2025 AUC 0.924137302855379\n",
            "\n",
            "[mbo] 29: num_iterations=897; learning_rate=0.0518; feature_fraction=0.427; num_leaves=2047; min_data_in_leaf=1710 : y = 0.924 : 117.6 secs : infill_ei\n",
            "\n",
            "jue oct 02 21:01:11 2025 AUC 0.923575179837085\n",
            "\n",
            "[mbo] 30: num_iterations=2648; learning_rate=0.0297; feature_fraction=0.579; num_leaves=588; min_data_in_leaf=1954 : y = 0.924 : 285.5 secs : infill_ei\n",
            "\n",
            "jue oct 02 21:05:29 2025 AUC 0.924588487077248\n",
            "\n",
            "[mbo] 31: num_iterations=1942; learning_rate=0.0282; feature_fraction=0.348; num_leaves=1060; min_data_in_leaf=1572 : y = 0.925 : 258.2 secs : infill_ei\n",
            "\n",
            "Saved the current state after iteration 32 in the file bayesiana.RDATA.\n",
            "\n",
            "jue oct 02 21:11:38 2025 AUC 0.922935895491714\n",
            "\n",
            "[mbo] 32: num_iterations=2373; learning_rate=0.05; feature_fraction=0.465; num_leaves=1876; min_data_in_leaf=1543 : y = 0.923 : 368.0 secs : infill_ei\n",
            "\n",
            "jue oct 02 21:15:58 2025 AUC 0.924301990150768\n",
            "\n",
            "[mbo] 33: num_iterations=1095; learning_rate=0.0489; feature_fraction=0.362; num_leaves=1782; min_data_in_leaf=856 : y = 0.924 : 259.2 secs : infill_ei\n",
            "\n",
            "Saved the current state after iteration 34 in the file bayesiana.RDATA.\n",
            "\n",
            "jue oct 02 21:22:55 2025 AUC 0.924391750763\n",
            "\n",
            "[mbo] 34: num_iterations=2999; learning_rate=0.0205; feature_fraction=0.386; num_leaves=1756; min_data_in_leaf=1572 : y = 0.924 : 416.3 secs : infill_ei\n",
            "\n",
            "jue oct 02 21:27:04 2025 AUC 0.923299555998975\n",
            "\n",
            "[mbo] 35: num_iterations=2871; learning_rate=0.0263; feature_fraction=0.388; num_leaves=732; min_data_in_leaf=2425 : y = 0.923 : 248.9 secs : infill_ei\n",
            "\n",
            "Saved the current state after iteration 36 in the file bayesiana.RDATA.\n",
            "\n",
            "jue oct 02 21:31:30 2025 AUC 0.922389691073128\n",
            "\n",
            "[mbo] 36: num_iterations=3000; learning_rate=0.097; feature_fraction=0.907; num_leaves=1837; min_data_in_leaf=3090 : y = 0.922 : 265.8 secs : infill_ei\n",
            "\n",
            "jue oct 02 21:39:54 2025 AUC 0.922668404759955\n",
            "\n",
            "[mbo] 37: num_iterations=2965; learning_rate=0.0307; feature_fraction=0.732; num_leaves=1610; min_data_in_leaf=1351 : y = 0.923 : 503.4 secs : infill_ei\n",
            "\n",
            "Saved the current state after iteration 38 in the file bayesiana.RDATA.\n",
            "\n",
            "jue oct 02 21:45:10 2025 AUC 0.925280868406964\n",
            "\n",
            "[mbo] 38: num_iterations=2154; learning_rate=0.0269; feature_fraction=0.367; num_leaves=1398; min_data_in_leaf=1465 : y = 0.925 : 315.0 secs : infill_ei\n",
            "\n",
            "jue oct 02 21:45:18 2025 AUC 0.908722220990285\n",
            "\n",
            "[mbo] 39: num_iterations=62; learning_rate=0.0197; feature_fraction=0.412; num_leaves=1364; min_data_in_leaf=2015 : y = 0.909 : 7.4 secs : infill_ei\n",
            "\n",
            "jue oct 02 21:46:02 2025 AUC 0.925330182458871\n",
            "\n",
            "[mbo] 40: num_iterations=445; learning_rate=0.0241; feature_fraction=0.501; num_leaves=560; min_data_in_leaf=2153 : y = 0.925 : 42.9 secs : infill_ei\n",
            "\n",
            "jue oct 02 21:46:40 2025 AUC 0.923835929510501\n",
            "\n",
            "[mbo] 41: num_iterations=376; learning_rate=0.0267; feature_fraction=0.369; num_leaves=1004; min_data_in_leaf=1855 : y = 0.924 : 38.3 secs : infill_ei\n",
            "\n",
            "jue oct 02 22:25:28 2025 AUC 0.921336405148642\n",
            "\n",
            "[mbo] 42: num_iterations=2208; learning_rate=0.0297; feature_fraction=0.521; num_leaves=1790; min_data_in_leaf=7 : y = 0.921 : 2327.5 secs : infill_ei\n",
            "\n",
            "Saved the current state after iteration 43 in the file bayesiana.RDATA.\n",
            "\n",
            "jue oct 02 22:29:11 2025 AUC 0.923863156451633\n",
            "\n",
            "[mbo] 43: num_iterations=2552; learning_rate=0.0175; feature_fraction=0.171; num_leaves=1329; min_data_in_leaf=2403 : y = 0.924 : 221.9 secs : infill_ei\n",
            "\n",
            "jue oct 02 22:51:01 2025 AUC 0.923718282825223\n",
            "\n",
            "[mbo] 44: num_iterations=2138; learning_rate=0.0213; feature_fraction=0.241; num_leaves=826; min_data_in_leaf=257 : y = 0.924 : 1308.9 secs : infill_ei\n",
            "\n",
            "Saved the current state after iteration 45 in the file bayesiana.RDATA.\n",
            "\n",
            "jue oct 02 22:51:44 2025 AUC 0.922710817198988\n",
            "\n",
            "[mbo] 45: num_iterations=599; learning_rate=0.0225; feature_fraction=0.906; num_leaves=474; min_data_in_leaf=3100 : y = 0.923 : 42.9 secs : infill_ei\n",
            "\n",
            "jue oct 02 22:51:50 2025 AUC 0.919830210423281\n",
            "\n",
            "[mbo] 46: num_iterations=113; learning_rate=0.0851; feature_fraction=0.72; num_leaves=489; min_data_in_leaf=5487 : y = 0.92 : 5.8 secs : infill_ei\n",
            "\n",
            "jue oct 02 22:53:59 2025 AUC 0.923491886264439\n",
            "\n",
            "[mbo] 47: num_iterations=1156; learning_rate=0.0453; feature_fraction=0.711; num_leaves=2038; min_data_in_leaf=2001 : y = 0.923 : 128.4 secs : infill_ei\n",
            "\n",
            "jue oct 02 22:55:07 2025 AUC 0.92005557937067\n",
            "\n",
            "[mbo] 48: num_iterations=1722; learning_rate=0.0428; feature_fraction=0.705; num_leaves=121; min_data_in_leaf=6978 : y = 0.92 : 67.5 secs : infill_ei\n",
            "\n",
            "jue oct 02 22:58:45 2025 AUC 0.924584180837634\n",
            "\n",
            "[mbo] 49: num_iterations=2137; learning_rate=0.013; feature_fraction=0.363; num_leaves=1422; min_data_in_leaf=2132 : y = 0.925 : 217.2 secs : infill_ei\n",
            "\n",
            "jue oct 02 23:44:24 2025 AUC 0.913394129105209\n",
            "\n",
            "[mbo] 50: num_iterations=2282; learning_rate=0.0265; feature_fraction=0.117; num_leaves=1131; min_data_in_leaf=88 : y = 0.913 : 2737.7 secs : infill_ei\n",
            "\n",
            "Saved the current state after iteration 51 in the file bayesiana.RDATA.\n",
            "\n",
            "jue oct 02 23:46:48 2025 AUC 0.922514810557754\n",
            "\n",
            "[mbo] 51: num_iterations=1082; learning_rate=0.0213; feature_fraction=0.787; num_leaves=2044; min_data_in_leaf=1701 : y = 0.923 : 143.6 secs : infill_ei\n",
            "\n",
            "jue oct 02 23:56:38 2025 AUC 0.92187386005918\n",
            "\n",
            "[mbo] 52: num_iterations=2419; learning_rate=0.0618; feature_fraction=0.203; num_leaves=346; min_data_in_leaf=756 : y = 0.922 : 589.0 secs : infill_ei\n",
            "\n",
            "Saved the current state after iteration 53 in the file bayesiana.RDATA.\n",
            "\n",
            "vie oct 03 00:02:42 2025 AUC 0.923677271704516\n",
            "\n",
            "[mbo] 53: num_iterations=2141; learning_rate=0.0286; feature_fraction=0.694; num_leaves=1558; min_data_in_leaf=1377 : y = 0.924 : 363.8 secs : infill_ei\n",
            "\n",
            "vie oct 03 00:14:23 2025 AUC 0.924728684661696\n",
            "\n",
            "[mbo] 54: num_iterations=2455; learning_rate=0.0521; feature_fraction=0.404; num_leaves=1391; min_data_in_leaf=821 : y = 0.925 : 700.4 secs : infill_ei\n",
            "\n",
            "Saved the current state after iteration 55 in the file bayesiana.RDATA.\n",
            "\n",
            "vie oct 03 00:15:20 2025 AUC 0.921955568557887\n",
            "\n",
            "[mbo] 55: num_iterations=857; learning_rate=0.0237; feature_fraction=0.913; num_leaves=1991; min_data_in_leaf=4733 : y = 0.922 : 55.3 secs : infill_ei\n",
            "\n",
            "vie oct 03 00:21:55 2025 AUC 0.924168222226224\n",
            "\n",
            "[mbo] 56: num_iterations=2483; learning_rate=0.0473; feature_fraction=0.533; num_leaves=1926; min_data_in_leaf=1667 : y = 0.924 : 394.6 secs : infill_ei\n",
            "\n",
            "vie oct 03 00:25:11 2025 AUC 0.923933982006871\n",
            "\n",
            "[mbo] 57: num_iterations=1068; learning_rate=0.03; feature_fraction=0.769; num_leaves=1396; min_data_in_leaf=1208 : y = 0.924 : 195.3 secs : infill_ei\n",
            "\n",
            "Saved the current state after iteration 58 in the file bayesiana.RDATA.\n",
            "\n",
            "vie oct 03 00:26:24 2025 AUC 0.924174253003288\n",
            "\n",
            "[mbo] 58: num_iterations=463; learning_rate=0.0239; feature_fraction=0.583; num_leaves=1978; min_data_in_leaf=1522 : y = 0.924 : 71.6 secs : infill_ei\n",
            "\n",
            "vie oct 03 00:34:48 2025 AUC 0.922170008299999\n",
            "\n",
            "[mbo] 59: num_iterations=2509; learning_rate=0.0596; feature_fraction=0.983; num_leaves=2036; min_data_in_leaf=1282 : y = 0.922 : 503.4 secs : infill_ei\n",
            "\n",
            "vie oct 03 00:35:22 2025 AUC 0.923255729810492\n",
            "\n",
            "[mbo] 60: num_iterations=437; learning_rate=0.0299; feature_fraction=0.828; num_leaves=195; min_data_in_leaf=2974 : y = 0.923 : 33.1 secs : infill_ei\n",
            "\n",
            "Saved the current state after iteration 61 in the file bayesiana.RDATA.\n",
            "\n",
            "vie oct 03 00:40:20 2025 AUC 0.925351846818231\n",
            "\n",
            "[mbo] 61: num_iterations=2123; learning_rate=0.00725; feature_fraction=0.256; num_leaves=1033; min_data_in_leaf=1454 : y = 0.925 : 297.7 secs : infill_ei\n",
            "\n",
            "vie oct 03 00:44:08 2025 AUC 0.924061797773019\n",
            "\n",
            "[mbo] 62: num_iterations=2129; learning_rate=0.00923; feature_fraction=0.349; num_leaves=973; min_data_in_leaf=1749 : y = 0.924 : 226.9 secs : infill_ei\n",
            "\n",
            "vie oct 03 00:51:20 2025 AUC 0.924424868268233\n",
            "\n",
            "[mbo] 63: num_iterations=2104; learning_rate=0.00922; feature_fraction=0.293; num_leaves=1383; min_data_in_leaf=907 : y = 0.924 : 431.6 secs : infill_ei\n",
            "\n",
            "Saved the current state after iteration 64 in the file bayesiana.RDATA.\n",
            "\n",
            "vie oct 03 00:55:02 2025 AUC 0.923566233687336\n",
            "\n",
            "[mbo] 64: num_iterations=2142; learning_rate=0.00502; feature_fraction=0.132; num_leaves=2046; min_data_in_leaf=1889 : y = 0.924 : 221.2 secs : infill_ei\n",
            "\n",
            "vie oct 03 00:59:55 2025 AUC 0.924221304889666\n",
            "\n",
            "[mbo] 65: num_iterations=2126; learning_rate=0.0304; feature_fraction=0.245; num_leaves=1171; min_data_in_leaf=1477 : y = 0.924 : 292.0 secs : infill_ei\n",
            "\n",
            "vie oct 03 01:02:40 2025 AUC 0.922599280216803\n",
            "\n",
            "[mbo] 66: num_iterations=2864; learning_rate=0.0298; feature_fraction=0.879; num_leaves=436; min_data_in_leaf=4035 : y = 0.923 : 163.7 secs : infill_ei\n",
            "\n",
            "Saved the current state after iteration 67 in the file bayesiana.RDATA.\n",
            "\n",
            "vie oct 03 01:05:57 2025 AUC 0.923443547931966\n",
            "\n",
            "[mbo] 67: num_iterations=1057; learning_rate=0.0572; feature_fraction=0.42; num_leaves=2043; min_data_in_leaf=1170 : y = 0.923 : 196.6 secs : infill_ei\n",
            "\n",
            "vie oct 03 01:07:10 2025 AUC 0.924821740066083\n",
            "\n",
            "[mbo] 68: num_iterations=688; learning_rate=0.027; feature_fraction=0.3; num_leaves=1300; min_data_in_leaf=2007 : y = 0.925 : 71.8 secs : infill_ei\n",
            "\n",
            "vie oct 03 01:08:01 2025 AUC 0.923734008700951\n",
            "\n",
            "[mbo] 69: num_iterations=524; learning_rate=0.0259; feature_fraction=0.409; num_leaves=517; min_data_in_leaf=2061 : y = 0.924 : 50.1 secs : infill_ei\n",
            "\n",
            "vie oct 03 01:10:08 2025 AUC 0.924451877420727\n",
            "\n",
            "[mbo] 70: num_iterations=1110; learning_rate=0.0348; feature_fraction=0.415; num_leaves=1327; min_data_in_leaf=1922 : y = 0.924 : 126.9 secs : infill_ei\n",
            "\n",
            "vie oct 03 01:28:13 2025 AUC 0.925093420378232\n",
            "\n",
            "[mbo] 71: num_iterations=2687; learning_rate=0.04; feature_fraction=0.296; num_leaves=1640; min_data_in_leaf=441 : y = 0.925 : 1084.0 secs : infill_ei\n",
            "\n",
            "Saved the current state after iteration 72 in the file bayesiana.RDATA.\n",
            "\n",
            "vie oct 03 01:43:20 2025 AUC 0.925071299979292\n",
            "\n",
            "[mbo] 72: num_iterations=2306; learning_rate=0.0109; feature_fraction=0.3; num_leaves=1392; min_data_in_leaf=473 : y = 0.925 : 906.0 secs : infill_ei\n",
            "\n",
            "Saved the current state after iteration 73 in the file bayesiana.RDATA.\n",
            "\n",
            "vie oct 03 01:49:31 2025 AUC 0.924925653050813\n",
            "\n",
            "[mbo] 73: num_iterations=2335; learning_rate=0.00518; feature_fraction=0.371; num_leaves=1561; min_data_in_leaf=1237 : y = 0.925 : 370.0 secs : infill_ei\n",
            "\n",
            "vie oct 03 01:59:55 2025 AUC 0.92626134021117\n",
            "\n",
            "[mbo] 74: num_iterations=2229; learning_rate=0.0124; feature_fraction=0.352; num_leaves=1397; min_data_in_leaf=678 : y = 0.926 : 623.8 secs : infill_ei\n",
            "\n",
            "Saved the current state after iteration 75 in the file bayesiana.RDATA.\n",
            "\n",
            "vie oct 03 02:49:12 2025 AUC 0.922226493584563\n",
            "\n",
            "[mbo] 75: num_iterations=2388; learning_rate=0.0146; feature_fraction=0.346; num_leaves=926; min_data_in_leaf=104 : y = 0.922 : 2953.6 secs : infill_ei\n",
            "\n",
            "Saved the current state after iteration 76 in the file bayesiana.RDATA.\n",
            "\n",
            "vie oct 03 02:49:36 2025 AUC 0.919957677612921\n",
            "\n",
            "[mbo] 76: num_iterations=537; learning_rate=0.0258; feature_fraction=0.987; num_leaves=872; min_data_in_leaf=6984 : y = 0.92 : 23.8 secs : infill_ei\n",
            "\n",
            "vie oct 03 02:51:21 2025 AUC 0.923852229835384\n",
            "\n",
            "[mbo] 77: num_iterations=986; learning_rate=0.0403; feature_fraction=0.406; num_leaves=410; min_data_in_leaf=1831 : y = 0.924 : 104.1 secs : infill_ei\n",
            "\n",
            "vie oct 03 02:56:25 2025 AUC 0.925008914175337\n",
            "\n",
            "[mbo] 78: num_iterations=2226; learning_rate=0.00591; feature_fraction=0.297; num_leaves=1587; min_data_in_leaf=1448 : y = 0.925 : 302.7 secs : infill_ei\n",
            "\n",
            "vie oct 03 03:05:51 2025 AUC 0.921637824672183\n",
            "\n",
            "[mbo] 79: num_iterations=2244; learning_rate=0.0711; feature_fraction=0.366; num_leaves=1460; min_data_in_leaf=865 : y = 0.922 : 565.1 secs : infill_ei\n",
            "\n",
            "Saved the current state after iteration 80 in the file bayesiana.RDATA.\n",
            "\n",
            "vie oct 03 03:41:52 2025 AUC 0.922455529429146\n",
            "\n",
            "[mbo] 80: num_iterations=2229; learning_rate=0.00577; feature_fraction=0.855; num_leaves=1404; min_data_in_leaf=194 : y = 0.922 : 2160.1 secs : infill_ei\n",
            "\n",
            "Saved the current state after iteration 81 in the file bayesiana.RDATA.\n",
            "\n",
            "vie oct 03 03:47:34 2025 AUC 0.922608065231376\n",
            "\n",
            "[mbo] 81: num_iterations=2633; learning_rate=0.0379; feature_fraction=0.392; num_leaves=1571; min_data_in_leaf=1821 : y = 0.923 : 341.0 secs : infill_ei\n",
            "\n",
            "vie oct 03 04:01:09 2025 AUC 0.924997030090617\n",
            "\n",
            "[mbo] 82: num_iterations=2198; learning_rate=0.0302; feature_fraction=0.353; num_leaves=1513; min_data_in_leaf=559 : y = 0.925 : 814.0 secs : infill_ei\n",
            "\n",
            "Saved the current state after iteration 83 in the file bayesiana.RDATA.\n",
            "\n",
            "vie oct 03 04:09:23 2025 AUC 0.924083438532097\n",
            "\n",
            "[mbo] 83: num_iterations=1860; learning_rate=0.0291; feature_fraction=0.392; num_leaves=1406; min_data_in_leaf=780 : y = 0.924 : 492.6 secs : infill_ei\n",
            "\n",
            "vie oct 03 04:10:48 2025 AUC 0.921589035034047\n",
            "\n",
            "[mbo] 84: num_iterations=1239; learning_rate=0.0358; feature_fraction=0.413; num_leaves=1827; min_data_in_leaf=4074 : y = 0.922 : 85.0 secs : infill_ei\n",
            "\n",
            "vie oct 03 04:19:01 2025 AUC 0.925486652800827\n",
            "\n",
            "[mbo] 85: num_iterations=2247; learning_rate=0.0136; feature_fraction=0.4; num_leaves=1334; min_data_in_leaf=900 : y = 0.925 : 491.5 secs : infill_ei\n",
            "\n",
            "Saved the current state after iteration 86 in the file bayesiana.RDATA.\n",
            "\n",
            "vie oct 03 04:45:40 2025 AUC 0.924206538734477\n",
            "\n",
            "[mbo] 86: num_iterations=2272; learning_rate=0.00668; feature_fraction=0.358; num_leaves=1783; min_data_in_leaf=262 : y = 0.924 : 1598.4 secs : infill_ei\n",
            "\n",
            "Saved the current state after iteration 87 in the file bayesiana.RDATA.\n",
            "\n",
            "vie oct 03 04:46:50 2025 AUC 0.922759600159211\n",
            "\n",
            "[mbo] 87: num_iterations=854; learning_rate=0.0279; feature_fraction=0.723; num_leaves=1042; min_data_in_leaf=3010 : y = 0.923 : 68.3 secs : infill_ei\n",
            "\n",
            "vie oct 03 04:57:08 2025 AUC 0.924384264049109\n",
            "\n",
            "[mbo] 88: num_iterations=2484; learning_rate=0.0131; feature_fraction=0.317; num_leaves=1742; min_data_in_leaf=769 : y = 0.924 : 617.3 secs : infill_ei\n",
            "\n",
            "Saved the current state after iteration 89 in the file bayesiana.RDATA.\n",
            "\n",
            "vie oct 03 05:16:59 2025 AUC 0.924606662025918\n",
            "\n",
            "[mbo] 89: num_iterations=2749; learning_rate=0.0232; feature_fraction=0.251; num_leaves=1668; min_data_in_leaf=453 : y = 0.925 : 1189.6 secs : infill_ei\n",
            "\n",
            "Saved the current state after iteration 90 in the file bayesiana.RDATA.\n",
            "\n",
            "vie oct 03 05:19:32 2025 AUC 0.92443048859104\n",
            "\n",
            "[mbo] 90: num_iterations=1189; learning_rate=0.0543; feature_fraction=0.538; num_leaves=1329; min_data_in_leaf=1881 : y = 0.924 : 152.9 secs : infill_ei\n",
            "\n",
            "vie oct 03 05:24:32 2025 AUC 0.923058855935643\n",
            "\n",
            "[mbo] 91: num_iterations=2039; learning_rate=0.0572; feature_fraction=0.397; num_leaves=115; min_data_in_leaf=1375 : y = 0.923 : 298.8 secs : infill_ei\n",
            "\n",
            "vie oct 03 05:34:41 2025 AUC 0.925836354606728\n",
            "\n",
            "[mbo] 92: num_iterations=2225; learning_rate=0.0112; feature_fraction=0.381; num_leaves=1535; min_data_in_leaf=703 : y = 0.926 : 608.5 secs : infill_ei\n",
            "\n",
            "Saved the current state after iteration 93 in the file bayesiana.RDATA.\n",
            "\n",
            "vie oct 03 05:50:43 2025 AUC 0.921136989581415\n",
            "\n",
            "[mbo] 93: num_iterations=2747; learning_rate=0.0434; feature_fraction=0.281; num_leaves=314; min_data_in_leaf=50 : y = 0.921 : 960.9 secs : infill_ei\n",
            "\n",
            "Saved the current state after iteration 94 in the file bayesiana.RDATA.\n",
            "\n",
            "vie oct 03 05:56:26 2025 AUC 0.925661095034517\n",
            "\n",
            "[mbo] 94: num_iterations=2195; learning_rate=0.0305; feature_fraction=0.387; num_leaves=1755; min_data_in_leaf=1431 : y = 0.926 : 342.4 secs : infill_ei\n",
            "\n",
            "vie oct 03 05:57:05 2025 AUC 0.923826946143181\n",
            "\n",
            "[mbo] 95: num_iterations=359; learning_rate=0.028; feature_fraction=0.563; num_leaves=1006; min_data_in_leaf=1943 : y = 0.924 : 37.7 secs : infill_ei\n",
            "\n",
            "vie oct 03 06:05:00 2025 AUC 0.924193724610087\n",
            "\n",
            "[mbo] 96: num_iterations=1786; learning_rate=0.0277; feature_fraction=0.266; num_leaves=1764; min_data_in_leaf=737 : y = 0.924 : 473.7 secs : infill_ei\n",
            "\n",
            "Saved the current state after iteration 97 in the file bayesiana.RDATA.\n",
            "\n",
            "vie oct 03 06:08:25 2025 AUC 0.92348367539104\n",
            "\n",
            "[mbo] 97: num_iterations=2627; learning_rate=0.00518; feature_fraction=0.218; num_leaves=1522; min_data_in_leaf=2931 : y = 0.923 : 204.5 secs : infill_ei\n",
            "\n",
            "vie oct 03 06:12:21 2025 AUC 0.924479477841171\n",
            "\n",
            "[mbo] 98: num_iterations=2242; learning_rate=0.0242; feature_fraction=0.384; num_leaves=1333; min_data_in_leaf=2170 : y = 0.924 : 235.2 secs : infill_ei\n",
            "\n",
            "vie oct 03 06:16:35 2025 AUC 0.924092533032589\n",
            "\n",
            "[mbo] 99: num_iterations=2202; learning_rate=0.0145; feature_fraction=0.338; num_leaves=1460; min_data_in_leaf=1840 : y = 0.924 : 252.6 secs : infill_ei\n",
            "\n",
            "Saved the current state after iteration 100 in the file bayesiana.RDATA.\n",
            "\n",
            "vie oct 03 06:17:56 2025 AUC 0.91900127825937\n",
            "\n",
            "[mbo] 100: num_iterations=1713; learning_rate=0.00509; feature_fraction=0.336; num_leaves=128; min_data_in_leaf=6803 : y = 0.919 : 80.6 secs : infill_ei\n",
            "\n",
            "Saved the final state in the file bayesiana.RDATA\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# inicio la optimizacion bayesiana, retomando si ya existe\n",
        "# es la celda mas lenta de todo el notebook\n",
        "\n",
        "if (!file.exists(kbayesiana)) {\n",
        "  bayesiana_salida <- mbo(obj.fun, learner= surr.km, control= ctrl)\n",
        "} else {\n",
        "  bayesiana_salida <- mboContinue(kbayesiana) # retomo en caso que ya exista\n",
        "}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "ssk5nnMk6INK",
        "vscode": {
          "languageId": "r"
        }
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<style>\n",
              ".list-inline {list-style: none; margin:0; padding: 0}\n",
              ".list-inline>li {display: inline-block}\n",
              ".list-inline>li:not(:last-child)::after {content: \"\\00b7\"; padding: 0 .5ex}\n",
              "</style>\n",
              "<ol class=list-inline><li>'num_iterations'</li><li>'learning_rate'</li><li>'feature_fraction'</li><li>'num_leaves'</li><li>'min_data_in_leaf'</li><li>'y'</li><li>'dob'</li><li>'eol'</li><li>'error.message'</li><li>'exec.time'</li><li>'ei'</li><li>'error.model'</li><li>'train.time'</li><li>'prop.type'</li><li>'propose.time'</li><li>'se'</li><li>'mean'</li></ol>\n"
            ],
            "text/latex": [
              "\\begin{enumerate*}\n",
              "\\item 'num\\_iterations'\n",
              "\\item 'learning\\_rate'\n",
              "\\item 'feature\\_fraction'\n",
              "\\item 'num\\_leaves'\n",
              "\\item 'min\\_data\\_in\\_leaf'\n",
              "\\item 'y'\n",
              "\\item 'dob'\n",
              "\\item 'eol'\n",
              "\\item 'error.message'\n",
              "\\item 'exec.time'\n",
              "\\item 'ei'\n",
              "\\item 'error.model'\n",
              "\\item 'train.time'\n",
              "\\item 'prop.type'\n",
              "\\item 'propose.time'\n",
              "\\item 'se'\n",
              "\\item 'mean'\n",
              "\\end{enumerate*}\n"
            ],
            "text/markdown": [
              "1. 'num_iterations'\n",
              "2. 'learning_rate'\n",
              "3. 'feature_fraction'\n",
              "4. 'num_leaves'\n",
              "5. 'min_data_in_leaf'\n",
              "6. 'y'\n",
              "7. 'dob'\n",
              "8. 'eol'\n",
              "9. 'error.message'\n",
              "10. 'exec.time'\n",
              "11. 'ei'\n",
              "12. 'error.model'\n",
              "13. 'train.time'\n",
              "14. 'prop.type'\n",
              "15. 'propose.time'\n",
              "16. 'se'\n",
              "17. 'mean'\n",
              "\n",
              "\n"
            ],
            "text/plain": [
              " [1] \"num_iterations\"   \"learning_rate\"    \"feature_fraction\" \"num_leaves\"      \n",
              " [5] \"min_data_in_leaf\" \"y\"                \"dob\"              \"eol\"             \n",
              " [9] \"error.message\"    \"exec.time\"        \"ei\"               \"error.model\"     \n",
              "[13] \"train.time\"       \"prop.type\"        \"propose.time\"     \"se\"              \n",
              "[17] \"mean\"            "
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "\n",
        "tb_bayesiana <- as.data.table(bayesiana_salida$opt.path)\n",
        "colnames( tb_bayesiana)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "u4zq-vknhjGc",
        "vscode": {
          "languageId": "r"
        }
      },
      "outputs": [],
      "source": [
        "# almaceno los resultados de la Bayesian Optimization\n",
        "# y capturo los mejores hiperparametros encontrados\n",
        "\n",
        "tb_bayesiana <- as.data.table(bayesiana_salida$opt.path)\n",
        "\n",
        "tb_bayesiana[, iter := .I]\n",
        "\n",
        "# ordeno en forma descendente por AUC = y\n",
        "setorder(tb_bayesiana, -y)\n",
        "\n",
        "# grabo para eventualmente poder utilizarlos en OTRA corrida\n",
        "fwrite( tb_bayesiana,\n",
        "  file= \"BO_log.txt\",\n",
        "  sep= \"\\t\"\n",
        ")\n",
        "\n",
        "# los mejores hiperparámetros son los que quedaron en el registro 1 de la tabla\n",
        "PARAM$out$lgbm$mejores_hiperparametros <- tb_bayesiana[\n",
        "  1, # el primero es el de mejor AUC\n",
        "  setdiff(colnames(tb_bayesiana),\n",
        "    c(\"y\",\"dob\",\"eol\",\"error.message\",\"exec.time\",\"ei\",\"error.model\",\n",
        "      \"train.time\",\"prop.type\",\"propose.time\",\"se\",\"mean\",\"iter\")),\n",
        "  with= FALSE\n",
        "]\n",
        "\n",
        "\n",
        "PARAM$out$lgbm$y <- tb_bayesiana[1, y]\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "id": "E8v2eA427N8e",
        "vscode": {
          "languageId": "r"
        }
      },
      "outputs": [],
      "source": [
        "write_yaml( PARAM, file=\"PARAM.yml\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "id": "iBTWexVU7PGC",
        "vscode": {
          "languageId": "r"
        }
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "   num_iterations learning_rate feature_fraction num_leaves min_data_in_leaf\n",
            "            <int>         <num>            <num>      <int>            <int>\n",
            "1:           2229    0.01235865        0.3517336       1397              678\n",
            "[1] 0.9262613\n"
          ]
        }
      ],
      "source": [
        "print(PARAM$out$lgbm$mejores_hiperparametros)\n",
        "print(PARAM$out$lgbm$y)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TKsVZmAnhwX-"
      },
      "source": [
        "## 2.3  Produccion"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RQ_C33Tr5B_9"
      },
      "source": [
        "### Final Training\n",
        "Construyo el modelo final, que es uno solo, no hace ningun tipo de particion < training, validation, testing>]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8qFmFivf5Iet"
      },
      "source": [
        "#### Final Training Dataset\n",
        "\n",
        "Aqui esta la gran decision de en qué meses hago el Final Training\n",
        "<br> debo utilizar los mejores hiperparámetros que encontré en la  optimización bayesiana"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "id": "lg5WVZncvc7H",
        "vscode": {
          "languageId": "r"
        }
      },
      "outputs": [],
      "source": [
        "# clase01\n",
        "dataset[, clase01 := ifelse(clase_ternaria %in% c(\"BAJA+1\", \"BAJA+2\"), 1L, 0L)]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "id": "yc9QzXREv0xf",
        "vscode": {
          "languageId": "r"
        }
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<table class=\"dataframe\">\n",
              "<caption>A data.table: 3 × 2</caption>\n",
              "<thead>\n",
              "\t<tr><th scope=col>clase_ternaria</th><th scope=col>N</th></tr>\n",
              "\t<tr><th scope=col>&lt;fct&gt;</th><th scope=col>&lt;int&gt;</th></tr>\n",
              "</thead>\n",
              "<tbody>\n",
              "\t<tr><td>CONTINUA</td><td>160292</td></tr>\n",
              "\t<tr><td>BAJA+1  </td><td>   831</td></tr>\n",
              "\t<tr><td>BAJA+2  </td><td>  1032</td></tr>\n",
              "</tbody>\n",
              "</table>\n"
            ],
            "text/latex": [
              "A data.table: 3 × 2\n",
              "\\begin{tabular}{ll}\n",
              " clase\\_ternaria & N\\\\\n",
              " <fct> & <int>\\\\\n",
              "\\hline\n",
              "\t CONTINUA & 160292\\\\\n",
              "\t BAJA+1   &    831\\\\\n",
              "\t BAJA+2   &   1032\\\\\n",
              "\\end{tabular}\n"
            ],
            "text/markdown": [
              "\n",
              "A data.table: 3 × 2\n",
              "\n",
              "| clase_ternaria &lt;fct&gt; | N &lt;int&gt; |\n",
              "|---|---|\n",
              "| CONTINUA | 160292 |\n",
              "| BAJA+1   |    831 |\n",
              "| BAJA+2   |   1032 |\n",
              "\n"
            ],
            "text/plain": [
              "  clase_ternaria N     \n",
              "1 CONTINUA       160292\n",
              "2 BAJA+1            831\n",
              "3 BAJA+2           1032"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "dataset_train <- dataset[foto_mes %in% PARAM$train_final]\n",
        "dataset_train[,.N,clase_ternaria]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "id": "thjdqEBLuvNt",
        "vscode": {
          "languageId": "r"
        }
      },
      "outputs": [],
      "source": [
        "# dejo los datos en el formato que necesita LightGBM\n",
        "\n",
        "dtrain_final <- lgb.Dataset(\n",
        "  data= data.matrix(dataset_train[, campos_buenos, with= FALSE]),\n",
        "  label= dataset_train[, clase01]\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VNUa-WSz5Oqu"
      },
      "source": [
        "#### Final Training Hyperparameters"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "id": "FgCcvBfEwImu",
        "vscode": {
          "languageId": "r"
        }
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<dl>\n",
              "\t<dt>$boosting</dt>\n",
              "\t\t<dd>'gbdt'</dd>\n",
              "\t<dt>$objective</dt>\n",
              "\t\t<dd>'binary'</dd>\n",
              "\t<dt>$metric</dt>\n",
              "\t\t<dd>'auc'</dd>\n",
              "\t<dt>$first_metric_only</dt>\n",
              "\t\t<dd>FALSE</dd>\n",
              "\t<dt>$boost_from_average</dt>\n",
              "\t\t<dd>TRUE</dd>\n",
              "\t<dt>$feature_pre_filter</dt>\n",
              "\t\t<dd>FALSE</dd>\n",
              "\t<dt>$force_row_wise</dt>\n",
              "\t\t<dd>TRUE</dd>\n",
              "\t<dt>$verbosity</dt>\n",
              "\t\t<dd>-100</dd>\n",
              "\t<dt>$seed</dt>\n",
              "\t\t<dd>200003</dd>\n",
              "\t<dt>$num_iterations</dt>\n",
              "\t\t<dd>2229</dd>\n",
              "\t<dt>$learning_rate</dt>\n",
              "\t\t<dd>0.0123586461173437</dd>\n",
              "\t<dt>$feature_fraction</dt>\n",
              "\t\t<dd>0.351733616718237</dd>\n",
              "\t<dt>$num_leaves</dt>\n",
              "\t\t<dd>1397</dd>\n",
              "\t<dt>$min_data_in_leaf</dt>\n",
              "\t\t<dd>678</dd>\n",
              "</dl>\n"
            ],
            "text/latex": [
              "\\begin{description}\n",
              "\\item[\\$boosting] 'gbdt'\n",
              "\\item[\\$objective] 'binary'\n",
              "\\item[\\$metric] 'auc'\n",
              "\\item[\\$first\\_metric\\_only] FALSE\n",
              "\\item[\\$boost\\_from\\_average] TRUE\n",
              "\\item[\\$feature\\_pre\\_filter] FALSE\n",
              "\\item[\\$force\\_row\\_wise] TRUE\n",
              "\\item[\\$verbosity] -100\n",
              "\\item[\\$seed] 200003\n",
              "\\item[\\$num\\_iterations] 2229\n",
              "\\item[\\$learning\\_rate] 0.0123586461173437\n",
              "\\item[\\$feature\\_fraction] 0.351733616718237\n",
              "\\item[\\$num\\_leaves] 1397\n",
              "\\item[\\$min\\_data\\_in\\_leaf] 678\n",
              "\\end{description}\n"
            ],
            "text/markdown": [
              "$boosting\n",
              ":   'gbdt'\n",
              "$objective\n",
              ":   'binary'\n",
              "$metric\n",
              ":   'auc'\n",
              "$first_metric_only\n",
              ":   FALSE\n",
              "$boost_from_average\n",
              ":   TRUE\n",
              "$feature_pre_filter\n",
              ":   FALSE\n",
              "$force_row_wise\n",
              ":   TRUE\n",
              "$verbosity\n",
              ":   -100\n",
              "$seed\n",
              ":   200003\n",
              "$num_iterations\n",
              ":   2229\n",
              "$learning_rate\n",
              ":   0.0123586461173437\n",
              "$feature_fraction\n",
              ":   0.351733616718237\n",
              "$num_leaves\n",
              ":   1397\n",
              "$min_data_in_leaf\n",
              ":   678\n",
              "\n",
              "\n"
            ],
            "text/plain": [
              "$boosting\n",
              "[1] \"gbdt\"\n",
              "\n",
              "$objective\n",
              "[1] \"binary\"\n",
              "\n",
              "$metric\n",
              "[1] \"auc\"\n",
              "\n",
              "$first_metric_only\n",
              "[1] FALSE\n",
              "\n",
              "$boost_from_average\n",
              "[1] TRUE\n",
              "\n",
              "$feature_pre_filter\n",
              "[1] FALSE\n",
              "\n",
              "$force_row_wise\n",
              "[1] TRUE\n",
              "\n",
              "$verbosity\n",
              "[1] -100\n",
              "\n",
              "$seed\n",
              "[1] 200003\n",
              "\n",
              "$num_iterations\n",
              "[1] 2229\n",
              "\n",
              "$learning_rate\n",
              "[1] 0.01235865\n",
              "\n",
              "$feature_fraction\n",
              "[1] 0.3517336\n",
              "\n",
              "$num_leaves\n",
              "[1] 1397\n",
              "\n",
              "$min_data_in_leaf\n",
              "[1] 678\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "param_final <- modifyList(PARAM$lgbm$param_fijos,\n",
        "  PARAM$out$lgbm$mejores_hiperparametros)\n",
        "\n",
        "param_final"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TZIYn4l95TBH"
      },
      "source": [
        "#### Training\n",
        "Genero el modelo final, siempre sobre TODOS los datos de  final_train, sin hacer ningun tipo de undersampling de la clase mayoritaria y mucho menos cross validation."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "id": "vPLsd4mMRe4u",
        "vscode": {
          "languageId": "r"
        }
      },
      "outputs": [],
      "source": [
        "# este punto es muy SUTIL  y será revisado en la Clase 05\n",
        "\n",
        "param_normalizado <- copy(param_final)\n",
        "param_normalizado$min_data_in_leaf <-  round(param_final$min_data_in_leaf / PARAM$trainingstrategy$undersampling)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "id": "WRI_-taRwOXO",
        "vscode": {
          "languageId": "r"
        }
      },
      "outputs": [],
      "source": [
        "# entreno LightGBM\n",
        "\n",
        "modelo_final <- lgb.train(\n",
        "  data= dtrain_final,\n",
        "  param= param_normalizado\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "id": "_bkhnCvj0g3Q",
        "vscode": {
          "languageId": "r"
        }
      },
      "outputs": [],
      "source": [
        "# ahora imprimo la importancia de variables\n",
        "\n",
        "tb_importancia <- as.data.table(lgb.importance(modelo_final))\n",
        "archivo_importancia <- \"impo.txt\"\n",
        "\n",
        "fwrite(tb_importancia,\n",
        "  file= archivo_importancia,\n",
        "  sep= \"\\t\"\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "id": "lZ3sLmbh0kFj",
        "vscode": {
          "languageId": "r"
        }
      },
      "outputs": [],
      "source": [
        "# grabo a disco el modelo en un formato para seres humanos ... ponele ...\n",
        "lgb.save(modelo_final, \"modelo.txt\" )"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VEtp2--t5Ymg"
      },
      "source": [
        "### Scoring"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hI5008Mj5ZdI"
      },
      "source": [
        "Aplico el modelo final a los datos del futuro"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "id": "PimBY3N_0ryP",
        "vscode": {
          "languageId": "r"
        }
      },
      "outputs": [],
      "source": [
        "# aplico el modelo a los datos sin clase\n",
        "dfuture <- dataset[foto_mes %in% PARAM$future]\n",
        "\n",
        "# aplico el modelo a los datos nuevos\n",
        "prediccion <- predict(\n",
        "  modelo_final,\n",
        "  data.matrix(dfuture[, campos_buenos, with= FALSE])\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {
        "id": "M9_NCquymhtF",
        "vscode": {
          "languageId": "r"
        }
      },
      "outputs": [],
      "source": [
        "# inicilizo el dataset  drealidad\n",
        "drealidad <- realidad_inicializar( dfuture, PARAM)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D26rNRh55gpw"
      },
      "source": [
        "#### Tabla Prediccion"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {
        "id": "RJwg7LHd11yu",
        "vscode": {
          "languageId": "r"
        }
      },
      "outputs": [],
      "source": [
        "# tabla de prediccion\n",
        "\n",
        "tb_prediccion <- dfuture[, list(numero_de_cliente, foto_mes)]\n",
        "tb_prediccion[, prob := prediccion ]\n",
        "\n",
        "# grabo las probabilidad del modelo\n",
        "fwrite(tb_prediccion,\n",
        "  file= \"prediccion.txt\",\n",
        "  sep= \"\\t\"\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jOt4eG_55ltv"
      },
      "source": [
        "Kaggle Competition Submit"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {
        "id": "Vdu3moTfJ1Vl",
        "vscode": {
          "languageId": "r"
        }
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<style>\n",
              ".list-inline {list-style: none; margin:0; padding: 0}\n",
              ".list-inline>li {display: inline-block}\n",
              ".list-inline>li:not(:last-child)::after {content: \"\\00b7\"; padding: 0 .5ex}\n",
              "</style>\n",
              "<ol class=list-inline><li>4000</li><li>4100</li><li>4200</li><li>4300</li><li>4400</li><li>4500</li><li>4600</li><li>4700</li><li>4800</li><li>4900</li><li>5000</li><li>5100</li><li>5200</li><li>5300</li><li>5400</li><li>5500</li><li>5600</li><li>5700</li><li>5800</li><li>5900</li><li>6000</li><li>6100</li><li>6200</li><li>6300</li><li>6400</li><li>6500</li><li>6600</li><li>6700</li><li>6800</li><li>6900</li><li>7000</li><li>7100</li><li>7200</li><li>7300</li><li>7400</li><li>7500</li><li>7600</li><li>7700</li><li>7800</li><li>7900</li><li>8000</li><li>8100</li><li>8200</li><li>8300</li><li>8400</li><li>8500</li><li>8600</li><li>8700</li><li>8800</li><li>8900</li><li>9000</li><li>9100</li><li>9200</li><li>9300</li><li>9400</li><li>9500</li><li>9600</li><li>9700</li><li>9800</li><li>9900</li><li>10000</li><li>10100</li><li>10200</li><li>10300</li><li>10400</li><li>10500</li><li>10600</li><li>10700</li><li>10800</li><li>10900</li><li>11000</li><li>11100</li><li>11200</li><li>11300</li><li>11400</li><li>11500</li><li>11600</li><li>11700</li><li>11800</li><li>11900</li><li>12000</li><li>12100</li><li>12200</li><li>12300</li><li>12400</li><li>12500</li><li>12600</li><li>12700</li><li>12800</li><li>12900</li><li>13000</li><li>13100</li><li>13200</li><li>13300</li><li>13400</li><li>13500</li><li>13600</li><li>13700</li><li>13800</li><li>13900</li><li>14000</li><li>14100</li><li>14200</li><li>14300</li><li>14400</li><li>14500</li><li>14600</li><li>14700</li><li>14800</li><li>14900</li><li>15000</li><li>15100</li><li>15200</li><li>15300</li><li>15400</li><li>15500</li><li>15600</li><li>15700</li><li>15800</li><li>15900</li><li>16000</li><li>16100</li><li>16200</li><li>16300</li><li>16400</li><li>16500</li><li>16600</li><li>16700</li><li>16800</li><li>16900</li><li>17000</li><li>17100</li><li>17200</li><li>17300</li><li>17400</li><li>17500</li><li>17600</li><li>17700</li><li>17800</li><li>17900</li><li>18000</li><li>18100</li><li>18200</li><li>18300</li><li>18400</li><li>18500</li><li>18600</li><li>18700</li><li>18800</li><li>18900</li><li>19000</li></ol>\n"
            ],
            "text/latex": [
              "\\begin{enumerate*}\n",
              "\\item 4000\n",
              "\\item 4100\n",
              "\\item 4200\n",
              "\\item 4300\n",
              "\\item 4400\n",
              "\\item 4500\n",
              "\\item 4600\n",
              "\\item 4700\n",
              "\\item 4800\n",
              "\\item 4900\n",
              "\\item 5000\n",
              "\\item 5100\n",
              "\\item 5200\n",
              "\\item 5300\n",
              "\\item 5400\n",
              "\\item 5500\n",
              "\\item 5600\n",
              "\\item 5700\n",
              "\\item 5800\n",
              "\\item 5900\n",
              "\\item 6000\n",
              "\\item 6100\n",
              "\\item 6200\n",
              "\\item 6300\n",
              "\\item 6400\n",
              "\\item 6500\n",
              "\\item 6600\n",
              "\\item 6700\n",
              "\\item 6800\n",
              "\\item 6900\n",
              "\\item 7000\n",
              "\\item 7100\n",
              "\\item 7200\n",
              "\\item 7300\n",
              "\\item 7400\n",
              "\\item 7500\n",
              "\\item 7600\n",
              "\\item 7700\n",
              "\\item 7800\n",
              "\\item 7900\n",
              "\\item 8000\n",
              "\\item 8100\n",
              "\\item 8200\n",
              "\\item 8300\n",
              "\\item 8400\n",
              "\\item 8500\n",
              "\\item 8600\n",
              "\\item 8700\n",
              "\\item 8800\n",
              "\\item 8900\n",
              "\\item 9000\n",
              "\\item 9100\n",
              "\\item 9200\n",
              "\\item 9300\n",
              "\\item 9400\n",
              "\\item 9500\n",
              "\\item 9600\n",
              "\\item 9700\n",
              "\\item 9800\n",
              "\\item 9900\n",
              "\\item 10000\n",
              "\\item 10100\n",
              "\\item 10200\n",
              "\\item 10300\n",
              "\\item 10400\n",
              "\\item 10500\n",
              "\\item 10600\n",
              "\\item 10700\n",
              "\\item 10800\n",
              "\\item 10900\n",
              "\\item 11000\n",
              "\\item 11100\n",
              "\\item 11200\n",
              "\\item 11300\n",
              "\\item 11400\n",
              "\\item 11500\n",
              "\\item 11600\n",
              "\\item 11700\n",
              "\\item 11800\n",
              "\\item 11900\n",
              "\\item 12000\n",
              "\\item 12100\n",
              "\\item 12200\n",
              "\\item 12300\n",
              "\\item 12400\n",
              "\\item 12500\n",
              "\\item 12600\n",
              "\\item 12700\n",
              "\\item 12800\n",
              "\\item 12900\n",
              "\\item 13000\n",
              "\\item 13100\n",
              "\\item 13200\n",
              "\\item 13300\n",
              "\\item 13400\n",
              "\\item 13500\n",
              "\\item 13600\n",
              "\\item 13700\n",
              "\\item 13800\n",
              "\\item 13900\n",
              "\\item 14000\n",
              "\\item 14100\n",
              "\\item 14200\n",
              "\\item 14300\n",
              "\\item 14400\n",
              "\\item 14500\n",
              "\\item 14600\n",
              "\\item 14700\n",
              "\\item 14800\n",
              "\\item 14900\n",
              "\\item 15000\n",
              "\\item 15100\n",
              "\\item 15200\n",
              "\\item 15300\n",
              "\\item 15400\n",
              "\\item 15500\n",
              "\\item 15600\n",
              "\\item 15700\n",
              "\\item 15800\n",
              "\\item 15900\n",
              "\\item 16000\n",
              "\\item 16100\n",
              "\\item 16200\n",
              "\\item 16300\n",
              "\\item 16400\n",
              "\\item 16500\n",
              "\\item 16600\n",
              "\\item 16700\n",
              "\\item 16800\n",
              "\\item 16900\n",
              "\\item 17000\n",
              "\\item 17100\n",
              "\\item 17200\n",
              "\\item 17300\n",
              "\\item 17400\n",
              "\\item 17500\n",
              "\\item 17600\n",
              "\\item 17700\n",
              "\\item 17800\n",
              "\\item 17900\n",
              "\\item 18000\n",
              "\\item 18100\n",
              "\\item 18200\n",
              "\\item 18300\n",
              "\\item 18400\n",
              "\\item 18500\n",
              "\\item 18600\n",
              "\\item 18700\n",
              "\\item 18800\n",
              "\\item 18900\n",
              "\\item 19000\n",
              "\\end{enumerate*}\n"
            ],
            "text/markdown": [
              "1. 4000\n",
              "2. 4100\n",
              "3. 4200\n",
              "4. 4300\n",
              "5. 4400\n",
              "6. 4500\n",
              "7. 4600\n",
              "8. 4700\n",
              "9. 4800\n",
              "10. 4900\n",
              "11. 5000\n",
              "12. 5100\n",
              "13. 5200\n",
              "14. 5300\n",
              "15. 5400\n",
              "16. 5500\n",
              "17. 5600\n",
              "18. 5700\n",
              "19. 5800\n",
              "20. 5900\n",
              "21. 6000\n",
              "22. 6100\n",
              "23. 6200\n",
              "24. 6300\n",
              "25. 6400\n",
              "26. 6500\n",
              "27. 6600\n",
              "28. 6700\n",
              "29. 6800\n",
              "30. 6900\n",
              "31. 7000\n",
              "32. 7100\n",
              "33. 7200\n",
              "34. 7300\n",
              "35. 7400\n",
              "36. 7500\n",
              "37. 7600\n",
              "38. 7700\n",
              "39. 7800\n",
              "40. 7900\n",
              "41. 8000\n",
              "42. 8100\n",
              "43. 8200\n",
              "44. 8300\n",
              "45. 8400\n",
              "46. 8500\n",
              "47. 8600\n",
              "48. 8700\n",
              "49. 8800\n",
              "50. 8900\n",
              "51. 9000\n",
              "52. 9100\n",
              "53. 9200\n",
              "54. 9300\n",
              "55. 9400\n",
              "56. 9500\n",
              "57. 9600\n",
              "58. 9700\n",
              "59. 9800\n",
              "60. 9900\n",
              "61. 10000\n",
              "62. 10100\n",
              "63. 10200\n",
              "64. 10300\n",
              "65. 10400\n",
              "66. 10500\n",
              "67. 10600\n",
              "68. 10700\n",
              "69. 10800\n",
              "70. 10900\n",
              "71. 11000\n",
              "72. 11100\n",
              "73. 11200\n",
              "74. 11300\n",
              "75. 11400\n",
              "76. 11500\n",
              "77. 11600\n",
              "78. 11700\n",
              "79. 11800\n",
              "80. 11900\n",
              "81. 12000\n",
              "82. 12100\n",
              "83. 12200\n",
              "84. 12300\n",
              "85. 12400\n",
              "86. 12500\n",
              "87. 12600\n",
              "88. 12700\n",
              "89. 12800\n",
              "90. 12900\n",
              "91. 13000\n",
              "92. 13100\n",
              "93. 13200\n",
              "94. 13300\n",
              "95. 13400\n",
              "96. 13500\n",
              "97. 13600\n",
              "98. 13700\n",
              "99. 13800\n",
              "100. 13900\n",
              "101. 14000\n",
              "102. 14100\n",
              "103. 14200\n",
              "104. 14300\n",
              "105. 14400\n",
              "106. 14500\n",
              "107. 14600\n",
              "108. 14700\n",
              "109. 14800\n",
              "110. 14900\n",
              "111. 15000\n",
              "112. 15100\n",
              "113. 15200\n",
              "114. 15300\n",
              "115. 15400\n",
              "116. 15500\n",
              "117. 15600\n",
              "118. 15700\n",
              "119. 15800\n",
              "120. 15900\n",
              "121. 16000\n",
              "122. 16100\n",
              "123. 16200\n",
              "124. 16300\n",
              "125. 16400\n",
              "126. 16500\n",
              "127. 16600\n",
              "128. 16700\n",
              "129. 16800\n",
              "130. 16900\n",
              "131. 17000\n",
              "132. 17100\n",
              "133. 17200\n",
              "134. 17300\n",
              "135. 17400\n",
              "136. 17500\n",
              "137. 17600\n",
              "138. 17700\n",
              "139. 17800\n",
              "140. 17900\n",
              "141. 18000\n",
              "142. 18100\n",
              "143. 18200\n",
              "144. 18300\n",
              "145. 18400\n",
              "146. 18500\n",
              "147. 18600\n",
              "148. 18700\n",
              "149. 18800\n",
              "150. 18900\n",
              "151. 19000\n",
              "\n",
              "\n"
            ],
            "text/plain": [
              "  [1]  4000  4100  4200  4300  4400  4500  4600  4700  4800  4900  5000  5100\n",
              " [13]  5200  5300  5400  5500  5600  5700  5800  5900  6000  6100  6200  6300\n",
              " [25]  6400  6500  6600  6700  6800  6900  7000  7100  7200  7300  7400  7500\n",
              " [37]  7600  7700  7800  7900  8000  8100  8200  8300  8400  8500  8600  8700\n",
              " [49]  8800  8900  9000  9100  9200  9300  9400  9500  9600  9700  9800  9900\n",
              " [61] 10000 10100 10200 10300 10400 10500 10600 10700 10800 10900 11000 11100\n",
              " [73] 11200 11300 11400 11500 11600 11700 11800 11900 12000 12100 12200 12300\n",
              " [85] 12400 12500 12600 12700 12800 12900 13000 13100 13200 13300 13400 13500\n",
              " [97] 13600 13700 13800 13900 14000 14100 14200 14300 14400 14500 14600 14700\n",
              "[109] 14800 14900 15000 15100 15200 15300 15400 15500 15600 15700 15800 15900\n",
              "[121] 16000 16100 16200 16300 16400 16500 16600 16700 16800 16900 17000 17100\n",
              "[133] 17200 17300 17400 17500 17600 17700 17800 17900 18000 18100 18200 18300\n",
              "[145] 18400 18500 18600 18700 18800 18900 19000"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "PARAM$cortes"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {
        "id": "gWW3tatE12je",
        "vscode": {
          "languageId": "r"
        }
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Envios=4000\t TOTAL=278400000  Public=221000000 Private=303000000\n",
            "Envios=4100\t TOTAL=283600000  Public=229933333 Private=306600000\n",
            "Envios=4200\t TOTAL=284000000  Public=233133333 Private=305800000\n",
            "Envios=4300\t TOTAL=288400000  Public=241800000 Private=308371429\n",
            "Envios=4400\t TOTAL=289600000  Public=239533333 Private=311057143\n",
            "Envios=4500\t TOTAL=291600000  Public=240466667 Private=313514286\n",
            "Envios=4600\t TOTAL=296000000  Public=241133333 Private=319514286\n",
            "Envios=4700\t TOTAL=302000000  Public=249466667 Private=324514286\n",
            "Envios=4800\t TOTAL=301600000  Public=247666667 Private=324714286\n",
            "Envios=4900\t TOTAL=302800000  Public=253600000 Private=323885714\n",
            "Envios=5000\t TOTAL=306400000  Public=256466667 Private=327800000\n",
            "Envios=5100\t TOTAL=307600000  Public=259466667 Private=328228571\n",
            "Envios=5200\t TOTAL=312000000  Public=262733333 Private=333114286\n",
            "Envios=5300\t TOTAL=314800000  Public=263133333 Private=336942857\n",
            "Envios=5400\t TOTAL=317600000  Public=266666667 Private=339428571\n",
            "Envios=5500\t TOTAL=317200000  Public=266666667 Private=338857143\n",
            "Envios=5600\t TOTAL=319200000  Public=272266667 Private=339314286\n",
            "Envios=5700\t TOTAL=318800000  Public=272666667 Private=338571429\n",
            "Envios=5800\t TOTAL=321600000  Public=273533333 Private=342200000\n",
            "Envios=5900\t TOTAL=323600000  Public=274466667 Private=344657143\n",
            "Envios=6000\t TOTAL=324800000  Public=280466667 Private=343800000\n",
            "Envios=6100\t TOTAL=326000000  Public=281600000 Private=345028571\n",
            "Envios=6200\t TOTAL=328000000  Public=284800000 Private=346514286\n",
            "Envios=6300\t TOTAL=328400000  Public=288333333 Private=345571429\n",
            "Envios=6400\t TOTAL=329600000  Public=289066667 Private=346971429\n",
            "Envios=6500\t TOTAL=329200000  Public=287600000 Private=347028571\n",
            "Envios=6600\t TOTAL=328800000  Public=287866667 Private=346342857\n",
            "Envios=6700\t TOTAL=330000000  Public=288400000 Private=347828571\n",
            "Envios=6800\t TOTAL=331200000  Public=294266667 Private=347028571\n",
            "Envios=6900\t TOTAL=329200000  Public=292200000 Private=345057143\n",
            "Envios=7000\t TOTAL=328000000  Public=292400000 Private=343257143\n",
            "Envios=7100\t TOTAL=330000000  Public=293066667 Private=345828571\n",
            "Envios=7200\t TOTAL=328800000  Public=291400000 Private=344828571\n",
            "Envios=7300\t TOTAL=329200000  Public=289200000 Private=346342857\n",
            "Envios=7400\t TOTAL=328000000  Public=287000000 Private=345571429\n",
            "Envios=7500\t TOTAL=326800000  Public=285333333 Private=344571429\n",
            "Envios=7600\t TOTAL=326400000  Public=282933333 Private=345028571\n",
            "Envios=7700\t TOTAL=325200000  Public=280733333 Private=344257143\n",
            "Envios=7800\t TOTAL=324800000  Public=281533333 Private=343342857\n",
            "Envios=7900\t TOTAL=325200000  Public=282333333 Private=343571429\n",
            "Envios=8000\t TOTAL=326400000  Public=285333333 Private=344000000\n",
            "Envios=8100\t TOTAL=327600000  Public=293333333 Private=342285714\n",
            "Envios=8200\t TOTAL=329600000  Public=291266667 Private=346028571\n",
            "Envios=8300\t TOTAL=330800000  Public=291800000 Private=347514286\n",
            "Envios=8400\t TOTAL=330400000  Public=289533333 Private=347914286\n",
            "Envios=8500\t TOTAL=330800000  Public=287800000 Private=349228571\n",
            "Envios=8600\t TOTAL=329600000  Public=286200000 Private=348200000\n",
            "Envios=8700\t TOTAL=331600000  Public=289466667 Private=349657143\n",
            "Envios=8800\t TOTAL=330400000  Public=290000000 Private=347714286\n",
            "Envios=8900\t TOTAL=331600000  Public=291000000 Private=349000000\n",
            "Envios=9000\t TOTAL=331200000  Public=289666667 Private=349000000\n",
            "Envios=9100\t TOTAL=332400000  Public=287800000 Private=351514286\n",
            "Envios=9200\t TOTAL=332000000  Public=285533333 Private=351914286\n",
            "Envios=9300\t TOTAL=332400000  Public=286133333 Private=352228571\n",
            "Envios=9400\t TOTAL=332800000  Public=286733333 Private=352542857\n",
            "Envios=9500\t TOTAL=333200000  Public=284666667 Private=354000000\n",
            "Envios=9600\t TOTAL=336800000  Public=290333333 Private=356714286\n",
            "Envios=9700\t TOTAL=337200000  Public=291066667 Private=356971429\n",
            "Envios=9800\t TOTAL=336800000  Public=289600000 Private=357028571\n",
            "Envios=9900\t TOTAL=337200000  Public=290133333 Private=357371429\n",
            "Envios=10000\t TOTAL=336800000  Public=290733333 Private=356542857\n",
            "Envios=10100\t TOTAL=338000000  Public=287933333 Private=359457143\n",
            "Envios=10200\t TOTAL=338400000  Public=291400000 Private=358542857\n",
            "Envios=10300\t TOTAL=338800000  Public=292533333 Private=358628571\n",
            "Envios=10400\t TOTAL=338400000  Public=295466667 Private=356800000\n",
            "Envios=10500\t TOTAL=338000000  Public=296466667 Private=355800000\n",
            "Envios=10600\t TOTAL=337600000  Public=296933333 Private=355028571\n",
            "Envios=10700\t TOTAL=338000000  Public=294266667 Private=356742857\n",
            "Envios=10800\t TOTAL=337600000  Public=294933333 Private=355885714\n",
            "Envios=10900\t TOTAL=335600000  Public=292933333 Private=353885714\n",
            "Envios=11000\t TOTAL=334400000  Public=293800000 Private=351800000\n",
            "Envios=11100\t TOTAL=335600000  Public=299466667 Private=351085714\n",
            "Envios=11200\t TOTAL=335200000  Public=299533333 Private=350485714\n",
            "Envios=11300\t TOTAL=334800000  Public=297266667 Private=350885714\n",
            "Envios=11400\t TOTAL=333600000  Public=295933333 Private=349742857\n",
            "Envios=11500\t TOTAL=333200000  Public=296600000 Private=348885714\n",
            "Envios=11600\t TOTAL=334400000  Public=294400000 Private=351542857\n",
            "Envios=11700\t TOTAL=334000000  Public=292266667 Private=351885714\n",
            "Envios=11800\t TOTAL=334400000  Public=293066667 Private=352114286\n",
            "Envios=11900\t TOTAL=333200000  Public=291333333 Private=351142857\n",
            "Envios=12000\t TOTAL=333600000  Public=296733333 Private=349400000\n",
            "Envios=12100\t TOTAL=331600000  Public=295266667 Private=347171429\n",
            "Envios=12200\t TOTAL=332000000  Public=295466667 Private=347657143\n",
            "Envios=12300\t TOTAL=330800000  Public=293733333 Private=346685714\n",
            "Envios=12400\t TOTAL=330400000  Public=294266667 Private=345885714\n",
            "Envios=12500\t TOTAL=330000000  Public=292200000 Private=346200000\n",
            "Envios=12600\t TOTAL=330400000  Public=295666667 Private=345285714\n",
            "Envios=12700\t TOTAL=329200000  Public=293066667 Private=344685714\n",
            "Envios=12800\t TOTAL=329600000  Public=293933333 Private=344885714\n",
            "Envios=12900\t TOTAL=330800000  Public=294800000 Private=346228571\n",
            "Envios=13000\t TOTAL=332800000  Public=295466667 Private=348800000\n",
            "Envios=13100\t TOTAL=335600000  Public=299000000 Private=351285714\n",
            "Envios=13200\t TOTAL=333600000  Public=297266667 Private=349171429\n",
            "Envios=13300\t TOTAL=332400000  Public=295400000 Private=348257143\n",
            "Envios=13400\t TOTAL=332800000  Public=299133333 Private=347228571\n",
            "Envios=13500\t TOTAL=333200000  Public=297533333 Private=348485714\n",
            "Envios=13600\t TOTAL=333600000  Public=300666667 Private=347714286\n",
            "Envios=13700\t TOTAL=332400000  Public=300933333 Private=345885714\n",
            "Envios=13800\t TOTAL=331200000  Public=298866667 Private=345057143\n",
            "Envios=13900\t TOTAL=331600000  Public=297000000 Private=346428571\n",
            "Envios=14000\t TOTAL=331200000  Public=297133333 Private=345800000\n",
            "Envios=14100\t TOTAL=330000000  Public=294933333 Private=345028571\n",
            "Envios=14200\t TOTAL=328800000  Public=295333333 Private=343142857\n",
            "Envios=14300\t TOTAL=329200000  Public=293333333 Private=344571429\n",
            "Envios=14400\t TOTAL=328000000  Public=291533333 Private=343628571\n",
            "Envios=14500\t TOTAL=326800000  Public=292200000 Private=341628571\n",
            "Envios=14600\t TOTAL=325600000  Public=289933333 Private=340885714\n",
            "Envios=14700\t TOTAL=324400000  Public=287466667 Private=340228571\n",
            "Envios=14800\t TOTAL=322400000  Public=285666667 Private=338142857\n",
            "Envios=14900\t TOTAL=322000000  Public=283733333 Private=338400000\n",
            "Envios=15000\t TOTAL=321600000  Public=284533333 Private=337485714\n",
            "Envios=15100\t TOTAL=321200000  Public=282733333 Private=337685714\n",
            "Envios=15200\t TOTAL=321600000  Public=286266667 Private=336742857\n",
            "Envios=15300\t TOTAL=321200000  Public=287266667 Private=335742857\n",
            "Envios=15400\t TOTAL=320800000  Public=287866667 Private=334914286\n",
            "Envios=15500\t TOTAL=318800000  Public=285666667 Private=333000000\n",
            "Envios=15600\t TOTAL=318400000  Public=286333333 Private=332142857\n",
            "Envios=15700\t TOTAL=318000000  Public=286466667 Private=331514286\n",
            "Envios=15800\t TOTAL=316800000  Public=284800000 Private=330514286\n",
            "Envios=15900\t TOTAL=314800000  Public=282600000 Private=328600000\n",
            "Envios=16000\t TOTAL=314400000  Public=283600000 Private=327600000\n",
            "Envios=16100\t TOTAL=316400000  Public=287066667 Private=328971429\n",
            "Envios=16200\t TOTAL=316800000  Public=287600000 Private=329314286\n",
            "Envios=16300\t TOTAL=315600000  Public=287866667 Private=327485714\n",
            "Envios=16400\t TOTAL=314400000  Public=286066667 Private=326542857\n",
            "Envios=16500\t TOTAL=313200000  Public=284466667 Private=325514286\n",
            "Envios=16600\t TOTAL=312000000  Public=282066667 Private=324828571\n",
            "Envios=16700\t TOTAL=310000000  Public=280066667 Private=322828571\n",
            "Envios=16800\t TOTAL=312800000  Public=283600000 Private=325314286\n",
            "Envios=16900\t TOTAL=313200000  Public=284000000 Private=325714286\n",
            "Envios=17000\t TOTAL=312000000  Public=281666667 Private=325000000\n",
            "Envios=17100\t TOTAL=310000000  Public=279866667 Private=322914286\n",
            "Envios=17200\t TOTAL=308800000  Public=277733333 Private=322114286\n",
            "Envios=17300\t TOTAL=306800000  Public=275933333 Private=320028571\n",
            "Envios=17400\t TOTAL=306400000  Public=276733333 Private=319114286\n",
            "Envios=17500\t TOTAL=305200000  Public=274600000 Private=318314286\n",
            "Envios=17600\t TOTAL=304000000  Public=275133333 Private=316371429\n",
            "Envios=17700\t TOTAL=305200000  Public=278400000 Private=316685714\n",
            "Envios=17800\t TOTAL=304800000  Public=278800000 Private=315942857\n",
            "Envios=17900\t TOTAL=303600000  Public=276733333 Private=315114286\n",
            "Envios=18000\t TOTAL=302400000  Public=274200000 Private=314485714\n",
            "Envios=18100\t TOTAL=300400000  Public=272333333 Private=312428571\n",
            "Envios=18200\t TOTAL=299200000  Public=270466667 Private=311514286\n",
            "Envios=18300\t TOTAL=297200000  Public=268533333 Private=309485714\n",
            "Envios=18400\t TOTAL=295200000  Public=266600000 Private=307457143\n",
            "Envios=18500\t TOTAL=293200000  Public=265066667 Private=305257143\n",
            "Envios=18600\t TOTAL=291200000  Public=262866667 Private=303342857\n",
            "Envios=18700\t TOTAL=289200000  Public=261066667 Private=301257143\n",
            "Envios=18800\t TOTAL=290400000  Public=261533333 Private=302771429\n",
            "Envios=18900\t TOTAL=289200000  Public=259333333 Private=302000000\n",
            "Envios=19000\t TOTAL=288800000  Public=257066667 Private=302400000\n"
          ]
        }
      ],
      "source": [
        "# genero archivos con los  \"envios\" mejores\n",
        "# suba TODOS los archivos a Kaggle\n",
        "\n",
        "# ordeno por probabilidad descendente\n",
        "setorder(tb_prediccion, -prob)\n",
        "\n",
        "dir.create(\"kaggle\")\n",
        "\n",
        "for (envios in PARAM$cortes) {\n",
        "\n",
        "  tb_prediccion[, Predicted := 0L] # seteo inicial a 0\n",
        "  tb_prediccion[1:envios, Predicted := 1L] # marco los primeros\n",
        "\n",
        "  archivo_kaggle <- paste0(\"./kaggle/KA\", PARAM$experimento, \"_\", envios, \".csv\")\n",
        "\n",
        "  # grabo el archivo\n",
        "  fwrite(tb_prediccion[, list(numero_de_cliente, Predicted)],\n",
        "    file= archivo_kaggle,\n",
        "    sep= \",\"\n",
        "  )\n",
        "\n",
        "  res <- realidad_evaluar( drealidad, tb_prediccion)\n",
        "\n",
        "  options(scipen = 999)\n",
        "  cat( \"Envios=\", envios, \"\\t\",\n",
        "    \" TOTAL=\", res$total,\n",
        "    \"  Public=\", res$public,\n",
        "    \" Private=\", res$private,\n",
        "    \"\\n\",\n",
        "    sep= \"\"\n",
        "  )\n",
        "\n",
        "}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {
        "id": "B9tB2X4439Hg",
        "vscode": {
          "languageId": "r"
        }
      },
      "outputs": [],
      "source": [
        "write_yaml( PARAM, file=\"PARAM.yml\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {
        "id": "9zA_W25c15DP",
        "vscode": {
          "languageId": "r"
        }
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "'vie oct 03 06:21:35 2025'"
            ],
            "text/latex": [
              "'vie oct 03 06:21:35 2025'"
            ],
            "text/markdown": [
              "'vie oct 03 06:21:35 2025'"
            ],
            "text/plain": [
              "[1] \"vie oct 03 06:21:35 2025\""
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "format(Sys.time(), \"%a %b %d %X %Y\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UdVZucdLHzZ0"
      },
      "source": [
        "Finalmente usted deberá cargar el resultado de su corrida en la Google Sheet Colaborativa,  hoja **TareaHogar04**\n",
        "<br> Siéntase libre de agregar las columnas que hagan falta a la planilla"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {
        "vscode": {
          "languageId": "r"
        }
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Envios=4000\t TOTAL=278400000  Public=220400000 Private=303257143\n",
            "Envios=4100\t TOTAL=282000000  Public=227066667 Private=305542857\n",
            "Envios=4200\t TOTAL=283200000  Public=227600000 Private=307028571\n",
            "Envios=4300\t TOTAL=289200000  Public=233866667 Private=312914286\n",
            "Envios=4400\t TOTAL=293600000  Public=239866667 Private=316628571\n",
            "Envios=4500\t TOTAL=294800000  Public=240200000 Private=318200000\n",
            "Envios=4600\t TOTAL=296000000  Public=241333333 Private=319428571\n",
            "Envios=4700\t TOTAL=300400000  Public=246666667 Private=323428571\n",
            "Envios=4800\t TOTAL=300800000  Public=247533333 Private=323628571\n",
            "Envios=4900\t TOTAL=302800000  Public=250533333 Private=325200000\n",
            "Envios=5000\t TOTAL=307200000  Public=256200000 Private=329057143\n",
            "Envios=5100\t TOTAL=310800000  Public=254266667 Private=335028571\n",
            "Envios=5200\t TOTAL=312800000  Public=260200000 Private=335342857\n",
            "Envios=5300\t TOTAL=312400000  Public=261466667 Private=334228571\n",
            "Envios=5400\t TOTAL=312000000  Public=259066667 Private=334685714\n",
            "Envios=5500\t TOTAL=312400000  Public=259266667 Private=335171429\n",
            "Envios=5600\t TOTAL=316000000  Public=257400000 Private=341114286\n",
            "Envios=5700\t TOTAL=318000000  Public=263666667 Private=341285714\n",
            "Envios=5800\t TOTAL=320000000  Public=275066667 Private=339257143\n",
            "Envios=5900\t TOTAL=320400000  Public=272733333 Private=340828571\n",
            "Envios=6000\t TOTAL=323200000  Public=278733333 Private=342257143\n",
            "Envios=6100\t TOTAL=323600000  Public=279533333 Private=342485714\n",
            "Envios=6200\t TOTAL=324000000  Public=285066667 Private=340685714\n",
            "Envios=6300\t TOTAL=324400000  Public=282800000 Private=342228571\n",
            "Envios=6400\t TOTAL=326400000  Public=280866667 Private=345914286\n",
            "Envios=6500\t TOTAL=326800000  Public=284200000 Private=345057143\n",
            "Envios=6600\t TOTAL=328800000  Public=287733333 Private=346400000\n",
            "Envios=6700\t TOTAL=330800000  Public=286133333 Private=349942857\n",
            "Envios=6800\t TOTAL=330400000  Public=286866667 Private=349057143\n",
            "Envios=6900\t TOTAL=330000000  Public=290000000 Private=347142857\n",
            "Envios=7000\t TOTAL=328000000  Public=288066667 Private=345114286\n",
            "Envios=7100\t TOTAL=326000000  Public=285800000 Private=343228571\n",
            "Envios=7200\t TOTAL=324800000  Public=283800000 Private=342371429\n",
            "Envios=7300\t TOTAL=326800000  Public=289533333 Private=342771429\n",
            "Envios=7400\t TOTAL=330400000  Public=292400000 Private=346685714\n",
            "Envios=7500\t TOTAL=330000000  Public=293000000 Private=345857143\n",
            "Envios=7600\t TOTAL=329600000  Public=293933333 Private=344885714\n",
            "Envios=7700\t TOTAL=330000000  Public=294666667 Private=345142857\n",
            "Envios=7800\t TOTAL=328800000  Public=292533333 Private=344342857\n",
            "Envios=7900\t TOTAL=328400000  Public=290266667 Private=344742857\n",
            "Envios=8000\t TOTAL=329600000  Public=290866667 Private=346200000\n",
            "Envios=8100\t TOTAL=328400000  Public=288666667 Private=345428571\n",
            "Envios=8200\t TOTAL=326400000  Public=286733333 Private=343400000\n",
            "Envios=8300\t TOTAL=327600000  Public=287400000 Private=344828571\n",
            "Envios=8400\t TOTAL=328800000  Public=293266667 Private=344028571\n",
            "Envios=8500\t TOTAL=330800000  Public=299200000 Private=344342857\n",
            "Envios=8600\t TOTAL=331200000  Public=299866667 Private=344628571\n",
            "Envios=8700\t TOTAL=330800000  Public=298200000 Private=344771429\n",
            "Envios=8800\t TOTAL=330400000  Public=296066667 Private=345114286\n",
            "Envios=8900\t TOTAL=333200000  Public=296666667 Private=348857143\n",
            "Envios=9000\t TOTAL=335200000  Public=295200000 Private=352342857\n",
            "Envios=9100\t TOTAL=336400000  Public=298200000 Private=352771429\n",
            "Envios=9200\t TOTAL=337600000  Public=301600000 Private=353028571\n",
            "Envios=9300\t TOTAL=338000000  Public=305000000 Private=352142857\n",
            "Envios=9400\t TOTAL=339200000  Public=308133333 Private=352514286\n",
            "Envios=9500\t TOTAL=338800000  Public=306000000 Private=352857143\n",
            "Envios=9600\t TOTAL=338400000  Public=304533333 Private=352914286\n",
            "Envios=9700\t TOTAL=336400000  Public=302800000 Private=350800000\n",
            "Envios=9800\t TOTAL=336000000  Public=305666667 Private=349000000\n",
            "Envios=9900\t TOTAL=335600000  Public=303333333 Private=349428571\n",
            "Envios=10000\t TOTAL=334400000  Public=301066667 Private=348685714\n",
            "Envios=10100\t TOTAL=335600000  Public=299066667 Private=351257143\n",
            "Envios=10200\t TOTAL=335200000  Public=297000000 Private=351571429\n",
            "Envios=10300\t TOTAL=334800000  Public=297800000 Private=350657143\n",
            "Envios=10400\t TOTAL=332800000  Public=295733333 Private=348685714\n",
            "Envios=10500\t TOTAL=332400000  Public=293800000 Private=348942857\n",
            "Envios=10600\t TOTAL=333600000  Public=292266667 Private=351314286\n",
            "Envios=10700\t TOTAL=334800000  Public=295466667 Private=351657143\n",
            "Envios=10800\t TOTAL=335200000  Public=295866667 Private=352057143\n",
            "Envios=10900\t TOTAL=336400000  Public=293800000 Private=354657143\n",
            "Envios=11000\t TOTAL=336000000  Public=294400000 Private=353828571\n",
            "Envios=11100\t TOTAL=335600000  Public=292200000 Private=354200000\n",
            "Envios=11200\t TOTAL=335200000  Public=292933333 Private=353314286\n",
            "Envios=11300\t TOTAL=335600000  Public=293333333 Private=353714286\n",
            "Envios=11400\t TOTAL=336000000  Public=296466667 Private=352942857\n",
            "Envios=11500\t TOTAL=335600000  Public=296466667 Private=352371429\n",
            "Envios=11600\t TOTAL=334400000  Public=294466667 Private=351514286\n",
            "Envios=11700\t TOTAL=333200000  Public=294666667 Private=349714286\n",
            "Envios=11800\t TOTAL=336000000  Public=300333333 Private=351285714\n",
            "Envios=11900\t TOTAL=335600000  Public=300933333 Private=350457143\n",
            "Envios=12000\t TOTAL=335200000  Public=303733333 Private=348685714\n",
            "Envios=12100\t TOTAL=334800000  Public=302200000 Private=348771429\n",
            "Envios=12200\t TOTAL=335200000  Public=303200000 Private=348914286\n",
            "Envios=12300\t TOTAL=334000000  Public=301266667 Private=348028571\n",
            "Envios=12400\t TOTAL=336000000  Public=302133333 Private=350514286\n",
            "Envios=12500\t TOTAL=334800000  Public=300266667 Private=349600000\n",
            "Envios=12600\t TOTAL=338400000  Public=303400000 Private=353400000\n",
            "Envios=12700\t TOTAL=337200000  Public=301600000 Private=352457143\n",
            "Envios=12800\t TOTAL=337600000  Public=302733333 Private=352542857\n",
            "Envios=12900\t TOTAL=337200000  Public=303466667 Private=351657143\n",
            "Envios=13000\t TOTAL=335200000  Public=301266667 Private=349742857\n",
            "Envios=13100\t TOTAL=334800000  Public=298800000 Private=350228571\n",
            "Envios=13200\t TOTAL=333600000  Public=296800000 Private=349371429\n",
            "Envios=13300\t TOTAL=331600000  Public=294666667 Private=347428571\n",
            "Envios=13400\t TOTAL=331200000  Public=295333333 Private=346571429\n",
            "Envios=13500\t TOTAL=332400000  Public=296000000 Private=348000000\n",
            "Envios=13600\t TOTAL=333600000  Public=299066667 Private=348400000\n",
            "Envios=13700\t TOTAL=334000000  Public=302066667 Private=347685714\n",
            "Envios=13800\t TOTAL=332000000  Public=300333333 Private=345571429\n",
            "Envios=13900\t TOTAL=332400000  Public=298600000 Private=346885714\n",
            "Envios=14000\t TOTAL=331200000  Public=296533333 Private=346057143\n",
            "Envios=14100\t TOTAL=330000000  Public=297466667 Private=343942857\n",
            "Envios=14200\t TOTAL=329600000  Public=300933333 Private=341885714\n",
            "Envios=14300\t TOTAL=327600000  Public=299133333 Private=339800000\n",
            "Envios=14400\t TOTAL=327200000  Public=297200000 Private=340057143\n",
            "Envios=14500\t TOTAL=326800000  Public=294533333 Private=340628571\n",
            "Envios=14600\t TOTAL=328000000  Public=295066667 Private=342114286\n",
            "Envios=14700\t TOTAL=327600000  Public=296133333 Private=341085714\n",
            "Envios=14800\t TOTAL=326400000  Public=294533333 Private=340057143\n",
            "Envios=14900\t TOTAL=326800000  Public=292600000 Private=341457143\n",
            "Envios=15000\t TOTAL=327200000  Public=290933333 Private=342742857\n",
            "Envios=15100\t TOTAL=326000000  Public=288333333 Private=342142857\n",
            "Envios=15200\t TOTAL=325600000  Public=288800000 Private=341371429\n",
            "Envios=15300\t TOTAL=324400000  Public=289333333 Private=339428571\n",
            "Envios=15400\t TOTAL=323200000  Public=286866667 Private=338771429\n",
            "Envios=15500\t TOTAL=322800000  Public=287400000 Private=337971429\n",
            "Envios=15600\t TOTAL=323200000  Public=287866667 Private=338342857\n",
            "Envios=15700\t TOTAL=322800000  Public=286133333 Private=338514286\n",
            "Envios=15800\t TOTAL=321600000  Public=284066667 Private=337685714\n",
            "Envios=15900\t TOTAL=321200000  Public=287733333 Private=335542857\n",
            "Envios=16000\t TOTAL=322400000  Public=291400000 Private=335685714\n",
            "Envios=16100\t TOTAL=322800000  Public=295000000 Private=334714286\n",
            "Envios=16200\t TOTAL=322400000  Public=295733333 Private=333828571\n",
            "Envios=16300\t TOTAL=321200000  Public=295800000 Private=332085714\n",
            "Envios=16400\t TOTAL=320000000  Public=296133333 Private=330228571\n",
            "Envios=16500\t TOTAL=319600000  Public=294533333 Private=330342857\n",
            "Envios=16600\t TOTAL=317600000  Public=292466667 Private=328371429\n",
            "Envios=16700\t TOTAL=318000000  Public=290133333 Private=329942857\n",
            "Envios=16800\t TOTAL=316000000  Public=288200000 Private=327914286\n",
            "Envios=16900\t TOTAL=315600000  Public=286200000 Private=328200000\n",
            "Envios=17000\t TOTAL=314400000  Public=284133333 Private=327371429\n",
            "Envios=17100\t TOTAL=313200000  Public=284400000 Private=325542857\n",
            "Envios=17200\t TOTAL=312000000  Public=282266667 Private=324742857\n",
            "Envios=17300\t TOTAL=310000000  Public=280400000 Private=322685714\n",
            "Envios=17400\t TOTAL=309600000  Public=281266667 Private=321742857\n",
            "Envios=17500\t TOTAL=307600000  Public=279266667 Private=319742857\n",
            "Envios=17600\t TOTAL=306400000  Public=277600000 Private=318742857\n",
            "Envios=17700\t TOTAL=305200000  Public=278133333 Private=316800000\n",
            "Envios=17800\t TOTAL=304800000  Public=276066667 Private=317114286\n",
            "Envios=17900\t TOTAL=302800000  Public=274000000 Private=315142857\n",
            "Envios=18000\t TOTAL=301600000  Public=272200000 Private=314200000\n",
            "Envios=18100\t TOTAL=300400000  Public=270066667 Private=313400000\n",
            "Envios=18200\t TOTAL=300000000  Public=268066667 Private=313685714\n",
            "Envios=18300\t TOTAL=298800000  Public=265600000 Private=313028571\n",
            "Envios=18400\t TOTAL=299200000  Public=268800000 Private=312228571\n",
            "Envios=18500\t TOTAL=297200000  Public=267133333 Private=310085714\n",
            "Envios=18600\t TOTAL=296800000  Public=265266667 Private=310314286\n",
            "Envios=18700\t TOTAL=295600000  Public=263400000 Private=309400000\n",
            "Envios=18800\t TOTAL=295200000  Public=261666667 Private=309571429\n",
            "Envios=18900\t TOTAL=293200000  Public=259666667 Private=307571429\n",
            "Envios=19000\t TOTAL=292800000  Public=260333333 Private=306714286\n"
          ]
        }
      ],
      "source": [
        "# Definir las 5 semillas fijas para el ensemble\n",
        "semillas_fijas <- c(200003,300007,400009,500009,600011)\n",
        "\n",
        "# Inicializar una lista para almacenar las predicciones de cada modelo\n",
        "list_predicciones <- list()\n",
        "\n",
        "# Iniciar el bucle para entrenar y predecir con cada una de las semillas\n",
        "for (semilla in semillas_fijas) {\n",
        "\n",
        "  # Asignar la semilla actual a los parámetros del modelo\n",
        "  param_normalizado$seed <- semilla\n",
        "  \n",
        "  # Entrenar el modelo LightGBM\n",
        "  modelo_temp <- lgb.train(\n",
        "    data = dtrain_final,\n",
        "    param = param_normalizado\n",
        "  )\n",
        "  \n",
        "  # Preparar los datos sin clase para la predicción\n",
        "  dfuture <- dataset[foto_mes %in% PARAM$future]\n",
        "  \n",
        "  # Realizar la predicción con el modelo actual\n",
        "  prediccion_temp <- predict(\n",
        "    modelo_temp,\n",
        "    data.matrix(dfuture[, campos_buenos, with = FALSE])\n",
        "  )\n",
        "  \n",
        "  # Guardar la predicción en la lista\n",
        "  list_predicciones[[length(list_predicciones) + 1]] <- prediccion_temp\n",
        "}\n",
        "\n",
        "# Unir las predicciones de todos los modelos en una sola matriz\n",
        "matriz_predicciones <- do.call(cbind, list_predicciones)\n",
        "\n",
        "# Calcular el promedio de las predicciones para obtener el resultado final del ensemble\n",
        "prediccion_ensemble <- rowMeans(matriz_predicciones)\n",
        "\n",
        "# Ahora, la variable 'prediccion_ensemble' contiene el resultado final del ensemble.\n",
        "# A partir de aquí, el código continúa usando esta nueva variable.\n",
        "\n",
        "# Inicilizo el dataset drealidad\n",
        "drealidad <- realidad_inicializar( dfuture, PARAM)\n",
        "\n",
        "# Crear la tabla de predicción\n",
        "tb_prediccion <- dfuture[, list(numero_de_cliente, foto_mes)]\n",
        "tb_prediccion[, prob := prediccion_ensemble ]\n",
        "\n",
        "# Generar los \"envios\" para los mejores resultados\n",
        "# Ordenar por probabilidad descendente\n",
        "setorder(tb_prediccion, -prob)\n",
        "\n",
        "# Crear el directorio 'kaggle' si no existe\n",
        "dir.create(\"kaggle_promediado\")\n",
        "resultados <- data.table()\n",
        "\n",
        "for (envios in PARAM$cortes) {\n",
        "\n",
        "  tb_prediccion[, Predicted := 0L] # seteo inicial a 0\n",
        "  tb_prediccion[1:envios, Predicted := 1L] # marcar los primeros envíos\n",
        "  \n",
        "  # Nombre del archivo para Kaggle\n",
        "  archivo_kaggle <- paste0(\"./kaggle_promediado/KA\", PARAM$experimento, \"_\", envios, \".csv\")\n",
        "  \n",
        "  # Guardar el archivo CSV\n",
        "  fwrite(tb_prediccion[, list(numero_de_cliente, Predicted)],\n",
        "         file = archivo_kaggle,\n",
        "         sep = \",\"\n",
        "  )\n",
        "  \n",
        "  # Evaluar el resultado\n",
        "  res <- realidad_evaluar( drealidad, tb_prediccion)\n",
        "    \n",
        "  resultados <- rbind(\n",
        "    resultados,\n",
        "    data.table(\n",
        "      clientes = envios,\n",
        "      ganancia_total = res$total,\n",
        "      ganancia_public = res$public,\n",
        "      ganancia_private = res$private\n",
        "    )\n",
        "  )\n",
        "  \n",
        "  # Imprimir los resultados en la consola\n",
        "  options(scipen = 999)\n",
        "  cat( \"Envios=\", envios, \"\\t\",\n",
        "       \" TOTAL=\", res$total,\n",
        "       \"  Public=\", res$public,\n",
        "       \" Private=\", res$private,\n",
        "       \"\\n\",\n",
        "       sep= \"\"\n",
        "  )\n",
        "}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "metadata": {
        "vscode": {
          "languageId": "r"
        }
      },
      "outputs": [
        {
          "ename": "ERROR",
          "evalue": "Error in ggplot(resultados_long, aes(x = clientes, y = ganancia, color = tipo)): no se pudo encontrar la función \"ggplot\"\n",
          "output_type": "error",
          "traceback": [
            "Error in ggplot(resultados_long, aes(x = clientes, y = ganancia, color = tipo)): no se pudo encontrar la función \"ggplot\"\nTraceback:\n"
          ]
        }
      ],
      "source": [
        "# pasamos a formato largo\n",
        "resultados_long <- melt(\n",
        "  resultados,\n",
        "  id.vars = \"clientes\",\n",
        "  measure.vars = c(\"ganancia_total\", \"ganancia_public\", \"ganancia_private\"),\n",
        "  variable.name = \"tipo\",\n",
        "  value.name = \"ganancia\"\n",
        ")\n",
        "\n",
        "# calcular máximos por tipo\n",
        "maximos <- resultados_long[, .SD[which.max(ganancia)], by = tipo]\n",
        "\n",
        "# crear etiquetas personalizadas para la leyenda\n",
        "etiquetas <- paste0(\n",
        "  maximos$tipo,\n",
        "  \" (envíos = \", maximos$clientes, \", máx = \", format(maximos$ganancia, big.mark = \",\"), \")\"\n",
        ")\n",
        "names(etiquetas) <- maximos$tipo\n",
        "\n",
        "# gráfico\n",
        "ggplot(resultados_long, aes(x = clientes, y = ganancia, color = tipo)) +\n",
        "  geom_line(size = 1) +\n",
        "  # agregar puntos en los máximos\n",
        "  geom_point(data = maximos, aes(x = clientes, y = ganancia, color = tipo), size = 3) +\n",
        "  labs(\n",
        "    title = \"Curvas de Ganancia\",\n",
        "    x = \"Clientes\",\n",
        "    y = \"Ganancia\",\n",
        "    color = \"Máximos\"\n",
        "  ) +\n",
        "  scale_color_manual(values = c(\"ganancia_total\" = \"steelblue\",\n",
        "                                \"ganancia_public\" = \"forestgreen\",\n",
        "                                \"ganancia_private\" = \"firebrick\"),\n",
        "                     labels = etiquetas) +\n",
        "  theme_minimal() +\n",
        "  theme(\n",
        "    plot.margin = margin(10, 10, 10, 10),  # top, right, bottom, left\n",
        "    legend.position = \"bottom\")+\n",
        "  guides(color = guide_legend(nrow = 3, byrow = TRUE))\n",
        "  #+ ggsave(\"curvas.png\", width = 10, height = 6)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "R",
      "language": "R",
      "name": "ir"
    },
    "language_info": {
      "codemirror_mode": "r",
      "file_extension": ".r",
      "mimetype": "text/x-r-source",
      "name": "R",
      "pygments_lexer": "r",
      "version": "4.4.3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
